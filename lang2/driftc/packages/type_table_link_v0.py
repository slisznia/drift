# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
"""
Link-time TypeTable unification for package consumption (v0).

Goal
----
When consuming packages, we must not require identical TypeId assignment across
independently-produced artifacts. Instead, we:

1) Merge imported type definitions into the host `TypeTable` deterministically.
2) Build a `pkg_type_id -> host_type_id` mapping.
3) Remap all TypeId references in:
   - package signatures
   - package MIR nodes
   - schema tables (struct/exception/variant schemas)

This makes package consumption scale without pinning everything to a single
`type_table_fingerprint`.

Pinned rules (MVP)
------------------
- Builtins are toolchain-owned and must unify to the host builtins:
  Int/Uint/Uint64/Bool/Float/String/Byte/Void/Error/DiagnosticValue/Unknown.
- Packages may import new user-defined nominal types into the host TypeTable
  as long as there are no semantic collisions.
- Collisions are hard errors:
  - same nominal identity but different schema
  - attempts to redefine builtins / reserved namespaces
- Merge is deterministic: inputs with the same content yield the same host
  TypeIds independent of package discovery order.

Notes
-----
This module operates on the *encoded* type table object stored in provisional
package payloads (`payload["type_table"]`).
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Mapping, Optional, Tuple

from lang2.driftc.core.generic_type_expr import GenericTypeExpr
from lang2.driftc.core.function_id import FunctionId, function_id_from_obj
from lang2.driftc.core.types_core import (
	NominalKey,
	TypeParamId,
	TypeDef,
	TypeId,
	TypeKind,
	TypeTable,
	StructFieldSchema,
	VariantArmSchema,
	VariantFieldSchema,
	VariantSchema,
)


@dataclass(frozen=True)
class DecodedTypeDef:
	kind: TypeKind
	name: str
	param_types: list[TypeId]
	module_id: str | None
	ref_mut: bool | None
	fn_throws: bool
	field_names: list[str] | None
	type_param_id: TypeParamId | None


@dataclass(frozen=True)
class DecodedTypeTable:
	package_id: str
	defs: dict[TypeId, DecodedTypeDef]
	struct_schemas: dict[NominalKey, tuple[list[StructFieldSchema], list[str], TypeId | None]]
	struct_instances: dict[TypeId, tuple[TypeId, list[TypeId]]]
	exception_schemas: dict[str, tuple[str, list[str]]]
	variant_schemas: dict[TypeId, VariantSchema]
	provided_nominals: set[tuple[TypeKind, str, str]]


def _decode_kind(name: str) -> TypeKind:
	try:
		return TypeKind[name]
	except KeyError as err:
		raise ValueError(f"unknown TypeKind '{name}' in package type table") from err


def _decode_generic_type_expr(obj: Any) -> GenericTypeExpr:
	"""
	Decode a GenericTypeExpr as encoded by `provisional_dmir_v0.encode_type_table`.
	"""
	if not isinstance(obj, dict):
		raise ValueError("invalid GenericTypeExpr encoding")
	name = obj.get("name")
	if not isinstance(name, str):
		raise ValueError("invalid GenericTypeExpr.name")
	module_id = obj.get("module_id")
	if module_id is not None and not isinstance(module_id, str):
		raise ValueError("invalid GenericTypeExpr.module_id")
	args_obj = obj.get("args")
	args: list[GenericTypeExpr] = []
	if args_obj is not None:
		if not isinstance(args_obj, list):
			raise ValueError("invalid GenericTypeExpr.args")
		args = [_decode_generic_type_expr(a) for a in args_obj]
	param_index = obj.get("param_index")
	if param_index is not None and not isinstance(param_index, int):
		raise ValueError("invalid GenericTypeExpr.param_index")
	if not name and param_index is None:
		raise ValueError("invalid GenericTypeExpr.name")
	if name != "fn":
		fn_throws = False
	else:
		if "fn_throws" in obj:
			fn_throws = obj.get("fn_throws")
			if fn_throws is None or not isinstance(fn_throws, bool):
				raise ValueError("invalid GenericTypeExpr.fn_throws")
		else:
			fn_throws = True
	return GenericTypeExpr(name=name, args=args, param_index=param_index, module_id=module_id, fn_throws=fn_throws)


def decode_type_table_obj(obj: Mapping[str, Any]) -> DecodedTypeTable:
	"""
	Decode a `type_table` JSON object from a package payload.
	"""
	pkg_id = obj.get("package_id")
	if not isinstance(pkg_id, str) or not pkg_id:
		raise ValueError("package type_table missing package_id")
	defs_obj = obj.get("defs")
	if not isinstance(defs_obj, dict):
		raise ValueError("package type_table missing defs")
	defs: dict[TypeId, DecodedTypeDef] = {}
	for tid_s, td_obj in defs_obj.items():
		try:
			tid = int(tid_s)
		except Exception as err:
			raise ValueError("invalid TypeId key in package type_table.defs") from err
		if not isinstance(td_obj, dict):
			raise ValueError("invalid type_table.defs entry")
		kind_s = td_obj.get("kind")
		name = td_obj.get("name")
		param_types = td_obj.get("param_types")
		module_id = td_obj.get("module_id")
		type_param_obj = td_obj.get("type_param_id")
		ref_mut = td_obj.get("ref_mut")
		fn_throws = td_obj.get("fn_throws", True)
		field_names = td_obj.get("field_names")
		if not isinstance(kind_s, str) or not isinstance(name, str) or not isinstance(param_types, list):
			raise ValueError("invalid type_table.defs entry fields")
		if module_id is not None and not isinstance(module_id, str):
			raise ValueError("invalid type_table.defs module_id")
		if module_id == "":
			raise ValueError("invalid type_table.defs module_id")
		if ref_mut is not None and not isinstance(ref_mut, bool):
			raise ValueError("invalid type_table.defs ref_mut")
		type_param_id: TypeParamId | None = None
		if type_param_obj is not None:
			if not isinstance(type_param_obj, dict):
				raise ValueError("invalid type_table.defs type_param_id")
			owner_obj = type_param_obj.get("owner")
			index_obj = type_param_obj.get("index")
			owner = function_id_from_obj(owner_obj)
			if owner is None or not isinstance(index_obj, int):
				raise ValueError("invalid type_table.defs type_param_id")
			type_param_id = TypeParamId(owner=owner, index=index_obj)
		if kind_s == "FUNCTION":
			if "fn_throws" in td_obj:
				fn_throws = td_obj.get("fn_throws")
				if fn_throws is None or not isinstance(fn_throws, bool):
					raise ValueError("invalid type_table.defs fn_throws")
			else:
				fn_throws = True
		else:
			fn_throws = False
		if field_names is not None and not isinstance(field_names, list):
			raise ValueError("invalid type_table.defs field_names")
		if kind_s == "TYPEVAR" and type_param_id is None:
			raise ValueError("invalid type_table.defs type_param_id")
		defs[tid] = DecodedTypeDef(
			kind=_decode_kind(kind_s),
			name=name,
			param_types=[int(x) for x in param_types],
			module_id=module_id,
			ref_mut=ref_mut,
			fn_throws=fn_throws,
			field_names=[str(x) for x in field_names] if field_names is not None else None,
			type_param_id=type_param_id,
		)

	struct_schemas_obj = obj.get("struct_schemas")
	struct_schemas: dict[NominalKey, tuple[list[StructFieldSchema], list[str], TypeId | None]] = {}
	if struct_schemas_obj is not None:
		if not isinstance(struct_schemas_obj, list):
			raise ValueError("invalid type_table.struct_schemas")
		for entry in struct_schemas_obj:
			if not isinstance(entry, dict):
				raise ValueError("invalid struct_schemas entry")
			base_id_obj = entry.get("base_id")
			base_id: TypeId | None = None
			if base_id_obj is None:
				raise ValueError("invalid struct_schemas entry base_id")
			if not isinstance(base_id_obj, int):
				raise ValueError("invalid struct_schemas entry base_id")
			base_id = base_id_obj
			type_id_obj = entry.get("type_id")
			if not isinstance(type_id_obj, dict):
				raise ValueError("invalid struct_schemas entry type_id")
			type_pkg = type_id_obj.get("package_id")
			type_mod = type_id_obj.get("module")
			type_name = type_id_obj.get("name")
			if not isinstance(type_pkg, str) or not type_pkg:
				raise ValueError("invalid struct_schemas entry type_id.package_id")
			if not isinstance(type_mod, str) or not type_mod:
				raise ValueError("invalid struct_schemas entry type_id.module")
			if not isinstance(type_name, str) or not type_name:
				raise ValueError("invalid struct_schemas entry type_id.name")
			module_id = entry.get("module_id")
			name = entry.get("name")
			fields = entry.get("fields")
			type_params_obj = entry.get("type_params")
			if not isinstance(module_id, str) or not isinstance(name, str) or not isinstance(fields, list):
				raise ValueError("invalid struct_schemas entry fields")
			if module_id != type_mod or name != type_name:
				raise ValueError("struct_schemas entry does not match type_id")
			field_schemas: list[StructFieldSchema] = []
			for fobj in fields:
				if not isinstance(fobj, dict):
					raise ValueError("invalid struct schema field entry")
				fname = fobj.get("name")
				fty = fobj.get("type_expr")
				if not isinstance(fname, str):
					raise ValueError("invalid struct schema field name")
				field_schemas.append(StructFieldSchema(name=fname, type_expr=_decode_generic_type_expr(fty)))
			type_params: list[str] = []
			if type_params_obj is not None:
				if not isinstance(type_params_obj, list):
					raise ValueError("invalid struct_schemas entry type_params")
				for tp in type_params_obj:
					if not isinstance(tp, str):
						raise ValueError("invalid struct_schemas entry type_params")
					type_params.append(tp)
			key = NominalKey(package_id=type_pkg, module_id=type_mod, name=type_name, kind=TypeKind.STRUCT)
			struct_schemas[key] = (field_schemas, type_params, base_id)

	exc_schemas_obj = obj.get("exception_schemas")
	exception_schemas: dict[str, tuple[str, list[str]]] = {}
	if exc_schemas_obj is not None:
		if not isinstance(exc_schemas_obj, dict):
			raise ValueError("invalid type_table.exception_schemas")
		for k, v in exc_schemas_obj.items():
			if not isinstance(k, str) or not isinstance(v, list) or len(v) != 2:
				raise ValueError("invalid exception_schemas entry")
			fqn = str(v[0])
			if k != fqn:
				raise ValueError("invalid exception_schemas key (must match event fqn)")
			fields = v[1]
			if not isinstance(fields, list):
				raise ValueError("invalid exception_schemas field list")
			exception_schemas[fqn] = (fqn, [str(x) for x in fields])

	variant_schemas_obj = obj.get("variant_schemas")
	variant_schemas: dict[TypeId, VariantSchema] = {}
	if variant_schemas_obj is not None:
		if not isinstance(variant_schemas_obj, dict):
			raise ValueError("invalid type_table.variant_schemas")
		for base_id_s, schema_obj in variant_schemas_obj.items():
			base_id = int(base_id_s)
			base_def = defs.get(base_id)
			if base_def is None or base_def.kind is not TypeKind.VARIANT:
				raise ValueError("variant_schemas entry missing VARIANT TypeDef")
			if base_def.param_types:
				raise ValueError("variant base TypeDef must not carry param_types")
			if not isinstance(schema_obj, dict):
				raise ValueError("invalid variant schema entry")
			schema_mid = schema_obj.get("module_id")
			name = schema_obj.get("name")
			type_params = schema_obj.get("type_params")
			arms_obj = schema_obj.get("arms")
			if not isinstance(schema_mid, str) or not isinstance(name, str) or not isinstance(type_params, list) or not isinstance(arms_obj, list):
				raise ValueError("invalid variant schema fields")
			arms: list[VariantArmSchema] = []
			for arm_obj in arms_obj:
				if not isinstance(arm_obj, dict):
					raise ValueError("invalid variant arm schema")
				arm_name = arm_obj.get("name")
				fields_obj = arm_obj.get("fields")
				if not isinstance(arm_name, str) or not isinstance(fields_obj, list):
					raise ValueError("invalid variant arm schema fields")
				fields: list[VariantFieldSchema] = []
				for fobj in fields_obj:
					if not isinstance(fobj, dict):
						raise ValueError("invalid variant field schema")
					fname = fobj.get("name")
					fty = fobj.get("type_expr")
					if not isinstance(fname, str):
						raise ValueError("invalid variant field name")
					fields.append(VariantFieldSchema(name=fname, type_expr=_decode_generic_type_expr(fty)))
				arms.append(VariantArmSchema(name=arm_name, fields=fields))
			if base_def.module_id != schema_mid or base_def.name != name:
				raise ValueError("variant schema does not match base VARIANT TypeDef")
			variant_schemas[base_id] = VariantSchema(module_id=schema_mid, name=name, type_params=[str(x) for x in type_params], arms=arms)

	struct_instances_obj = obj.get("struct_instances")
	struct_instances: dict[TypeId, tuple[TypeId, list[TypeId]]] = {}
	if struct_instances_obj is not None:
		if not isinstance(struct_instances_obj, list):
			raise ValueError("invalid type_table.struct_instances")
		for entry in struct_instances_obj:
			if not isinstance(entry, dict):
				raise ValueError("invalid struct_instances entry")
			inst_id_obj = entry.get("inst_id")
			base_id_obj = entry.get("base_id")
			type_args_obj = entry.get("type_args")
			if not isinstance(inst_id_obj, int) or not isinstance(base_id_obj, int) or not isinstance(type_args_obj, list):
				raise ValueError("invalid struct_instances entry fields")
			base_def = defs.get(base_id_obj)
			if base_def is None or base_def.kind is not TypeKind.STRUCT:
				raise ValueError("invalid struct_instances entry base_id")
			inst_def = defs.get(inst_id_obj)
			if inst_def is None or inst_def.kind is not TypeKind.STRUCT:
				raise ValueError("invalid struct_instances entry inst_id")
			if inst_def.module_id != base_def.module_id or inst_def.name != base_def.name:
				raise ValueError("struct instance TypeDef does not match base identity")
			struct_instances[int(inst_id_obj)] = (int(base_id_obj), [int(x) for x in type_args_obj])

	provided_nominals_obj = obj.get("provided_nominals")
	if provided_nominals_obj is None:
		raise ValueError("type_table.provided_nominals required (rebuild package)")
	if not isinstance(provided_nominals_obj, list):
		raise ValueError("invalid type_table.provided_nominals")
	provided_nominals: set[tuple[TypeKind, str, str]] = set()
	for entry in provided_nominals_obj:
		if not isinstance(entry, dict):
			raise ValueError("invalid provided_nominals entry")
		kind_s = entry.get("kind")
		module_id = entry.get("module_id")
		name = entry.get("name")
		if not isinstance(kind_s, str) or not isinstance(module_id, str) or not isinstance(name, str):
			raise ValueError("invalid provided_nominals entry")
		kind = _decode_kind(kind_s)
		if kind not in (TypeKind.STRUCT, TypeKind.VARIANT, TypeKind.SCALAR):
			raise ValueError("invalid provided_nominals entry")
		if not module_id:
			raise ValueError("invalid provided_nominals entry")
		provided_nominals.add((kind, module_id, name))
	return DecodedTypeTable(
		package_id=pkg_id,
		defs=defs,
		struct_schemas=struct_schemas,
		struct_instances=struct_instances,
		exception_schemas=exception_schemas,
		variant_schemas=variant_schemas,
		provided_nominals=provided_nominals,
	)


def _canonical_builtin_name(name: str) -> str:
	if name == "u64":
		return "Uint64"
	return name


def _builtin_type_id(host: TypeTable, td: DecodedTypeDef) -> TypeId | None:
	"""
	Map a package TypeDef to a canonical host builtin TypeId if it is a builtin.
	"""
	if td.kind is TypeKind.SCALAR:
		name = _canonical_builtin_name(td.name)
		if name == "Int":
			return host.ensure_int()
		if name == "Uint":
			return host.ensure_uint()
		if name == "Uint64":
			return host.ensure_uint64()
		if name == "Byte":
			return host.ensure_byte()
		if name == "Bool":
			return host.ensure_bool()
		if name == "Float":
			return host.ensure_float()
		if name == "String":
			return host.ensure_string()
	if td.kind is TypeKind.VOID:
		return host.ensure_void()
	if td.kind is TypeKind.ERROR and td.name == "Error":
		return host.ensure_error()
	if td.kind is TypeKind.DIAGNOSTICVALUE and td.name == "DiagnosticValue":
		return host.ensure_diagnostic_value()
	if td.kind is TypeKind.UNKNOWN and td.name == "Unknown":
		return host.ensure_unknown()
	return None


def import_type_table_and_build_typeid_map(pkg_tt_obj: Mapping[str, Any], host: TypeTable) -> dict[TypeId, TypeId]:
	"""
	Backwards-compatible single-package wrapper for the deterministic multi-linker.

	Do not add new logic here. All production behavior must live in
	`import_type_tables_and_build_typeid_maps(...)` so package type linking has a
	single source of truth.
	"""
	return import_type_tables_and_build_typeid_maps([pkg_tt_obj], host)[0]


TypeKey = tuple
_CORE_NOMINAL_ALLOWLIST: set[tuple[TypeKind, str]] = {(TypeKind.VARIANT, "Optional")}


def _normalized_pkg_id_for_module(pkg_id: str, module_id: str | None) -> str:
	if module_id == "lang.core":
		return "lang.core"
	return pkg_id


def import_type_tables_and_build_typeid_maps(pkg_tt_objs: list[Mapping[str, Any]], host: TypeTable) -> list[dict[TypeId, TypeId]]:
	"""
	Two-phase, order-independent type linking for package consumption.

	Pinned determinism contract:
	- The resulting host TypeIds and per-package `TypeId -> TypeId` maps must not
	  depend on package discovery order, filesystem ordering, or `--package-root`
	  ordering.
	- Allocation is driven only by canonical type keys derived from package
	  contents (builtins, nominal identities, and structural constructors).
	"""
	pkgs = [decode_type_table_obj(obj) for obj in pkg_tt_objs]
	host.module_packages.setdefault("lang.core", "lang.core")
	# Module ownership is owned by the package resolver (or workspace), not by
	# type linking. Avoid inferring moduleâ†’package mappings from TypeDefs.
	# Module ownership collision checks are performed by the resolver; linker
	# does not infer providers from schemas/TypeDefs.
	module_providers: dict[str, str] = {}
	for pkg in pkgs:
		provided = {(k, mid, name) for (k, mid, name) in pkg.provided_nominals}
		for kind, module_id, name in provided:
			match = next(
				(
					td
					for td in pkg.defs.values()
					if td.kind is kind and td.module_id == module_id and td.name == name
				),
				None,
			)
			if match is None or _builtin_type_id(host, match) is not None:
				raise ValueError("invalid provided_nominals entry (no matching TypeDef)")
		for kind, module_id, name in provided:
			if module_id != "lang.core":
				prev = module_providers.get(module_id)
				if prev is None:
					module_providers[module_id] = pkg.package_id
				elif prev != pkg.package_id:
					raise ValueError(f"module id collision for '{module_id}'")
				continue
			if pkg.package_id != "lang.core":
				raise ValueError("package cannot provide lang.core definitions")
			if kind in (TypeKind.STRUCT, TypeKind.SCALAR, TypeKind.VARIANT):
				if (kind, name) not in _CORE_NOMINAL_ALLOWLIST:
					raise ValueError("unsupported lang.core nominal in package")
	for module_id, pkg_id in host.module_packages.items():
		prev = module_providers.get(module_id)
		if prev is not None and prev != pkg_id:
			raise ValueError(f"module id collision for '{module_id}'")
	# Populate host.module_packages deterministically from provided modules.
	for module_id, pkg_id in sorted(module_providers.items()):
		host.module_packages[module_id] = pkg_id

	# Phase A: compute canonical keys for every package TypeId.
	#
	# Keys must cover all types that can appear in signatures/MIR/schemas:
	# - builtins (by kind+name),
	# - nominal types (module_id, kind, name),
	# - derived/structural types (constructor + param keys),
	# - variant instantiations (base nominal key + arg keys).
	pkg_tid_to_key: list[dict[TypeId, TypeKey]] = []
	typevar_display_names: dict[TypeKey, tuple[int, str]] = {}
	for pkg in pkgs:
		memo: dict[TypeId, TypeKey] = {}

		def key_for_tid(tid: TypeId) -> TypeKey:
			if tid in memo:
				return memo[tid]
			td = pkg.defs.get(tid)
			if td is None:
				raise ValueError(f"unknown TypeId {tid} referenced by package type table")
			# Builtins: identified by kind+name (toolchain-owned).
			if _builtin_type_id(host, td) is not None:
				builtin_name = _canonical_builtin_name(td.name)
				k = ("builtin", td.kind.name, builtin_name)
				memo[tid] = k
				return k
			# Nominal identities: (kind,package_id,module_id,name).
			mid = td.module_id or ""
			pkg_id = _normalized_pkg_id_for_module(pkg.package_id, td.module_id) if mid else ""
			if td.kind is TypeKind.STRUCT and tid in pkg.struct_instances:
				base_id, type_args = pkg.struct_instances[tid]
				base_def = pkg.defs.get(base_id)
				if base_def is None or base_def.kind is not TypeKind.STRUCT:
					raise ValueError("struct instance missing base TypeDef")
				if base_def.module_id is None:
					raise ValueError(f"struct instance base '{base_def.name}' missing module_id")
				if td.module_id != base_def.module_id or td.name != base_def.name:
					raise ValueError("struct instance TypeDef does not match base identity")
				base_mid = base_def.module_id or ""
				base_pkg_id = _normalized_pkg_id_for_module(pkg.package_id, base_def.module_id) if base_mid else ""
				base_key = ("nominal", TypeKind.STRUCT.name, base_pkg_id, base_mid, base_def.name)
				arg_keys = tuple(key_for_tid(x) for x in type_args)
				k = ("inst", base_key, arg_keys)
				memo[tid] = k
				return k
			if td.kind in (TypeKind.STRUCT, TypeKind.SCALAR):
				if td.kind is TypeKind.SCALAR and _builtin_type_id(host, td) is None and td.module_id is None:
					raise ValueError(f"package SCALAR '{td.name}' missing module_id")
				if td.kind is TypeKind.STRUCT and td.module_id is None:
					raise ValueError(f"package STRUCT '{td.name}' missing module_id")
				k = ("nominal", td.kind.name, pkg_id, mid, td.name)
				memo[tid] = k
				return k
			if td.kind is TypeKind.VARIANT:
				base_key = ("nominal", TypeKind.VARIANT.name, pkg_id, mid, td.name)
				# Distinguish base vs instantiated variant types.
				if tid in pkg.variant_schemas and not td.param_types:
					memo[tid] = base_key
					return base_key
				if td.param_types:
					arg_keys = tuple(key_for_tid(x) for x in td.param_types)
					k = ("inst", base_key, arg_keys)
					memo[tid] = k
					return k
				memo[tid] = base_key
				return base_key
			if td.kind is TypeKind.TYPEVAR:
				owner = td.type_param_id.owner
				k = ("typevar", pkg.package_id, ("owner", owner.module, owner.name, owner.ordinal), td.type_param_id.index)
				existing_entry = typevar_display_names.get(k)
				if existing_entry is None or tid < existing_entry[0]:
					typevar_display_names[k] = (tid, td.name)
				memo[tid] = k
				return k

			# Structural / derived types.
			sub_keys = tuple(key_for_tid(x) for x in td.param_types)
			if td.kind is TypeKind.ARRAY:
				k = ("array", sub_keys[0])
			elif td.kind is TypeKind.REF:
				k = ("ref", bool(td.ref_mut), sub_keys[0])
			elif td.kind is TypeKind.FNRESULT:
				k = ("fnresult", sub_keys[0], sub_keys[1])
			elif td.kind is TypeKind.FUNCTION:
				k = ("function", bool(td.fn_throws), sub_keys)
			else:
				k = ("kind", td.kind.name, td.name, sub_keys, bool(td.ref_mut))
			memo[tid] = k
			return k

		m: dict[TypeId, TypeKey] = {}
		for tid in pkg.defs.keys():
			m[tid] = key_for_tid(tid)
		pkg_tid_to_key.append(m)

	# Phase A: merge/validate exception schemas (keyed by canonical event fqn).
	for pkg in pkgs:
		for fqn, schema in sorted(pkg.exception_schemas.items()):
			prev = host.exception_schemas.get(fqn)
			if prev is None:
				host.exception_schemas[fqn] = schema
			elif prev != schema:
				raise ValueError(f"exception schema collision for '{fqn}'")

	# Phase A: merge/validate variant schemas by nominal identity.
	merged_variant_schemas: dict[NominalKey, VariantSchema] = {}
	for pkg in pkgs:
		for _base_id, schema in pkg.variant_schemas.items():
			if schema.module_id == "lang.core" and pkg.package_id != "lang.core":
				if (TypeKind.VARIANT, schema.name) != (TypeKind.VARIANT, "Optional"):
					raise ValueError("package cannot provide lang.core definitions")
			pkg_id = _normalized_pkg_id_for_module(pkg.package_id, schema.module_id)
			key = NominalKey(package_id=pkg_id, module_id=schema.module_id, name=schema.name, kind=TypeKind.VARIANT)
			if schema.module_id == "lang.core":
				if (TypeKind.VARIANT, schema.name) not in _CORE_NOMINAL_ALLOWLIST:
					raise ValueError(f"unsupported lang.core nominal '{schema.name}' in package")
				if schema.name == "Optional":
					base_id = host.ensure_optional_base()
					canonical = host.variant_schemas.get(base_id)
					if canonical is None or canonical != schema:
						raise ValueError("lang.core Optional schema mismatch")
			prev = merged_variant_schemas.get(key)
			if prev is None:
				merged_variant_schemas[key] = schema
			elif prev != schema:
				raise ValueError(f"variant schema collision for '{schema.module_id}:{schema.name}'")

	# Phase A: merge/validate struct schemas with full field typing.
	merged_struct_schemas: dict[NominalKey, tuple[list[StructFieldSchema], list[str]]] = {}
	for pkg_idx, pkg in enumerate(pkgs):
		pkg_struct_ids: dict[NominalKey, list[TypeId]] = {}
		for tid, td in pkg.defs.items():
			if td.kind is TypeKind.STRUCT:
				if td.module_id is None:
					raise ValueError(f"package STRUCT '{td.name}' missing module_id")
				pkg_id = _normalized_pkg_id_for_module(pkg.package_id, td.module_id)
				key = NominalKey(package_id=pkg_id, module_id=td.module_id, name=td.name, kind=TypeKind.STRUCT)
				pkg_struct_ids.setdefault(key, []).append(tid)
		for key, (field_schemas, type_params, base_id) in pkg.struct_schemas.items():
			candidates = pkg_struct_ids.get(key)
			if not candidates:
				raise ValueError(f"struct schema '{key.module_id}:{key.name}' missing STRUCT TypeDef in package type table")
			if base_id not in candidates:
				raise ValueError(f"struct schema '{key.module_id}:{key.name}' base_id missing in TypeDef table")
			base_def = pkg.defs.get(base_id)
			if base_def is None or base_def.kind is not TypeKind.STRUCT:
				raise ValueError(f"struct schema '{key.module_id}:{key.name}' base_id not a STRUCT TypeDef")
			if base_def.module_id != key.module_id or base_def.name != key.name:
				raise ValueError(f"struct schema '{key.module_id}:{key.name}' base_id mismatch")
			prev = merged_struct_schemas.get(key)
			if prev is None:
				merged_struct_schemas[key] = (list(field_schemas), list(type_params))
			elif prev != (list(field_schemas), list(type_params)):
				raise ValueError(f"struct schema collision for '{key.module_id}:{key.name}'")

	# Phase B: allocate/import host TypeIds in canonical order (no discovery dependence).
	key_to_host: dict[TypeKey, TypeId] = {}
	typevar_param_ids: dict[TypeKey, TypeParamId] = {}
	typevar_owner = FunctionId(module="lang.__external", name="__pkg_typevar", ordinal=0)
	typevar_index = 0

	def ensure_builtin(k: TypeKey) -> TypeId:
		_, kind_s, name = k
		name = _canonical_builtin_name(name)
		kind = TypeKind[kind_s]
		if kind is TypeKind.SCALAR:
			if name == "Int":
				return host.ensure_int()
			if name == "Uint":
				return host.ensure_uint()
			if name == "Uint64":
				return host.ensure_uint64()
			if name == "Byte":
				return host.ensure_byte()
			if name == "Bool":
				return host.ensure_bool()
			if name == "Float":
				return host.ensure_float()
			if name == "String":
				return host.ensure_string()
		if kind is TypeKind.VOID:
			return host.ensure_void()
		if kind is TypeKind.ERROR and name == "Error":
			return host.ensure_error()
		if kind is TypeKind.DIAGNOSTICVALUE and name == "DiagnosticValue":
			return host.ensure_diagnostic_value()
		if kind is TypeKind.UNKNOWN and name == "Unknown":
			return host.ensure_unknown()
		raise ValueError(f"unsupported builtin type in package: {k!r}")

	# Declare nominal types deterministically.
	nominal_keys: list[NominalKey] = []
	nominal_keys.extend(list(merged_struct_schemas.keys()))
	nominal_keys.extend(list(merged_variant_schemas.keys()))
	for pkg in pkgs:
		for _tid, td in pkg.defs.items():
			if td.kind is TypeKind.SCALAR and _builtin_type_id(host, td) is None:
				nominal_keys.append(
					NominalKey(
						package_id=_normalized_pkg_id_for_module(pkg.package_id, td.module_id),
						module_id=td.module_id,
						name=td.name,
						kind=TypeKind.SCALAR,
					)
				)
	nominal_keys = sorted(
		set(nominal_keys),
		key=lambda nk: (nk.package_id or "", nk.module_id or "", nk.kind.name, nk.name),
	)

	for nk in nominal_keys:
		mid = nk.module_id or ""
		if nk.kind is TypeKind.STRUCT:
			field_schemas, type_params = merged_struct_schemas[nk]
			field_names = [f.name for f in field_schemas]
			prev = host.struct_schemas.get(nk)
			if prev is not None:
				_h_name, h_fields = prev
				if list(h_fields) != list(field_names):
					raise ValueError(f"struct field name mismatch for '{mid}:{nk.name}'")
				base_id = host.get_struct_base(module_id=mid, name=nk.name)
				if base_id is not None:
					schema = host.struct_bases.get(base_id)
					if schema is not None and list(schema.type_params) != list(type_params):
						raise ValueError(f"struct type parameter mismatch for '{mid}:{nk.name}'")
			else:
				host.declare_struct(mid, nk.name, list(field_names), list(type_params))
		elif nk.kind is TypeKind.VARIANT:
			schema = merged_variant_schemas[nk]
			host_base = host.get_variant_base(module_id=schema.module_id, name=schema.name)
			if host_base is not None:
				host_schema = host.get_variant_schema(host_base)
				if host_schema is None or host_schema != schema:
					raise ValueError(f"variant schema collision for '{schema.module_id}:{schema.name}'")
			else:
				host.declare_variant(schema.module_id, schema.name, schema.type_params, schema.arms)
		elif nk.kind is TypeKind.SCALAR:
			host.declare_scalar(nk.module_id or "", nk.name)

	# Seed nominal keys into key_to_host.
	for nk in nominal_keys:
		mid = nk.module_id or ""
		if nk.kind is TypeKind.STRUCT:
			key_to_host[("nominal", TypeKind.STRUCT.name, nk.package_id or "", mid, nk.name)] = host.require_nominal(
				kind=TypeKind.STRUCT,
				module_id=mid,
				name=nk.name,
			)
		elif nk.kind is TypeKind.VARIANT:
			key_to_host[("nominal", TypeKind.VARIANT.name, nk.package_id or "", mid, nk.name)] = host.require_nominal(
				kind=TypeKind.VARIANT,
				module_id=mid,
				name=nk.name,
			)
		elif nk.kind is TypeKind.SCALAR:
			key_to_host[("nominal", TypeKind.SCALAR.name, nk.package_id or "", mid, nk.name)] = host.require_nominal(
				kind=TypeKind.SCALAR,
				module_id=nk.module_id,
				name=nk.name,
			)

	all_keys: set[TypeKey] = set()
	for tid_keys in pkg_tid_to_key:
		all_keys.update(tid_keys.values())

	def depth_of_key(k: TypeKey, memo: dict[TypeKey, int]) -> int:
		if k in memo:
			return memo[k]
		tag = k[0]
		if tag in ("builtin", "nominal"):
			memo[k] = 0
			return 0
		if tag == "typevar":
			memo[k] = 0
			return 0
		if tag == "inst":
			base_key = k[1]
			arg_keys = k[2]
			d = 1 + max([depth_of_key(base_key, memo)] + [depth_of_key(x, memo) for x in arg_keys])
			memo[k] = d
			return d
		sub: list[TypeKey] = []
		if tag == "array":
			sub = [k[1]]
		elif tag == "ref":
			sub = [k[2]]
		elif tag == "fnresult":
			sub = [k[1], k[2]]
		elif tag == "function":
			sub = list(k[2])
		elif tag == "kind":
			sub = list(k[3])
		d = 1 + max([depth_of_key(x, memo) for x in sub], default=0)
		memo[k] = d
		return d

	depth_memo: dict[TypeKey, int] = {}
	remaining_keys = [k for k in all_keys if k not in key_to_host]
	remaining_keys.sort(key=lambda k: (depth_of_key(k, depth_memo), k))

	for k in remaining_keys:
		tag = k[0]
		if tag == "builtin":
			key_to_host[k] = ensure_builtin(k)
		elif tag == "nominal":
			# Must have been seeded by nominal_keys.
			if k not in key_to_host:
				_kind, kind_s, _pkg_id, mid, name = k
				key_to_host[k] = host.require_nominal(kind=TypeKind[kind_s], module_id=(mid or None), name=name)
		elif tag == "array":
			key_to_host[k] = host.new_array(key_to_host[k[1]])
		elif tag == "ref":
			is_mut = bool(k[1])
			inner = key_to_host[k[2]]
			key_to_host[k] = host.ensure_ref_mut(inner) if is_mut else host.ensure_ref(inner)
		elif tag == "fnresult":
			ok = key_to_host[k[1]]
			err = key_to_host[k[2]]
			key_to_host[k] = host.ensure_fnresult(ok, err)
		elif tag == "function":
			can_throw = bool(k[1])
			pts = [key_to_host[x] for x in k[2]]
			if not pts:
				raise ValueError("invalid function type key (no return type)")
			key_to_host[k] = host.ensure_function(pts[:-1], pts[-1], can_throw=can_throw)
		elif tag == "inst":
			base_tid = key_to_host[k[1]]
			args = [key_to_host[x] for x in list(k[2])]
			base_key = k[1]
			kind_s = base_key[1] if isinstance(base_key, tuple) and len(base_key) > 1 else ""
			if kind_s == TypeKind.STRUCT.name:
				if any(host.has_typevar(arg) for arg in args):
					key_to_host[k] = host.ensure_struct_template(base_tid, args)
				else:
					key_to_host[k] = host.ensure_struct_instantiated(base_tid, args)
			else:
				if any(host.has_typevar(arg) for arg in args):
					key_to_host[k] = host.ensure_variant_template(base_tid, args)
				else:
					key_to_host[k] = host.ensure_variant_instantiated(base_tid, args)
		elif tag == "typevar":
			param_id = typevar_param_ids.get(k)
			if param_id is None:
				if isinstance(k[2], tuple) and k[2] and k[2][0] == "owner":
					_owner_tag, mod, name, ordinal = k[2]
					owner = FunctionId(module=str(mod), name=str(name), ordinal=int(ordinal))
					param_id = TypeParamId(owner=owner, index=int(k[3]))
				else:
					param_id = TypeParamId(typevar_owner, typevar_index)
					typevar_index += 1
				typevar_param_ids[k] = param_id
			display_entry = typevar_display_names.get(k)
			display_name = display_entry[1] if display_entry is not None else None
			key_to_host[k] = host.ensure_typevar(param_id, name=display_name)
		else:
			raise ValueError(f"unsupported type key in package linker: {k!r}")

	# Finalize struct field types deterministically (names + types).
	for nk in sorted(merged_struct_schemas.keys(), key=lambda k: (k.package_id or "", k.module_id or "", k.name)):
		mid = nk.module_id or ""
		host_tid = host.require_nominal(kind=TypeKind.STRUCT, module_id=mid, name=nk.name)
		h_td = host.get(host_tid)
		if h_td.kind is not TypeKind.STRUCT:
			raise ValueError(f"expected STRUCT for '{mid}:{nk.name}' after import")
		field_schemas, type_params = merged_struct_schemas[nk]
		# If host struct already had field types defined, require exact match.
		host.define_struct_schema_fields(host_tid, list(field_schemas))
		if not type_params:
			field_types = [
				host._eval_generic_type_expr(f.type_expr, [], module_id=mid) for f in field_schemas
			]
			if any(t != host.ensure_unknown() for t in h_td.param_types):
				if list(h_td.param_types) != field_types:
					raise ValueError(f"struct field type mismatch for '{mid}:{nk.name}'")
			else:
				host.define_struct_fields(host_tid, field_types)

	# Ensure non-generic variants have concrete instances available.
	host.finalize_variants()

	# Phase C: per-package tid maps.
	out_maps: list[dict[TypeId, TypeId]] = []
	for tid_keys in pkg_tid_to_key:
		m: dict[TypeId, TypeId] = {}
		for tid, k in tid_keys.items():
			host_tid = key_to_host.get(k)
			if host_tid is None:
				raise ValueError(f"failed to map package TypeId {tid} to host TypeId (key {k!r})")
			m[tid] = host_tid
		out_maps.append(m)
	return out_maps
