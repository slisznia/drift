[==== FILE LIST ====]
staged/lang2/driftc/parser/__init__.py
staged/lang2/driftc/traits/enforce.py
staged/lang2/driftc/traits/solver.py
staged/lang2/driftc/traits/world.py
staged/lang2/driftc/type_checker.py
staged/lang2/tests/core/test_type_subst.py
staged/lang2/tests/traits/tests/test_trait_world.py
staged/lang2/tests/type_checker/tests/test_type_checker_expressions.py
staged/work/generics-support/work-progress.md


[==== File: staged/lang2/driftc/parser/__init__.py =====]
"""
lang2 parser copy (self-contained, no runtime dependency on lang/).
Parses Drift source and adapts to lang2.driftc.stage0 AST + FnSignatures for the
lang2 pipeline.
"""

from __future__ import annotations

from pathlib import Path
from dataclasses import replace
from typing import Callable, Dict, Tuple, Optional, List

from lark.exceptions import UnexpectedInput

from . import parser as _parser
from . import ast as parser_ast
from lang2.driftc.stage0 import ast as s0
from lang2.driftc.stage1 import AstToHIR
from lang2.driftc import stage1 as H
from lang2.driftc.checker import FnSignature
from lang2.driftc.core.diagnostics import Diagnostic
from lang2.driftc.core.span import Span
from lang2.driftc.core.types_core import TypeKind
from lang2.driftc.core.event_codes import event_code, PAYLOAD_MASK
from lang2.driftc.core.function_id import FunctionId
from lang2.driftc.core.types_core import (
	TypeTable,
	VariantArmSchema,
	VariantFieldSchema,
)
from lang2.driftc.core.type_resolve_common import resolve_opaque_type
from lang2.driftc.core.generic_type_expr import GenericTypeExpr


def _qualify_fn_name(module_id: str, name: str) -> str:
	# MVP: symbols in the default `main` module remain unqualified so single-module
	# programs keep legacy names. Other modules are qualified as `module::name`.
	if module_id in (None, "main"):
		return name
	return f"{module_id}::{name}"


def _validate_module_id(mid: str, *, span: Span) -> list[Diagnostic]:
	"""
	Validate a module id per the language spec (format + reserved prefixes).

	This is shared by:
	- single-module builds (`parse_drift_files_to_hir`), and
	- workspace builds (`parse_drift_workspace_to_hir`), including inferred ids
	  from `-M/--module-path`.
	"""
	if not isinstance(mid, str) or not mid:
		return [
			Diagnostic(
				message="invalid module id (empty)",
				severity="error",
				span=span,
			)
		]
	raw_len = len(mid.encode("utf-8"))
	if raw_len > 254:
		return [
			Diagnostic(
				message=f"invalid module id '{mid}': length {raw_len} exceeds 254 UTF-8 bytes",
				severity="error",
				span=span,
			)
		]
	# Reserved module namespaces. Only the dotted namespace prefixes are reserved
	# (e.g. `std.foo`), not the bare segment itself (e.g. `lib` is allowed).
	forbidden_prefixes = ("lang", "abi", "std", "core", "lib")
	for pfx in forbidden_prefixes:
		if mid.startswith(pfx + "."):
			return [
				Diagnostic(
					message=f"invalid module id '{mid}': reserved prefix '{pfx}' is not allowed",
					severity="error",
					span=span,
				)
			]
	if mid.startswith(".") or mid.endswith(".") or ".." in mid:
		return [
			Diagnostic(
				message=f"invalid module id '{mid}': dots must separate non-empty segments",
				severity="error",
				span=span,
			)
		]
	if mid.startswith("_") or mid.endswith("_") or "__" in mid:
		return [
			Diagnostic(
				message=f"invalid module id '{mid}': underscores must not be leading/trailing or consecutive",
				severity="error",
				span=span,
			)
		]
	segments = mid.split(".")
	for seg in segments:
		if not seg:
			return [
				Diagnostic(
					message=f"invalid module id '{mid}': empty segment",
					severity="error",
					span=span,
				)
			]
		if seg.startswith("_") or seg.endswith("_") or "__" in seg:
			return [
				Diagnostic(
					message=f"invalid module id '{mid}': segment '{seg}' has invalid underscore placement",
					severity="error",
					span=span,
				)
			]
		# MVP: segments must start with a lowercase letter to avoid ambiguous module
		# names and to keep directory→module inference predictable.
		if not ("a" <= seg[0] <= "z"):
			return [
				Diagnostic(
					message=f"invalid module id '{mid}': segment '{seg}' must start with a lowercase letter",
					severity="error",
					span=span,
				)
			]
		for ch in seg:
			if not (("a" <= ch <= "z") or ("0" <= ch <= "9") or ch == "_"):
				return [
					Diagnostic(
						message=f"invalid module id '{mid}': segment '{seg}' contains invalid character '{ch}'",
						severity="error",
						span=span,
					)
				]
	return []


def _format_span_short(span: Span) -> str:
	"""
	Format a span as `file:line:column` for use in `Diagnostic.notes`.

	Notes are currently plain strings (no secondary-span support), so we keep the
	format stable and human-oriented.
	"""
	f = span.file or "<unknown>"
	l = span.line if span.line is not None else "?"
	c = span.column if span.column is not None else "?"
	return f"{f}:{l}:{c}"


def _prime_builtins(table: TypeTable) -> None:
	"""
	Ensure builtin TypeIds exist and are seeded in a stable order.

	This is required for package embedding in Milestone 4: until TypeId remapping
	exists, independently-produced artifacts must agree on builtin ids.
	"""
	table.ensure_unknown()
	table.ensure_int()
	table.ensure_uint()
	table.ensure_bool()
	table.ensure_float()
	table.ensure_string()
	table.ensure_void()
	table.ensure_error()
	table.ensure_diagnostic_value()
	# Seed commonly used derived types so TypeIds are stable across builds.
	#
	# MVP: DV accessors return Optional<Int/Bool/String>, so we ensure those
	# instantiations exist even if a particular module doesn't use them directly.
	table.new_optional(table.ensure_int())
	table.new_optional(table.ensure_bool())
	table.new_optional(table.ensure_string())


def _type_expr_to_str(typ: parser_ast.TypeExpr) -> str:
	"""Render a TypeExpr into a string (e.g., Array<Int>, Result<Int, Error>)."""
	if not typ.args:
		return typ.name
	args = ", ".join(_type_expr_to_str(a) for a in typ.args)
	return f"{typ.name}<{args}>"


def _type_expr_key(typ: parser_ast.TypeExpr) -> tuple[object | None, str, tuple]:
	qual = getattr(typ, "module_id", None) or getattr(typ, "module_alias", None)
	return (qual, typ.name, tuple(_type_expr_key(a) for a in getattr(typ, "args", []) or []))


def _type_expr_key_str(typ: parser_ast.TypeExpr) -> str:
	qual = getattr(typ, "module_id", None) or getattr(typ, "module_alias", None)
	base = f"{qual}.{typ.name}" if qual else typ.name
	if not (getattr(typ, "args", []) or []):
		return base
	args = ", ".join(_type_expr_key_str(a) for a in getattr(typ, "args", []) or [])
	return f"{base}<{args}>"


def _generic_type_expr_from_parser(
	typ: parser_ast.TypeExpr,
	*,
	type_params: list[str],
) -> GenericTypeExpr:
	"""
	Convert a parser `TypeExpr` into a generic-aware core `GenericTypeExpr`.

	This is used for schema-bearing declarations (variants) where field types may
	refer to generic parameters (e.g. `Some(value: T)`).
	"""
	if typ.name in type_params and not typ.args:
		return GenericTypeExpr.param(type_params.index(typ.name))
	return GenericTypeExpr.named(
		typ.name,
		[_generic_type_expr_from_parser(a, type_params=type_params) for a in getattr(typ, "args", [])],
		module_id=getattr(typ, "module_id", None),
	)


def _convert_expr(expr: parser_ast.Expr) -> s0.Expr:
	"""Convert parser AST expressions into lang2.driftc.stage0 AST expressions."""
	if isinstance(expr, parser_ast.Literal):
		return s0.Literal(value=expr.value, loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.Name):
		return s0.Name(ident=expr.ident, loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.TraitIs):
		return s0.TraitIs(
			subject=expr.subject,
			trait=expr.trait,
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.TraitAnd):
		return s0.TraitAnd(
			left=_convert_expr(expr.left),
			right=_convert_expr(expr.right),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.TraitOr):
		return s0.TraitOr(
			left=_convert_expr(expr.left),
			right=_convert_expr(expr.right),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.TraitNot):
		return s0.TraitNot(
			expr=_convert_expr(expr.expr),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.Lambda):
		params = [
			s0.Param(
				name=p.name,
				type_expr=p.type_expr,
				non_escaping=getattr(p, "non_escaping", False),
				loc=Span.from_loc(getattr(p, "loc", None)),
			)
			for p in expr.params
		]
		body_expr = _convert_expr(expr.body_expr) if expr.body_expr is not None else None
		body_block = s0.Block(statements=_convert_block(expr.body_block)) if expr.body_block is not None else None
		return s0.Lambda(
			params=params,
			ret_type=getattr(expr, "ret_type", None),
			body_expr=body_expr,
			body_block=body_block,
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.Call):
		return s0.Call(
			func=_convert_expr(expr.func),
			args=[_convert_expr(a) for a in expr.args],
			kwargs=[
				s0.KwArg(
					name=kw.name,
					value=_convert_expr(kw.value),
					loc=Span.from_loc(getattr(kw, "loc", None)),
				)
				for kw in getattr(expr, "kwargs", [])
			],
			type_args=getattr(expr, "type_args", None),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.Attr):
		# Member-through-reference access (`p->field`) is normalized at the
		# parser→stage0 boundary by inserting an explicit deref.
		#
		# This keeps stage0/stage1 ASTs simple: later phases only need normal
		# member access plus unary deref (`*p`).
		base = _convert_expr(expr.value)
		if getattr(expr, "op", ".") == "->":
			base = s0.Unary(op="*", operand=base, loc=Span.from_loc(getattr(expr.value, "loc", None)))
		return s0.Attr(value=base, attr=expr.attr, loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.QualifiedMember):
		return s0.QualifiedMember(
			base_type_expr=expr.base_type,
			member=expr.member,
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.Index):
		return s0.Index(
			value=_convert_expr(expr.value),
			index=_convert_expr(expr.index),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.Binary):
		return s0.Binary(
			op=expr.op,
			left=_convert_expr(expr.left),
			right=_convert_expr(expr.right),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.Unary):
		return s0.Unary(op=expr.op, operand=_convert_expr(expr.operand), loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.ArrayLiteral):
		return s0.ArrayLiteral(elements=[_convert_expr(e) for e in expr.elements], loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.Move):
		return s0.Move(value=_convert_expr(expr.value), loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.Placeholder):
		return s0.Placeholder(loc=Span.from_loc(getattr(expr, "loc", None)))
	if isinstance(expr, parser_ast.Ternary):
		return s0.Ternary(
			cond=_convert_expr(expr.condition),
			then_expr=_convert_expr(expr.then_value),
			else_expr=_convert_expr(expr.else_value),
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.TryCatchExpr):
		catch_arms = [
			s0.CatchExprArm(
				event=arm.event,
				binder=arm.binder,
				block=_convert_block(arm.block),
				loc=Span.from_loc(getattr(arm, "loc", None)),
			)
			for arm in expr.catch_arms
		]
		return s0.TryCatchExpr(
			attempt=_convert_expr(expr.attempt),
			catch_arms=catch_arms,
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.MatchExpr):
		arms = [
			s0.MatchArm(
				ctor=arm.ctor,
				pattern_arg_form=getattr(arm, "pattern_arg_form", "positional"),
				binders=list(arm.binders),
				binder_fields=list(arm.binder_fields) if getattr(arm, "binder_fields", None) is not None else None,
				block=_convert_block(arm.block),
				loc=Span.from_loc(getattr(arm, "loc", None)),
			)
			for arm in expr.arms
		]
		return s0.MatchExpr(
			scrutinee=_convert_expr(expr.scrutinee),
			arms=arms,
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.ExceptionCtor):
		return s0.ExceptionCtor(
			name=expr.name,
			args=[_convert_expr(a) for a in expr.args],
			kwargs=[
				s0.KwArg(
					name=kw.name,
					value=_convert_expr(kw.value),
					loc=Span.from_loc(getattr(kw, "loc", None)),
				)
				for kw in expr.kwargs
			],
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	if isinstance(expr, parser_ast.FString):
		return s0.FString(
			parts=list(expr.parts),
			holes=[
				s0.FStringHole(
					expr=_convert_expr(h.expr),
					spec=h.spec,
					loc=Span.from_loc(getattr(h, "loc", None)),
				)
				for h in expr.holes
			],
			loc=Span.from_loc(getattr(expr, "loc", None)),
		)
	raise NotImplementedError(f"Unsupported expression in adapter: {expr!r}")


def _convert_return(stmt: parser_ast.ReturnStmt) -> s0.Stmt:
	return s0.ReturnStmt(value=_convert_expr(stmt.value) if stmt.value is not None else None, loc=Span.from_loc(stmt.loc))


def _convert_expr_stmt(stmt: parser_ast.ExprStmt) -> s0.Stmt:
	return s0.ExprStmt(expr=_convert_expr(stmt.value), loc=Span.from_loc(stmt.loc))


def _convert_let(stmt: parser_ast.LetStmt) -> s0.Stmt:
	return s0.LetStmt(
		name=stmt.name,
		value=_convert_expr(stmt.value),
		type_expr=getattr(stmt, "type_expr", None),
		mutable=bool(getattr(stmt, "mutable", False)),
		loc=Span.from_loc(stmt.loc),
	)


def _convert_assign(stmt: parser_ast.AssignStmt) -> s0.Stmt:
	return s0.AssignStmt(target=_convert_expr(stmt.target), value=_convert_expr(stmt.value), loc=Span.from_loc(stmt.loc))


def _convert_aug_assign(stmt: "parser_ast.AugAssignStmt") -> s0.Stmt:
	"""
	Convert an augmented assignment statement.

	MVP supports:
	`+=`, `-=`, `*=`, `/=`, `%=`, `&=`, `|=`, `^=`, `<<=`, `>>=`.

	We preserve this as a distinct stage0 statement so later lowering can
	implement correct read-modify-write semantics for complex lvalues.
	"""
	return s0.AugAssignStmt(
		target=_convert_expr(stmt.target),
		op=str(getattr(stmt, "op", "+=")),
		value=_convert_expr(stmt.value),
		loc=Span.from_loc(stmt.loc),
	)

def _convert_if(stmt: parser_ast.IfStmt) -> s0.Stmt:
	return s0.IfStmt(
		cond=_convert_expr(stmt.condition),
		then_block=_convert_block(stmt.then_block),
		else_block=_convert_block(stmt.else_block) if stmt.else_block else [],
		loc=Span.from_loc(stmt.loc),
	)


def _convert_break(stmt: parser_ast.BreakStmt) -> s0.Stmt:
	return s0.BreakStmt(loc=Span.from_loc(stmt.loc))


def _convert_continue(stmt: parser_ast.ContinueStmt) -> s0.Stmt:
	return s0.ContinueStmt(loc=Span.from_loc(stmt.loc))


def _convert_while(stmt: parser_ast.WhileStmt) -> s0.Stmt:
	return s0.WhileStmt(cond=_convert_expr(stmt.condition), body=_convert_block(stmt.body), loc=Span.from_loc(stmt.loc))


def _convert_for(stmt: parser_ast.ForStmt) -> s0.Stmt:
	return s0.ForStmt(iter_var=stmt.var, iterable=_convert_expr(stmt.iter_expr), body=_convert_block(stmt.body), loc=Span.from_loc(stmt.loc))


def _convert_throw(stmt: parser_ast.ThrowStmt) -> s0.Stmt:
	return s0.ThrowStmt(value=_convert_expr(stmt.expr), loc=Span.from_loc(stmt.loc))


def _convert_raise(stmt: parser_ast.RaiseStmt) -> s0.Stmt:
	# TODO: when rethrow semantics are defined, map RaiseStmt appropriately.
	# For now, treat parser RaiseStmt as a plain throw of the expression.
	expr = getattr(stmt, "expr", None) or getattr(stmt, "value")
	return s0.ThrowStmt(value=_convert_expr(expr), loc=Span.from_loc(stmt.loc))


def _convert_rethrow(stmt: parser_ast.RethrowStmt) -> s0.Stmt:
	return s0.RethrowStmt(loc=Span.from_loc(stmt.loc))


def _convert_try(stmt: parser_ast.TryStmt) -> s0.Stmt:
	catches = [
		s0.CatchExprArm(
			event=c.event,
			binder=c.binder,
			block=_convert_block(c.block),
			loc=Span.from_loc(getattr(c, "loc", None)),
		)
		for c in stmt.catches
	]
	return s0.TryStmt(body=_convert_block(stmt.body), catches=catches, loc=Span.from_loc(stmt.loc))


def _convert_import(stmt: parser_ast.ImportStmt) -> s0.Stmt:
	path = ".".join(stmt.path)
	return s0.ImportStmt(path=path, loc=Span.from_loc(stmt.loc))


_STMT_DISPATCH: dict[type[parser_ast.Stmt], Callable[[parser_ast.Stmt], s0.Stmt]] = {
	parser_ast.ReturnStmt: _convert_return,
	parser_ast.ExprStmt: _convert_expr_stmt,
	parser_ast.LetStmt: _convert_let,
	parser_ast.AssignStmt: _convert_assign,
	parser_ast.AugAssignStmt: _convert_aug_assign,
	parser_ast.IfStmt: _convert_if,
	parser_ast.BreakStmt: _convert_break,
	parser_ast.ContinueStmt: _convert_continue,
	parser_ast.WhileStmt: _convert_while,
	parser_ast.ForStmt: _convert_for,
	parser_ast.ThrowStmt: _convert_throw,
	parser_ast.RaiseStmt: _convert_raise,
	parser_ast.RethrowStmt: _convert_rethrow,
	parser_ast.TryStmt: _convert_try,
	parser_ast.ImportStmt: _convert_import,
}


def _convert_stmt(stmt: parser_ast.Stmt) -> s0.Stmt:
	"""Convert parser AST statements into lang2.driftc.stage0 AST statements."""
	fn = _STMT_DISPATCH.get(type(stmt))
	if fn is None:
		raise NotImplementedError(f"Unsupported statement in adapter: {stmt!r}")
	return fn(stmt)


def _convert_block(block: parser_ast.Block) -> list[s0.Stmt]:
	return [_convert_stmt(s) for s in block.statements]


class _FrontendParam:
	def __init__(
		self,
		name: str,
		type_expr: parser_ast.TypeExpr | None,
		loc: Optional[parser_ast.Located],
		*,
		non_escaping: bool = False,
	) -> None:
		self.name = name
		# Preserve the parsed type expression so the resolver can build real TypeIds.
		self.type = type_expr
		self.loc = loc
		self.non_escaping = non_escaping


class _FrontendDecl:
	def __init__(
		self,
		fn_id: FunctionId,
		name: str,
		method_name: Optional[str],
		type_params: list[str],
		type_param_locs: list[parser_ast.Located],
		params: list[_FrontendParam],
		return_type: parser_ast.TypeExpr,
		loc: Optional[parser_ast.Located],
		is_method: bool = False,
		self_mode: Optional[str] = None,
		impl_target: Optional[parser_ast.TypeExpr] = None,
		module: Optional[str] = None,
	) -> None:
		self.fn_id = fn_id
		self.name = name
		self.method_name = method_name
		self.type_params = type_params
		self.type_param_locs = type_param_locs
		self.params = params
		self.return_type = return_type
		self.throws = ()
		self.loc = loc
		self.is_extern = False
		self.is_intrinsic = False
		self.is_method = is_method
		self.self_mode = self_mode
		self.impl_target = impl_target
		self.module = module


def _decl_from_parser_fn(fn: parser_ast.FunctionDef, *, fn_id: FunctionId) -> _FrontendDecl:
	params = [
		_FrontendParam(
			p.name,
			p.type_expr,
			getattr(p, "loc", None),
			non_escaping=getattr(p, "non_escaping", False),
		)
		for p in fn.params
	]
	return _FrontendDecl(
		fn_id,
		fn.name,
		fn.orig_name,
		fn.type_params,
		list(getattr(fn, "type_param_locs", []) or []),
		params,
		fn.return_type,
		getattr(fn, "loc", None),
		fn.is_method,
		fn.self_mode,
		fn.impl_target,
	)


def _diagnostic(message: str, loc: object | None) -> Diagnostic:
	"""Helper to create a Diagnostic from a parser location."""
	return Diagnostic(message=message, severity="error", span=Span.from_loc(loc))


def _typeexpr_uses_internal_fnresult(typ: parser_ast.TypeExpr) -> bool:
	"""
	Return True if a surface type annotation mentions `FnResult` anywhere.

	`FnResult<T, Error>` is an internal ABI carrier used by lang2 for can-throw
	functions. It is not a surface type in the Drift language: user code should
	write `returns T` and use exceptions/try/catch for control flow.
	"""
	if typ.name == "FnResult":
		return True
	for arg in getattr(typ, "args", []) or []:
		if _typeexpr_uses_internal_fnresult(arg):
			return True
	return False


def _typeexpr_is_callable(typ: parser_ast.TypeExpr | None) -> bool:
	if typ is None:
		return False
	if typ.name in {"&", "&mut"} and getattr(typ, "args", None):
		return _typeexpr_is_callable(typ.args[0])
	return typ.name in {"Fn", "Callable"}


def _report_internal_fnresult_in_surface_type(
	*,
	kind: str,
	symbol: str,
	loc: object | None,
	diagnostics: list[Diagnostic],
) -> None:
	diagnostics.append(
		_diagnostic(
			f"{kind} '{symbol}' uses internal-only type 'FnResult' in a surface annotation; "
			"write `returns T` and use exceptions/try-catch instead",
			loc,
		)
	)


def _build_exception_catalog(exceptions: list[parser_ast.ExceptionDef], module_name: str | None, diagnostics: list[Diagnostic]) -> dict[str, int]:
	"""
	Assign deterministic event codes to exception declarations using the shared ABI hash.

	Collisions on the payload bits are reported as errors and the colliding
	exceptions are omitted from the catalog to avoid undefined dispatch.
	"""
	catalog: dict[str, int] = {}
	payload_seen: dict[int, str] = {}
	seen_names: set[str] = set()
	for exc in exceptions:
		if exc.name in seen_names:
			diagnostics.append(_diagnostic(f"duplicate exception '{exc.name}'", getattr(exc, "loc", None)))
			continue
		seen_names.add(exc.name)
		fqn = f"{module_name}:{exc.name}" if module_name else exc.name
		code = event_code(fqn)
		payload = code & PAYLOAD_MASK
		if payload in payload_seen and payload_seen[payload] != fqn:
			other = payload_seen[payload]
			diagnostics.append(
				_diagnostic(
					f"exception code collision between '{other}' and '{fqn}' (payload {payload})",
					getattr(exc, "loc", None),
				)
			)
			continue
		payload_seen[payload] = fqn
		catalog[fqn] = code
	return catalog


def _span_in_file(path: Path, loc: object | None) -> Span:
	"""
	Construct a Span that is anchored to a specific source file.

	The parser AST location objects do not carry a filename; for multi-file module
	builds we need the file to be explicit so diagnostics can point at the right
	origin.
	"""
	if loc is None:
		return Span(file=str(path))
	span = Span.from_loc(loc)
	if span.file is None:
		return Span(
			file=str(path),
			line=span.line,
			column=span.column,
			end_line=span.end_line,
			end_column=span.end_column,
			raw=span.raw,
		)
	return span


def _diag_duplicate(
	*,
	kind: str,
	name: str,
	first_path: Path,
	first_loc: object | None,
	second_path: Path,
	second_loc: object | None,
) -> list[Diagnostic]:
	"""
	Build a primary error + secondary note diagnostic for a cross-file duplicate.

	The error is pinned to the second definition; the note is pinned to the first.
	"""
	first_span = _span_in_file(first_path, first_loc)
	second_span = _span_in_file(second_path, second_loc)
	return [
		Diagnostic(
			message=f"duplicate {kind} definition for '{name}'",
			severity="error",
			span=second_span,
		),
		Diagnostic(
			message=f"previous definition of '{name}' is here",
			severity="note",
			span=first_span,
		),
	]


def parse_drift_files_to_hir(
	paths: list[Path],
) -> Tuple[Dict[FunctionId, H.HBlock], Dict[FunctionId, FnSignature], Dict[str, List[FunctionId]], "TypeTable", Dict[str, int], List[Diagnostic]]:
	"""
	Parse and lower a set of Drift source files into a single module unit.

	MVP (Milestone 1): accepts multiple files that all declare the same `module`
	id (or default to `main`). The module is lowered as if it were one merged file:
	- top-level declarations are combined,
	- cross-file collisions are diagnosed (with a pinned note pointing at the
	  first definition),
	- then the existing parser→stage0→HIR pipeline runs on the merged program.

	This does not implement cross-module imports yet; it only handles multiple
	files *within* the same module.
	"""
	diagnostics: list[Diagnostic] = []
	if not paths:
		return {}, {}, {}, TypeTable(), {}, [Diagnostic(message="no input files", severity="error")]

	programs: list[tuple[Path, parser_ast.Program]] = []
	for path in paths:
		source = path.read_text()
		try:
			prog = _parser.parse_program(source)
		except _parser.ModuleDeclError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc)))
			continue
		except _parser.QualifiedMemberParseError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc)))
			continue
		except _parser.FStringParseError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc)))
			continue
		except UnexpectedInput as err:
			span = Span(
				file=str(path),
				line=getattr(err, "line", None),
				column=getattr(err, "column", None),
				raw=err,
			)
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=span))
			continue
		programs.append((path, prog))

	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, diagnostics

	# Enforce single-module membership across the file set.
	def _effective_module_id(p: parser_ast.Program) -> str:
		return getattr(p, "module", None) or "main"

	module_id = _effective_module_id(programs[0][1])
	for path, prog in programs:
		mid = _effective_module_id(prog)
		decl_span = _span_in_file(path, getattr(prog, "module_loc", None))
		diagnostics.extend(_validate_module_id(mid, span=decl_span))
	for path, prog in programs[1:]:
		mid = _effective_module_id(prog)
		if mid != module_id:
			diagnostics.append(
				Diagnostic(
					message=f"module id mismatch: expected '{module_id}', found '{mid}'",
					severity="error",
					span=Span(file=str(path), line=1, column=1),
				)
			)
	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, diagnostics

	merged, _origins = _merge_module_files(module_id, programs, diagnostics)

	# Lower the merged program using the existing single-file pipeline.
	return _lower_parsed_program_to_hir(merged, diagnostics=diagnostics)


def _merge_module_files(
	module_id: str,
	files: list[tuple[Path, parser_ast.Program]],
	diagnostics: list[Diagnostic],
) -> tuple[parser_ast.Program, dict[FunctionId, Path]]:
	"""
	Merge a module's file set into a single parser AST `Program` (Milestone 1 rule set).

	This is the single source of truth for “multi-file module” merge behavior.
	Both `parse_drift_files_to_hir` (single-module build) and the workspace loader
	(Milestone 2) must call this helper to avoid drift.
	"""
	merged = parser_ast.Program(module=module_id)
	# Provenance map for module-local callable symbols (free functions and methods).
	#
	# Used by the workspace loader to implement per-file import environments:
	# we need to know which source file a given function body came from so we can
	# apply that file's imports while rewriting call sites.
	origin_by_fn_id: dict[FunctionId, Path] = {}

	first_fn_sig: dict[tuple, tuple[Path, object | None]] = {}
	name_ord: dict[str, int] = {}
	free_names: set[str] = set()
	for path, prog in files:
		for fn in getattr(prog, "functions", []) or []:
			sig_key = (
				fn.name,
				len(getattr(fn, "params", []) or []),
				tuple(_type_expr_key(p.type_expr) for p in getattr(fn, "params", []) or []),
			)
			if sig_key in first_fn_sig:
				first_path, first_loc = first_fn_sig[sig_key]
				diagnostics.extend(
					_diag_duplicate(
						kind="function",
						name=fn.name,
						first_path=first_path,
						first_loc=first_loc,
						second_path=path,
						second_loc=getattr(fn, "loc", None),
					)
				)
				continue
			first_fn_sig[sig_key] = (path, getattr(fn, "loc", None))
			free_names.add(fn.name)
			merged.functions.append(fn)
			ordinal = name_ord.get(fn.name, 0)
			name_ord[fn.name] = ordinal + 1
			fn_id = FunctionId(module=module_id, name=fn.name, ordinal=ordinal)
			origin_by_fn_id.setdefault(fn_id, path)

	first_const: dict[str, tuple[Path, object | None]] = {}
	for path, prog in files:
		for c in getattr(prog, "consts", []) or []:
			if c.name in first_const:
				first_path, first_loc = first_const[c.name]
				diagnostics.extend(
					_diag_duplicate(
						kind="const",
						name=c.name,
						first_path=first_path,
						first_loc=first_loc,
						second_path=path,
						second_loc=getattr(c, "loc", None),
					)
				)
				continue
			first_const[c.name] = (path, getattr(c, "loc", None))
			merged.consts.append(c)

	first_struct: dict[str, tuple[Path, object | None]] = {}
	for path, prog in files:
		for s in getattr(prog, "structs", []) or []:
			if s.name in first_struct:
				first_path, first_loc = first_struct[s.name]
				diagnostics.extend(
					_diag_duplicate(
						kind="struct",
						name=s.name,
						first_path=first_path,
						first_loc=first_loc,
						second_path=path,
						second_loc=getattr(s, "loc", None),
					)
				)
				continue
			first_struct[s.name] = (path, getattr(s, "loc", None))
			merged.structs.append(s)

	first_exc: dict[str, tuple[Path, object | None]] = {}
	for path, prog in files:
		for exc in getattr(prog, "exceptions", []) or []:
			if exc.name in first_exc:
				first_path, first_loc = first_exc[exc.name]
				diagnostics.extend(
					_diag_duplicate(
						kind="exception",
						name=exc.name,
						first_path=first_path,
						first_loc=first_loc,
						second_path=path,
						second_loc=getattr(exc, "loc", None),
					)
				)
				continue
			first_exc[exc.name] = (path, getattr(exc, "loc", None))
			merged.exceptions.append(exc)

	first_variant: dict[str, tuple[Path, object | None]] = {}
	for path, prog in files:
		for v in getattr(prog, "variants", []) or []:
			if v.name in first_variant:
				first_path, first_loc = first_variant[v.name]
				diagnostics.extend(
					_diag_duplicate(
						kind="variant",
						name=v.name,
						first_path=first_path,
						first_loc=first_loc,
						second_path=path,
						second_loc=getattr(v, "loc", None),
					)
				)
				continue
			first_variant[v.name] = (path, getattr(v, "loc", None))
			merged.variants.append(v)

	first_trait: dict[str, tuple[Path, object | None]] = {}
	for path, prog in files:
		for tr in getattr(prog, "traits", []) or []:
			if tr.name in first_trait:
				first_path, first_loc = first_trait[tr.name]
				diagnostics.extend(
					_diag_duplicate(
						kind="trait",
						name=tr.name,
						first_path=first_path,
						first_loc=first_loc,
						second_path=path,
						second_loc=getattr(tr, "loc", None),
					)
				)
				continue
			first_trait[tr.name] = (path, getattr(tr, "loc", None))
			merged.traits.append(tr)

	# Combine module directives (imports/exports).
	for _, prog in files:
		merged.imports.extend(getattr(prog, "imports", []) or [])
		merged.from_imports.extend(getattr(prog, "from_imports", []) or [])
		merged.exports.extend(getattr(prog, "exports", []) or [])

	# Merge implement blocks by target repr and de-duplicate methods.
	impls_by_key: dict[tuple[tuple | None, tuple], parser_ast.ImplementDef] = {}
	first_method: dict[tuple[tuple | None, tuple, str], tuple[Path, object | None]] = {}
	for path, prog in files:
		for impl in getattr(prog, "implements", []) or []:
			target_key = _type_expr_key(impl.target)
			target_str = _type_expr_key_str(impl.target)
			trait_key = _type_expr_key(impl.trait) if getattr(impl, "trait", None) is not None else None
			trait_str = _type_expr_key_str(impl.trait) if getattr(impl, "trait", None) is not None else None
			key = (trait_key, target_key)
			dst = impls_by_key.get(key)
			if dst is None:
				dst = parser_ast.ImplementDef(
					target=impl.target,
					trait=getattr(impl, "trait", None),
					require=getattr(impl, "require", None),
					loc=getattr(impl, "loc", None),
					methods=[],
				)
				impls_by_key[key] = dst
			elif getattr(dst, "require", None) != getattr(impl, "require", None):
				impl_label = f"{trait_str} for {target_str}" if trait_str else target_str
				diagnostics.append(
					Diagnostic(
						message=f"conflicting require clauses for implement block '{impl_label}'",
						severity="error",
						span=_span_in_file(path, getattr(impl, "loc", None)),
					)
				)
			for m in getattr(impl, "methods", []) or []:
				if m.name in free_names:
					first_path, _first_loc = first_fn[m.name]
					diagnostics.append(
						Diagnostic(
							message=f"method '{m.name}' conflicts with existing free function of the same name",
							severity="error",
							span=_span_in_file(path, getattr(m, "loc", None)),
							notes=[f"previous free function definition is in {first_path}"],
						)
					)
					continue
				method_key = (trait_key, target_key, m.name)
				if method_key in first_method:
					first_path, first_loc = first_method[method_key]
					impl_label = f"{trait_str} for {target_str}" if trait_str else target_str
					diagnostics.extend(
						_diag_duplicate(
							kind=f"method for type '{impl_label}'",
							name=m.name,
							first_path=first_path,
							first_loc=first_loc,
							second_path=path,
							second_loc=getattr(m, "loc", None),
						)
					)
					continue
				first_method[method_key] = (path, getattr(m, "loc", None))
				dst.methods.append(m)
				if trait_str:
					symbol_name = f"{target_str}::{trait_str}::{m.name}"
				else:
					symbol_name = f"{target_str}::{m.name}"
				ordinal = name_ord.get(symbol_name, 0)
				name_ord[symbol_name] = ordinal + 1
				fn_id = FunctionId(module=module_id, name=symbol_name, ordinal=ordinal)
				origin_by_fn_id.setdefault(fn_id, path)
	merged.implements = list(impls_by_key.values())
	return merged, origin_by_fn_id


def parse_drift_workspace_to_hir(
	paths: list[Path],
	*,
	module_paths: list[Path] | None = None,
	external_module_exports: dict[str, dict[str, object]] | None = None,
) -> Tuple[
	Dict[FunctionId, H.HBlock],
	Dict[FunctionId, FnSignature],
	Dict[str, List[FunctionId]],
	"TypeTable",
	Dict[str, int],
	Dict[str, Dict[str, object]],
	List[Diagnostic],
]:
	"""
	Parse and lower a set of Drift source files that may belong to multiple modules.

	This is Milestone 2 (“module imports and cross-module resolution”) scaffolding:
	- input is an unordered set of files (typically all `*.drift` files in a build),
	- files are grouped by their declared `module <id>` (or default to `main`),
	- each module is merged from its file set (Milestone 1 behavior),
	- imports are resolved across modules (MVP: `from <module> import <symbol>`),
	- resulting HIR/signatures are returned as a single program unit suitable for
	  the existing HIR→MIR→SSA→LLVM pipeline.

		Important MVP constraints (pinned for clarity):
		- Imports are treated as **per-file** bindings:
		  - Duplicate identical imports in one file are idempotent (“no-op after first”).
		  - Conflicting aliases/bindings in one file are diagnosed as errors.
		  - Different files may import the same module/symbol freely; the module is still
		    parsed/merged/compiled once per build and referenced from all import sites.
		- Module-qualified access (`import m` then `m.foo()`) is supported for calling
		  exported free functions and for struct constructor calls (`m.Point(...)`).
		- Cross-module import validation supports both value and type namespaces
		  (types: structs, variants, exceptions).

	Returns:
	  (func_hirs, signatures, fn_ids_by_name, type_table, exception_catalog, module_exports, diagnostics)
	"""
	diagnostics: list[Diagnostic] = []
	if not paths:
		return {}, {}, {}, TypeTable(), {}, {}, [Diagnostic(message="no input files", severity="error")]

	def _effective_module_id(p: parser_ast.Program) -> str:
		return getattr(p, "module", None) or "main"

	# Parse all files first.
	parsed: list[tuple[Path, parser_ast.Program]] = []
	for path in paths:
		source = path.read_text()
		try:
			prog = _parser.parse_program(source)
		except _parser.ModuleDeclError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc)))
			continue
		except _parser.QualifiedMemberParseError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc)))
			continue
		except _parser.FStringParseError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc)))
			continue
		except UnexpectedInput as err:
			span = Span(
				file=str(path),
				line=getattr(err, "line", None),
				column=getattr(err, "column", None),
				raw=err,
			)
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=span))
			continue
		parsed.append((path, prog))

	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	def _infer_module_id_from_paths(path: Path) -> tuple[str, Path] | tuple[None, None]:
		"""
		Infer the module id for a file from the configured module roots.

		Rule (MVP, pinned in work-progress):
		- find the first module root that is a prefix of the file's absolute path,
		- module id is derived from the directory relative to the root:
		  - empty relative path => "main"
		  - otherwise path segments joined by '.' (platform-independent).
		"""
		if not module_paths:
			return None, None
		abs_path = path.resolve()
		candidates: list[tuple[Path, Path]] = []
		for root in module_paths:
			abs_root = root.resolve()
			try:
				rel_dir = abs_path.parent.relative_to(abs_root)
			except ValueError:
				continue
			candidates.append((abs_root, rel_dir))

		if not candidates:
			return None, None

		# Deterministic root selection: pick the most-specific root (longest prefix).
		# This prevents module identity from depending on CLI flag ordering when roots
		# overlap (e.g. `-M src` and `-M src/vendor`).
		candidates.sort(key=lambda r: len(r[0].parts), reverse=True)
		best_len = len(candidates[0][0].parts)
		best = [c for c in candidates if len(c[0].parts) == best_len]
		if len(best) != 1:
			# Ambiguous configuration: multiple roots at the same specificity match
			# the same file.
			return None, None

		abs_root, rel_dir = best[0]
		parts = list(rel_dir.parts)
		if not parts or parts == ["."]:
			return "main", abs_root
		for seg in parts:
			if seg in {".", ".."}:
				return None, None
			if not seg:
				return None, None
		return ".".join(parts), abs_root

	# Group by module id (declared or inferred).
	by_module: dict[str, list[tuple[Path, parser_ast.Program]]] = {}
	roots_by_module: dict[str, set[Path]] = {}
	# For pinned diagnostics, keep at least one representative file per (module, root).
	root_file_by_module: dict[str, dict[Path, Path]] = {}
	for path, prog in parsed:
		if module_paths:
			inferred, root = _infer_module_id_from_paths(path)
			if inferred is None or root is None:
				diagnostics.append(
					Diagnostic(
						message=f"file '{path}' is not under exactly one configured module root",
						severity="error",
						span=Span(file=str(path), line=1, column=1),
					)
				)
				continue
			# Validate inferred id before using it as a module-graph key.
			diagnostics.extend(_validate_module_id(inferred, span=Span(file=str(path), line=1, column=1)))
			declared = getattr(prog, "module", None)
			if declared is not None:
				decl_span = _span_in_file(path, getattr(prog, "module_loc", None))
				diagnostics.extend(_validate_module_id(declared, span=decl_span))
				if any(d.severity == "error" for d in diagnostics):
					continue
				if declared != inferred:
					notes = [f"inferred module id is '{inferred}' from root '{root}'"]
					diagnostics.append(
						Diagnostic(
							message=f"module id mismatch: expected '{inferred}', found '{declared}'",
							severity="error",
							span=decl_span,
							notes=notes,
						)
					)
					continue
			# Treat missing module header as implicit declaration of the inferred id.
			if declared is None:
				prog = replace(prog, module=inferred)
			by_module.setdefault(inferred, []).append((path, prog))
			roots_by_module.setdefault(inferred, set()).add(root)
			root_file_by_module.setdefault(inferred, {}).setdefault(root, path)
		else:
			mid = _effective_module_id(prog)
			decl_span = _span_in_file(path, getattr(prog, "module_loc", None))
			diagnostics.extend(_validate_module_id(mid, span=decl_span))
			by_module.setdefault(mid, []).append((path, prog))

	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	# When module roots are used, reject ambiguous module ids coming from
	# multiple roots (prevents accidental shadowing/selection by search order).
	if module_paths:
		for mid, roots in roots_by_module.items():
			if len(roots) > 1:
				root_list = ", ".join(str(r) for r in sorted(roots))
				span_file = None
				# Anchor the diagnostic to a concrete file under one of the roots.
				for r in sorted(roots):
					span_file = root_file_by_module.get(mid, {}).get(r)
					if span_file is not None:
						break
				span = Span(file=str(span_file), line=1, column=1) if span_file else Span()
				diagnostics.append(
					Diagnostic(
						message=f"multiple module roots provide module '{mid}' ({root_list})",
						severity="error",
						span=span,
					)
				)
	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, {}, diagnostics
	# Merge each module (Milestone 1 rules) and retain callable provenance per file.
	merged_programs: dict[str, parser_ast.Program] = {}
	origin_by_module: dict[str, dict[FunctionId, Path]] = {}
	for mid, files in by_module.items():
		merged, origins = _merge_module_files(mid, files, diagnostics)
		merged_programs[mid] = merged
		origin_by_module[mid] = origins

	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	def _build_export_interface(
		*,
		module_id: str,
		merged_prog: parser_ast.Program,
		module_files: list[tuple[Path, parser_ast.Program]],
	) -> tuple[
		dict[str, tuple[str, str]],
		dict[str, set[str]],
		set[str],
		dict[str, Span],
		dict[str, tuple[str, str]],
		dict[str, tuple[tuple[str, str], tuple[str, str], Span, Span]],
	]:
		"""
		Build the exported interface for a module.

		MVP visibility model:
		- items are private by default,
		- `export { Name, ... }` lists the exported names,
		- both values and types may be exported, but in separate namespaces:
		  - values: free functions
		  - types: structs, variants, exceptions

		Because `export { ... }` syntax is unqualified, exporting a name that exists
		in both namespaces is ambiguous. Until we add explicit qualifiers, that is
		a compile-time error.

		Because `exports.types` is kind-separated (structs/variants/exceptions), an
		exported name that resolves to multiple type kinds is also a compile-time
		error.

		Spans are anchored to the source file that contained the `export { ... }`
		statement so diagnostics remain useful in multi-file modules.
		"""
		module_fn_names: set[str] = {fn.name for fn in getattr(merged_prog, "functions", []) or []}
		module_const_names: set[str] = {c.name for c in getattr(merged_prog, "consts", []) or []}
		module_struct_names: set[str] = {s.name for s in getattr(merged_prog, "structs", []) or []}
		module_variant_names: set[str] = {v.name for v in getattr(merged_prog, "variants", []) or []}
		module_exception_names: set[str] = {e.name for e in getattr(merged_prog, "exceptions", []) or []}

		raw_export_entries: list[tuple[str, Span]] = []
		for path, parsed_prog in module_files:
			for ex in getattr(parsed_prog, "exports", []) or []:
				ex_span = _span_in_file(path, getattr(ex, "loc", None))
				for n in getattr(ex, "names", []) or []:
					raw_export_entries.append((n, ex_span))

		# MVP rule: exporting the same name multiple times within a module is a
		# deterministic user error (even if it would be a no-op). We treat it as a
		# duplicate declaration so the module interface remains crisp and tooling
		# never has to guess which export site is authoritative.
		seen_export_names: dict[str, Span] = {}

		# Exported values map exported local name -> underlying (module_id, symbol).
		#
		# This enables a minimal re-export mechanism without introducing a new
		# surface syntax yet:
		#
		#   from other.module import foo
		#   export { foo }
		#
		# Export entries always name symbols in the *current* module interface
		# (e.g., `a::foo`). When `foo` is re-exported (implemented by another module),
		# the workspace loader materializes a trampoline function `a::foo` that
		# forwards to the underlying target `other.module::foo`.
		exported_values: dict[str, tuple[str, str]] = {}
		exported_types: dict[str, set[str]] = {"structs": set(), "variants": set(), "exceptions": set()}
		exported_consts: set[str] = set()
		pending_reexports: dict[str, Span] = {}

		# Collect re-export candidates from `from <module> import <symbol> [as alias]`
		# statements across files in the module. Imports are per-file, but exports
		# are module-level; to keep export resolution deterministic we require that
		# any *exported* imported binding be unambiguous across the module.
		reexport_candidates: dict[str, tuple[str, str]] = {}
		reexport_first_span: dict[str, Span] = {}
		reexport_conflicts: dict[str, tuple[tuple[str, str], tuple[str, str], Span, Span]] = {}
		for path, parsed_prog in module_files:
			for imp in getattr(parsed_prog, "from_imports", []) or []:
				local_name = getattr(imp, "alias", None) or getattr(imp, "symbol", "")
				mod = ".".join(getattr(imp, "module_path", []) or [])
				sym = getattr(imp, "symbol", "")
				if not local_name or not mod or not sym:
					continue
				target = (mod, sym)
				imp_span = _span_in_file(path, getattr(imp, "loc", None))
				prev = reexport_candidates.get(local_name)
				if prev is None:
					reexport_candidates[local_name] = target
					reexport_first_span[local_name] = imp_span
				elif prev != target:
					if local_name not in reexport_conflicts:
						reexport_conflicts[local_name] = (
							prev,
							target,
							reexport_first_span.get(local_name, Span()),
							imp_span,
						)

		for n, ex_span in raw_export_entries:
			first_span = seen_export_names.get(n)
			if first_span is None:
				seen_export_names[n] = ex_span
			else:
				diagnostics.append(
					Diagnostic(
						message=f"duplicate export of symbol '{n}' in module '{module_id}'",
						severity="error",
						span=ex_span,
						notes=[f"first export was here: {_format_span_short(first_span)}"],
					)
				)
				continue

			in_values = n in module_fn_names
			in_consts = n in module_const_names
			in_struct = n in module_struct_names
			in_variant = n in module_variant_names
			in_exc = n in module_exception_names
			type_hits = int(in_struct) + int(in_variant) + int(in_exc)
			in_types = type_hits > 0

			if (in_values and in_consts) or (in_values and in_types) or (in_consts and in_types):
				diagnostics.append(
					Diagnostic(
						message=f"exported name '{n}' is ambiguous (defined as multiple kinds in module '{module_id}')",
						severity="error",
						span=ex_span,
					)
				)
				continue
			if type_hits > 1:
				diagnostics.append(
					Diagnostic(
						message=f"exported type name '{n}' is ambiguous (defined as multiple type kinds in module '{module_id}')",
						severity="error",
						span=ex_span,
					)
				)
				continue

			if not in_values and not in_consts and not in_types:
				# Re-export candidate. We resolve these deterministically after we
				# have computed export interfaces for all modules and any external
				# package-provided modules.
				#
				# This keeps the export interface composable: `export { foo }` may
				# refer to a local definition or an imported binding (re-export).
				conflict = reexport_conflicts.get(n)
				if conflict is not None:
					prev, new, first_imp_span, second_imp_span = conflict
					diagnostics.append(
						Diagnostic(
							message=(
								f"exported name '{n}' is ambiguous due to conflicting imports "
								f"({prev[0]}::{prev[1]} vs {new[0]}::{new[1]}); cannot export it"
							),
							severity="error",
							span=ex_span,
							notes=[
								f"first import was here: {_format_span_short(first_imp_span)}",
								f"conflicting import was here: {_format_span_short(second_imp_span)}",
							],
						)
					)
					continue
				target = reexport_candidates.get(n)
				if target is not None:
					pending_reexports[n] = ex_span
					continue
				diagnostics.append(
					Diagnostic(
						message=f"module '{module_id}' exports unknown symbol '{n}'",
						severity="error",
						span=ex_span,
					)
				)
				continue

			if in_values:
				exported_values[n] = (module_id, n)
			if in_consts:
				exported_consts.add(n)
			if in_struct:
				exported_types["structs"].add(n)
			if in_variant:
				exported_types["variants"].add(n)
			if in_exc:
				exported_types["exceptions"].add(n)

		return (
			exported_values,
			exported_types,
			exported_consts,
			pending_reexports,
			reexport_candidates,
			reexport_conflicts,
		)

	# Note: module-scoped nominal type identity is implemented in lang2.
	# Multiple modules may define types with the same short name without
	# colliding; identity is `(module_id, name, kind)`.

	# Export sets (private by default, explicit exports required).
	#
	# MVP supports exporting/importing both value-level and type-level symbols,
	# but keeps them in separate namespaces:
	# - values: currently just free functions
	# - types: structs, variants, exceptions
	#
	# Export lists are unqualified identifiers, so to avoid ambiguity we reject
	# any module that defines the same name in both namespaces (until the language
	# adds explicit `export type ...` / `export fn ...` syntax).
	exports_values_by_module: dict[str, dict[str, tuple[str, str]]] = {}
	exports_types_by_module: dict[str, dict[str, set[str]]] = {}
	exports_consts_by_module: dict[str, set[str]] = {}
	pending_reexports_by_module: dict[str, dict[str, Span]] = {}
	reexport_candidates_by_module: dict[str, dict[str, tuple[str, str]]] = {}
	reexport_conflicts_by_module: dict[str, dict[str, tuple[tuple[str, str], tuple[str, str], Span, Span]]] = {}
	# Re-export target maps (for types/consts). Values are materialized as
	# trampolines, so consumers always reference the exporting module id.
	reexported_type_targets_by_module: dict[str, dict[str, dict[str, tuple[str, str]]]] = {}
	reexported_const_targets_by_module: dict[str, dict[str, tuple[str, str]]] = {}
	for mid, prog in merged_programs.items():
		(
			exported_values,
			exported_types,
			exported_consts,
			pending_reexports,
			reexport_candidates,
			reexport_conflicts,
		) = _build_export_interface(
			module_id=mid,
			merged_prog=prog,
			module_files=by_module.get(mid, []),
		)
		exports_values_by_module[mid] = exported_values
		exports_types_by_module[mid] = exported_types
		exports_consts_by_module[mid] = exported_consts
		pending_reexports_by_module[mid] = pending_reexports
		reexport_candidates_by_module[mid] = reexport_candidates
		reexport_conflicts_by_module[mid] = reexport_conflicts
		reexported_type_targets_by_module[mid] = {"structs": {}, "variants": {}, "exceptions": {}}
		reexported_const_targets_by_module[mid] = {}

	# Resolve re-exports across modules deterministically.
	#
	# For `export { foo }` where `foo` is imported via `from m import foo`,
	# we extend the exporting module's interface with:
	# - values: `foo` is exported and later materialized as a trampoline function
	#   `this_module::foo` that forwards to `m::foo`,
	# - consts: `foo` is exported and later materialized as a *local* compile-time
	#   constant `this_module::foo` copied from `m::foo` (no runtime storage),
	# - types: `foo` is exported as an alias of the underlying definition and is
	#   recorded in reexport target maps so import resolution can bind it to the
	#   defining module identity (no type duplication).
	def _export_lookup(mod: str) -> tuple[set[str], set[str], dict[str, set[str]]]:
		"""Return (exported_values, exported_consts, exported_types_by_kind) for a module."""
		if mod in exports_values_by_module or mod in exports_types_by_module or mod in exports_consts_by_module:
			return (
				set((exports_values_by_module.get(mod) or {}).keys()),
				set(exports_consts_by_module.get(mod) or set()),
				exports_types_by_module.get(mod) or {"structs": set(), "variants": set(), "exceptions": set()},
			)
		if external_module_exports is not None and mod in external_module_exports:
			ext = external_module_exports.get(mod) or {}
			ext_types = ext.get("types")
			types_obj: dict[str, set[str]] = {"structs": set(), "variants": set(), "exceptions": set()}
			if isinstance(ext_types, dict):
				types_obj = {
					"structs": set(ext_types.get("structs") or set()),
					"variants": set(ext_types.get("variants") or set()),
					"exceptions": set(ext_types.get("exceptions") or set()),
				}
			return (
				set(ext.get("values") or set()),
				set(ext.get("consts") or set()),
				types_obj,
			)
		return set(), set(), {"structs": set(), "variants": set(), "exceptions": set()}

	# We iterate until no progress so multi-hop re-exports resolve deterministically.
	for _ in range(len(merged_programs) + 1):
		progress = False
		for mid, pending in pending_reexports_by_module.items():
			if not pending:
				continue
			for name, ex_span in list(pending.items()):
				target = (reexport_candidates_by_module.get(mid) or {}).get(name)
				if target is None:
					continue
				tmod, tsym = target
				vals, consts, types_obj = _export_lookup(tmod)
				is_val = tsym in vals
				is_const = tsym in consts
				is_struct = tsym in (types_obj.get("structs") or set())
				is_variant = tsym in (types_obj.get("variants") or set())
				is_exc = tsym in (types_obj.get("exceptions") or set())
				hits = int(is_val) + int(is_const) + int(is_struct) + int(is_variant) + int(is_exc)
				if hits == 0:
					continue
				if hits > 1:
					diagnostics.append(
						Diagnostic(
							message=f"exported name '{name}' is ambiguous (target '{tmod}::{tsym}' exists in multiple namespaces)",
							severity="error",
							span=ex_span,
						)
					)
					pending.pop(name, None)
					progress = True
					continue
				if is_val:
					exports_values_by_module[mid][name] = (tmod, tsym)
				elif is_const:
					# Const re-export MVP:
					# - the exporting module `mid` exports a *local* const symbol
					#   `mid::name` as part of its interface.
					# - later in the driver pipeline, `mid::name` is materialized by
					#   copying the typed literal value of `tmod::tsym` into the exporting
					#   module’s const table.
					#
					# Import resolution must treat the const as belonging to the exporting
					# module so consumers do not need to reference the origin module.
					exports_consts_by_module[mid].add(name)
					reexported_const_targets_by_module[mid][name] = (tmod, tsym)
				elif is_struct:
					exports_types_by_module[mid]["structs"].add(name)
					reexported_type_targets_by_module[mid]["structs"][name] = (tmod, tsym)
				elif is_variant:
					exports_types_by_module[mid]["variants"].add(name)
					reexported_type_targets_by_module[mid]["variants"][name] = (tmod, tsym)
				elif is_exc:
					exports_types_by_module[mid]["exceptions"].add(name)
					reexported_type_targets_by_module[mid]["exceptions"][name] = (tmod, tsym)
				pending.pop(name, None)
				progress = True
		if not progress:
			break

	# Any remaining pending re-exports could not be resolved.
	for mid, pending in pending_reexports_by_module.items():
		for name, ex_span in pending.items():
			target = (reexport_candidates_by_module.get(mid) or {}).get(name)
			if target is None:
				continue
			tmod, tsym = target
			diagnostics.append(
				Diagnostic(
					message=f"module '{mid}' exports unknown symbol '{name}' (imported as '{tsym}' from '{tmod}')",
					severity="error",
					span=ex_span,
				)
			)

	def _union_exported_types(types_obj: dict[str, set[str]] | None) -> set[str]:
		if not types_obj:
			return set()
		out: set[str] = set()
		for vs in types_obj.values():
			out |= set(vs)
		return out

	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	# Export interface summary (used by package emission and future tooling).
	module_exports: dict[str, dict[str, list[str]]] = {}
	for mid in merged_programs.keys():
		vals = exports_values_by_module.get(mid, {})
		types = exports_types_by_module.get(mid, {"structs": set(), "variants": set(), "exceptions": set()})
		consts = exports_consts_by_module.get(mid, set())
		reexp_types = reexported_type_targets_by_module.get(mid, {"structs": {}, "variants": {}, "exceptions": {}})
		reexp_consts = reexported_const_targets_by_module.get(mid, {})
		module_exports[mid] = {
			"values": sorted(list(vals.keys())),
			"types": {
				"structs": sorted(list(types.get("structs", set()))),
				"variants": sorted(list(types.get("variants", set()))),
				"exceptions": sorted(list(types.get("exceptions", set()))),
			},
			"consts": sorted(list(consts)),
			"reexports": {
				"types": {
					"structs": {n: {"module": m, "name": s} for n, (m, s) in sorted(reexp_types.get("structs", {}).items())},
					"variants": {n: {"module": m, "name": s} for n, (m, s) in sorted(reexp_types.get("variants", {}).items())},
					"exceptions": {n: {"module": m, "name": s} for n, (m, s) in sorted(reexp_types.get("exceptions", {}).items())},
				},
				"consts": {n: {"module": m, "name": s} for n, (m, s) in sorted(reexp_consts.items())},
			},
		}

	# Resolve imports and build a dependency graph.
	#
	# MVP rule: import bindings are per-file. Module dependencies, however, are
	# computed at module granularity (a module depends on another module if any
	# of its files import it).
	#
	# Keep per-edge provenance so cycle diagnostics can be source-anchored.
	# Each edge is (to_module, span).
	dep_edges: dict[str, list[tuple[str, Span]]] = {mid: [] for mid in merged_programs}
	from_value_bindings_by_file: dict[Path, dict[str, tuple[str, str]]] = {}
	from_type_bindings_by_file: dict[Path, dict[str, tuple[str, str]]] = {}
	from_const_bindings_by_file: dict[Path, dict[str, tuple[str, str]]] = {}
	module_aliases_by_file: dict[Path, dict[str, str]] = {}
	for mid, files in by_module.items():
		for path, prog in files:
			file_seen_values: dict[str, tuple[str, str]] = {}
			file_seen_types: dict[str, tuple[str, str]] = {}
			file_seen_consts: dict[str, tuple[str, str]] = {}
			file_value_bindings: dict[str, tuple[str, str]] = {}
			file_type_bindings: dict[str, tuple[str, str]] = {}
			file_const_bindings: dict[str, tuple[str, str]] = {}
			# Track first import site per local binding name so conflict diagnostics
			# can point at both the import and the local declaration.
			file_value_binding_span: dict[str, Span] = {}
			file_type_binding_span: dict[str, Span] = {}
			file_const_binding_span: dict[str, Span] = {}
			file_module_aliases: dict[str, str] = {}
			# MVP rule: `from m import name` introduces a file-scoped binding in the
			# same namespace as top-level declarations in that file. Conflicts are
			# errors regardless of order (imports are treated as a logical header).
			top_level_fn_by_name: dict[str, object] = {fn.name: fn for fn in getattr(prog, "functions", []) or []}
			top_level_const_by_name: dict[str, object] = {c.name: c for c in getattr(prog, "consts", []) or []}
			top_level_type_by_name: dict[str, object] = {}
			for s in getattr(prog, "structs", []) or []:
				top_level_type_by_name[s.name] = s
			for v in getattr(prog, "variants", []) or []:
				top_level_type_by_name[v.name] = v
			for e in getattr(prog, "exceptions", []) or []:
				top_level_type_by_name[e.name] = e

			for imp in getattr(prog, "imports", []) or []:
				mod = ".".join(getattr(imp, "path", []) or [])
				if not mod:
					continue
				span = _span_in_file(path, getattr(imp, "loc", None))
				dep_edges[mid].append((mod, span))
				if mod not in merged_programs and (external_module_exports is None or mod not in external_module_exports):
					diagnostics.append(Diagnostic(message=f"imported module '{mod}' not found", severity="error", span=span))
					continue
				alias = getattr(imp, "alias", None) or (getattr(imp, "path", []) or [mod])[-1]
				prev = file_module_aliases.get(alias)
				if prev is None:
					file_module_aliases[alias] = mod
				elif prev != mod:
					diagnostics.append(
						Diagnostic(
							message=f"import alias '{alias}' conflicts: cannot import both '{prev}' and '{mod}' as '{alias}'",
							severity="error",
							span=span,
						)
					)

			# Record module aliases for later module-qualified access resolution.
			# This is per-file by design (imports are file-scoped in MVP).
			module_aliases_by_file[path] = dict(file_module_aliases)

			for fi in getattr(prog, "from_imports", []) or []:
				mod = ".".join(getattr(fi, "module_path", []) or [])
				sym = getattr(fi, "symbol", "")
				if not mod or not sym:
					continue
				span = _span_in_file(path, getattr(fi, "loc", None))
				dep_edges[mid].append((mod, span))
				if mod not in merged_programs and (external_module_exports is None or mod not in external_module_exports):
					diagnostics.append(Diagnostic(message=f"imported module '{mod}' not found", severity="error", span=span))
					continue

				exported_values_map = exports_values_by_module.get(mod, {})
				exported_types_obj = exports_types_by_module.get(mod, {"structs": set(), "variants": set(), "exceptions": set()})
				exported_types_set = _union_exported_types(exported_types_obj)
				exported_consts_set = set(exports_consts_by_module.get(mod, set()))
				exported_const_targets = reexported_const_targets_by_module.get(mod, {})
				exported_type_targets = reexported_type_targets_by_module.get(mod, {"structs": {}, "variants": {}, "exceptions": {}})
				if mod not in merged_programs and external_module_exports is not None and mod in external_module_exports:
					ext = external_module_exports.get(mod) or {}
					exported_values_map = {n: (mod, n) for n in sorted(ext.get("values") or set())}
					ext_types = ext.get("types")
					if isinstance(ext_types, dict):
						exported_types_set = set(ext_types.get("structs") or set()) | set(ext_types.get("variants") or set()) | set(
							ext_types.get("exceptions") or set()
						)
					else:
						exported_types_set = set()
					exported_consts_set = set(ext.get("consts") or set())
					# External modules may include re-export metadata for types/consts.
					ext_reexp = ext.get("reexports")
					exported_const_targets = {}
					exported_type_targets = {"structs": {}, "variants": {}, "exceptions": {}}
					if isinstance(ext_reexp, dict):
						ext_reexp_types = ext_reexp.get("types")
						ext_reexp_consts = ext_reexp.get("consts")
						if isinstance(ext_reexp_consts, dict):
							for k, v in ext_reexp_consts.items():
								if isinstance(k, str) and isinstance(v, dict):
									tm = v.get("module")
									tn = v.get("name")
									if isinstance(tm, str) and isinstance(tn, str):
										exported_const_targets[k] = (tm, tn)
						if isinstance(ext_reexp_types, dict):
							for kind in ("structs", "variants", "exceptions"):
								km = ext_reexp_types.get(kind)
								if isinstance(km, dict):
									for k, v in km.items():
										if isinstance(k, str) and isinstance(v, dict):
											tm = v.get("module")
											tn = v.get("name")
											if isinstance(tm, str) and isinstance(tn, str):
												exported_type_targets[kind][k] = (tm, tn)
				available_exports = sorted(set(exported_values_map.keys()) | exported_types_set | exported_consts_set)
				is_glob = bool(getattr(fi, "is_glob", False))
				if is_glob:
					if getattr(fi, "alias", None) is not None:
						diagnostics.append(
							Diagnostic(
								message="from-import glob does not support aliasing",
								severity="error",
								span=span,
							)
						)
						continue
					# Expand deterministically: values, consts, then types; each sorted.
					glob_values = sorted(exported_values_map.keys())
					glob_consts = sorted(exported_consts_set)
					glob_types = sorted(exported_types_set)
					for v in glob_values:
						local_name = v
						target = exported_values_map.get(v, (mod, v))
						prev = file_seen_values.get(local_name)
						if prev is None:
							file_seen_values[local_name] = target
							file_value_binding_span[local_name] = span
							file_value_bindings[local_name] = target
						elif prev != target:
							prev_span = file_value_binding_span.get(local_name, Span())
							diagnostics.append(
								Diagnostic(
									message=f"ambiguous imported name '{local_name}': both '{prev[0]}::{prev[1]}' and '{target[0]}::{target[1]}' are in scope",
									severity="error",
									span=span,
									notes=[f"previous import was here: {_format_span_short(prev_span)}"],
								)
							)
					for c in glob_consts:
						local_name = c
						# Const re-exports are materialized into the exporting module’s
						# own const table, so the local binding always targets `mod::c`.
						target = (mod, c)
						prev = file_seen_consts.get(local_name)
						if prev is None:
							file_seen_consts[local_name] = target
							file_const_binding_span[local_name] = span
							file_const_bindings[local_name] = target
						elif prev != target:
							prev_span = file_const_binding_span.get(local_name, Span())
							diagnostics.append(
								Diagnostic(
									message=f"ambiguous imported const name '{local_name}': both '{prev[0]}::{prev[1]}' and '{target[0]}::{target[1]}' are in scope",
									severity="error",
									span=span,
									notes=[f"previous import was here: {_format_span_short(prev_span)}"],
								)
							)
					for t in glob_types:
						local_name = t
						if t in (exported_types_obj.get("structs") or set()):
							target = exported_type_targets.get("structs", {}).get(t, (mod, t))
						elif t in (exported_types_obj.get("variants") or set()):
							target = exported_type_targets.get("variants", {}).get(t, (mod, t))
						elif t in (exported_types_obj.get("exceptions") or set()):
							target = exported_type_targets.get("exceptions", {}).get(t, (mod, t))
						else:
							target = (mod, t)
						prev = file_seen_types.get(local_name)
						if prev is None:
							file_seen_types[local_name] = target
							file_type_binding_span[local_name] = span
							file_type_bindings[local_name] = target
						elif prev != target:
							prev_span = file_type_binding_span.get(local_name, Span())
							diagnostics.append(
								Diagnostic(
									message=f"ambiguous imported type name '{local_name}': both '{prev[0]}::{prev[1]}' and '{target[0]}::{target[1]}' are in scope",
									severity="error",
									span=span,
									notes=[f"previous import was here: {_format_span_short(prev_span)}"],
								)
							)
					continue

				is_value = sym in exported_values_map
				is_type = sym in exported_types_set
				is_const = sym in exported_consts_set
				if not is_value and not is_type and not is_const:
					available = ", ".join(available_exports)
					notes = (
						[f"available exports: {available}"]
						if available
						else [f"module '{mod}' exports nothing (private by default)"]
					)
					diagnostics.append(
						Diagnostic(
							message=f"module '{mod}' does not export symbol '{sym}'",
							severity="error",
							span=span,
							notes=notes,
						)
					)
					continue
				if int(is_value) + int(is_type) + int(is_const) > 1:
					diagnostics.append(
						Diagnostic(
							message=f"module '{mod}' exports symbol '{sym}' in multiple namespaces; cannot import it in MVP",
							severity="error",
							span=span,
						)
					)
					continue

				local_name = getattr(fi, "alias", None) or sym
				if is_value:
					# Re-exported values are exported under the current module id but
					# implemented by another module/symbol. For MVP we materialize
					# re-exports as trampoline functions (`mod::sym`) so imports remain
					# stable and module interfaces are self-contained.
					raw_target = exported_values_map.get(sym, (mod, sym))
					target = (mod, sym) if raw_target != (mod, sym) else raw_target
					prev = file_seen_values.get(local_name)
					if prev is None:
						file_seen_values[local_name] = target
						file_value_binding_span[local_name] = span
					elif prev != target:
						diagnostics.append(
							Diagnostic(
								message=f"ambiguous imported name '{local_name}': both '{prev[0]}::{prev[1]}' and '{target[0]}::{target[1]}' are in scope",
								severity="error",
								span=span,
								notes=[f"previous import was here: {_format_span_short(file_value_binding_span.get(local_name, Span()))}"],
							)
						)
						continue
					file_value_bindings[local_name] = target

				if is_const:
					# Const re-exports are materialized into the exporting module’s
					# own const table, so the local binding always targets `mod::sym`.
					target = (mod, sym)
					prev = file_seen_consts.get(local_name)
					if prev is None:
						file_seen_consts[local_name] = target
						file_const_binding_span[local_name] = span
					elif prev != target:
						diagnostics.append(
							Diagnostic(
								message=f"ambiguous imported const name '{local_name}': both '{prev[0]}::{prev[1]}' and '{target[0]}::{target[1]}' are in scope",
								severity="error",
								span=span,
								notes=[f"previous import was here: {_format_span_short(file_const_binding_span.get(local_name, Span()))}"],
							)
						)
						continue
					file_const_bindings[local_name] = target

				if is_type:
					if sym in (exported_types_obj.get("structs") or set()):
						target = exported_type_targets.get("structs", {}).get(sym, (mod, sym))
					elif sym in (exported_types_obj.get("variants") or set()):
						target = exported_type_targets.get("variants", {}).get(sym, (mod, sym))
					elif sym in (exported_types_obj.get("exceptions") or set()):
						target = exported_type_targets.get("exceptions", {}).get(sym, (mod, sym))
					else:
						target = (mod, sym)
					prev = file_seen_types.get(local_name)
					if prev is None:
						file_seen_types[local_name] = target
						file_type_binding_span[local_name] = span
					elif prev != target:
						diagnostics.append(
							Diagnostic(
								message=f"ambiguous imported type name '{local_name}': both '{prev[0]}::{prev[1]}' and '{target[0]}::{target[1]}' are in scope",
								severity="error",
								span=span,
								notes=[f"previous import was here: {_format_span_short(file_type_binding_span.get(local_name, Span()))}"],
							)
						)
						continue
					file_type_bindings[local_name] = target

			from_value_bindings_by_file[path] = file_value_bindings
			from_type_bindings_by_file[path] = file_type_bindings
			from_const_bindings_by_file[path] = file_const_bindings

			# After collecting the effective import bindings, enforce the pinned
			# conflict rule with local top-level declarations.
			for local_name, (imp_mod, imp_sym) in file_value_bindings.items():
				local_decl = top_level_fn_by_name.get(local_name) or top_level_const_by_name.get(local_name)
				if local_decl is None:
					continue
				decl_span = _span_in_file(path, getattr(local_decl, "loc", None))
				imp_span = file_value_binding_span.get(local_name, Span())
				diagnostics.append(
					Diagnostic(
						message=f"name '{local_name}' conflicts with imported binding from module '{imp_mod}'",
						severity="error",
						span=decl_span,
						notes=[
							f"imported as '{local_name}' from '{imp_mod}::{imp_sym}' at {getattr(imp_span, 'file', str(path))}:{getattr(imp_span, 'line', '?')}:{getattr(imp_span, 'column', '?')}",
						],
					)
				)
			for local_name, (imp_mod, imp_sym) in file_const_bindings.items():
				local_decl = top_level_fn_by_name.get(local_name) or top_level_const_by_name.get(local_name)
				if local_decl is None:
					continue
				decl_span = _span_in_file(path, getattr(local_decl, "loc", None))
				imp_span = file_const_binding_span.get(local_name, Span())
				diagnostics.append(
					Diagnostic(
						message=f"name '{local_name}' conflicts with imported const binding from module '{imp_mod}'",
						severity="error",
						span=decl_span,
						notes=[
							f"imported as '{local_name}' from '{imp_mod}::{imp_sym}' at {getattr(imp_span, 'file', str(path))}:{getattr(imp_span, 'line', '?')}:{getattr(imp_span, 'column', '?')}",
						],
					)
				)
			for local_name, (imp_mod, imp_sym) in file_type_bindings.items():
				local_decl = top_level_type_by_name.get(local_name)
				if local_decl is None:
					continue
				decl_span = _span_in_file(path, getattr(local_decl, "loc", None))
				imp_span = file_type_binding_span.get(local_name, Span())
				diagnostics.append(
					Diagnostic(
						message=f"type name '{local_name}' conflicts with imported type from module '{imp_mod}'",
						severity="error",
						span=decl_span,
						notes=[
							f"imported as '{local_name}' from '{imp_mod}::{imp_sym}' at {getattr(imp_span, 'file', str(path))}:{getattr(imp_span, 'line', '?')}:{getattr(imp_span, 'column', '?')}",
						],
					)
				)

	# Collapse edge lists into a simple adjacency set for cycle detection.
	deps: dict[str, set[str]] = {mid: {to for (to, _sp) in edges if to in merged_programs} for mid, edges in dep_edges.items()}

	# Resolve module-qualified and imported type references using per-file import
	# bindings and module export interfaces.
	#
	# After successful resolution we record the canonical `module_id` on the type
	# expression (and rewrite imported aliases to their original symbol name). This
	# preserves module-scoped nominal identity end-to-end.
	def _exported_types_for_module(mod: str) -> set[str]:
		if mod in exports_types_by_module:
			return _union_exported_types(exports_types_by_module.get(mod))
		if external_module_exports is not None and mod in external_module_exports:
			ext = external_module_exports.get(mod) or {}
			ext_types = ext.get("types")
			if isinstance(ext_types, dict):
				return set(ext_types.get("structs") or set()) | set(ext_types.get("variants") or set()) | set(
					ext_types.get("exceptions") or set()
				)
			return set()
		return set()

	def _resolve_type_expr_in_file(
		path: Path,
		file_aliases: dict[str, str],
		file_type_bindings: dict[str, tuple[str, str]],
		te: parser_ast.TypeExpr | None,
	) -> None:
		if te is None:
			return
		if getattr(te, "module_alias", None):
			alias = te.module_alias
			mod = file_aliases.get(alias or "")
			span = _span_in_file(path, getattr(te, "loc", None))
			if mod is None:
				diagnostics.append(
					Diagnostic(
						message=f"unknown module alias '{alias}' in type reference '{alias}.{te.name}'",
						severity="error",
						span=span,
					)
				)
			else:
				types = _exported_types_for_module(mod)
				if te.name not in types:
					available = ", ".join(sorted(types))
					notes = (
						[f"available exported types: {available}"]
						if available
						else [f"module '{mod}' exports no types (private by default)"]
					)
					diagnostics.append(
						Diagnostic(
							message=f"module '{mod}' does not export type '{te.name}'",
							severity="error",
							span=span,
							notes=notes,
						)
					)
				else:
					# Record the canonical module id for later lowering.
					#
					# If `mod` re-exports this type, resolve it to the defining module
					# identity (no type duplication across module interfaces).
					def_mod, def_name = (mod, te.name)
					reexp = reexported_type_targets_by_module.get(mod)
					if reexp is not None:
						for kind in ("structs", "variants", "exceptions"):
							if te.name in (exports_types_by_module.get(mod) or {}).get(kind, set()):
								def_mod, def_name = reexp.get(kind, {}).get(te.name, (mod, te.name))
								break
					elif external_module_exports is not None and mod in external_module_exports:
						ext = external_module_exports.get(mod) or {}
						ext_reexp = ext.get("reexports")
						ext_types = ext.get("types")
						if isinstance(ext_reexp, dict) and isinstance(ext_types, dict):
							ext_reexp_types = ext_reexp.get("types")
							if isinstance(ext_reexp_types, dict):
								for kind in ("structs", "variants", "exceptions"):
									kind_set = set(ext_types.get(kind) or set())
									if te.name in kind_set:
										tgt = ext_reexp_types.get(kind, {}).get(te.name) if isinstance(ext_reexp_types.get(kind), dict) else None
										if isinstance(tgt, dict):
											tm = tgt.get("module")
											tn = tgt.get("name")
											if isinstance(tm, str) and isinstance(tn, str):
												def_mod, def_name = (tm, tn)
										break
					te.module_id = def_mod
					te.name = def_name
					te.module_alias = None
		# Unqualified imported type: `from m import Point` makes `Point` resolve to
		# the imported module, even when referenced without an `x.` qualifier.
		if getattr(te, "module_alias", None) is None and getattr(te, "module_id", None) is None:
			target = file_type_bindings.get(te.name)
			if target is not None:
				mod, sym = target
				te.module_id = mod
				te.name = sym
		for a in getattr(te, "args", []) or []:
			_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, a)

	def _resolve_types_in_block(path: Path, file_aliases: dict[str, str], file_type_bindings: dict[str, tuple[str, str]], blk: parser_ast.Block) -> None:
		for st in getattr(blk, "statements", []) or []:
			# Resolve any type-level references embedded in expressions (e.g.,
			# `TypeRef::Ctor(...)` where `TypeRef` may include a module alias).
			def _resolve_types_in_expr(expr: parser_ast.Expr) -> None:
				if isinstance(expr, parser_ast.QualifiedMember):
					_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, expr.base_type)
					return
				if isinstance(expr, parser_ast.Call):
					_resolve_types_in_expr(expr.func)
					for a in getattr(expr, "args", []) or []:
						_resolve_types_in_expr(a)
					for kw in getattr(expr, "kwargs", []) or []:
						_resolve_types_in_expr(kw.value)
					return
				if isinstance(expr, parser_ast.Attr):
					_resolve_types_in_expr(expr.value)
					return
				if isinstance(expr, parser_ast.Index):
					_resolve_types_in_expr(expr.value)
					_resolve_types_in_expr(expr.index)
					return
				if isinstance(expr, parser_ast.Unary):
					_resolve_types_in_expr(expr.operand)
					return
				if isinstance(expr, parser_ast.Binary):
					_resolve_types_in_expr(expr.left)
					_resolve_types_in_expr(expr.right)
					return
				if isinstance(expr, parser_ast.Move):
					_resolve_types_in_expr(expr.value)
					return
				if isinstance(expr, parser_ast.Ternary):
					_resolve_types_in_expr(expr.condition)
					_resolve_types_in_expr(expr.then_value)
					_resolve_types_in_expr(expr.else_value)
					return
				if isinstance(expr, parser_ast.ArrayLiteral):
					for e in getattr(expr, "elements", []) or []:
						_resolve_types_in_expr(e)
					return
				if isinstance(expr, parser_ast.TryCatchExpr):
					_resolve_types_in_expr(expr.attempt)
					for arm in getattr(expr, "catch_arms", []) or []:
						_resolve_types_in_block(path, file_aliases, file_type_bindings, arm.block)
					return
				if isinstance(expr, parser_ast.MatchExpr):
					_resolve_types_in_expr(expr.scrutinee)
					for arm in getattr(expr, "arms", []) or []:
						_resolve_types_in_block(path, file_aliases, file_type_bindings, arm.block)
					return
				if isinstance(expr, parser_ast.ExceptionCtor):
					for a in getattr(expr, "args", []) or []:
						_resolve_types_in_expr(a)
					for kw in getattr(expr, "kwargs", []) or []:
						_resolve_types_in_expr(kw.value)
					return
				if isinstance(expr, parser_ast.FString):
					for h in getattr(expr, "holes", []) or []:
						_resolve_types_in_expr(h.expr)
					return
				# literals/names/placeholders are leaf nodes

			if isinstance(st, parser_ast.LetStmt) and getattr(st, "type_expr", None) is not None:
				_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, st.type_expr)
			if isinstance(st, parser_ast.LetStmt):
				_resolve_types_in_expr(st.value)
			if isinstance(st, parser_ast.AssignStmt):
				_resolve_types_in_expr(st.target)
				_resolve_types_in_expr(st.value)
			if isinstance(st, parser_ast.AugAssignStmt):
				_resolve_types_in_expr(st.target)
				_resolve_types_in_expr(st.value)
			if isinstance(st, parser_ast.ReturnStmt) and st.value is not None:
				_resolve_types_in_expr(st.value)
			if isinstance(st, parser_ast.ExprStmt):
				_resolve_types_in_expr(st.value)
			if isinstance(st, parser_ast.IfStmt):
				_resolve_types_in_expr(st.condition)
				_resolve_types_in_block(path, file_aliases, file_type_bindings, st.then_block)
				if st.else_block is not None:
					_resolve_types_in_block(path, file_aliases, file_type_bindings, st.else_block)
			if isinstance(st, parser_ast.TryStmt):
				if isinstance(getattr(st, "attempt", None), parser_ast.Expr):
					_resolve_types_in_expr(st.attempt)
				_resolve_types_in_block(path, file_aliases, file_type_bindings, st.body)
				for c in getattr(st, "catches", []) or []:
					_resolve_types_in_block(path, file_aliases, file_type_bindings, c.block)
			if isinstance(st, parser_ast.WhileStmt):
				_resolve_types_in_expr(st.condition)
				_resolve_types_in_block(path, file_aliases, file_type_bindings, st.body)
			if isinstance(st, parser_ast.ForStmt):
				_resolve_types_in_expr(st.iter_expr)
				_resolve_types_in_block(path, file_aliases, file_type_bindings, st.body)
			if isinstance(st, parser_ast.ThrowStmt):
				_resolve_types_in_expr(st.expr)

	for mid, files in by_module.items():
		for path, prog in files:
			file_aliases = module_aliases_by_file.get(path, {})
			file_type_bindings = from_type_bindings_by_file.get(path, {})
			# Top-level declarations.
			for fn in getattr(prog, "functions", []) or []:
				for p in getattr(fn, "params", []) or []:
					_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, p.type_expr)
				_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, getattr(fn, "return_type", None))
				_resolve_types_in_block(path, file_aliases, file_type_bindings, fn.body)
			for impl in getattr(prog, "implements", []) or []:
				_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, impl.target)
				for mfn in getattr(impl, "methods", []) or []:
					for p in getattr(mfn, "params", []) or []:
						_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, p.type_expr)
					_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, getattr(mfn, "return_type", None))
					_resolve_types_in_block(path, file_aliases, file_type_bindings, mfn.body)
			for s in getattr(prog, "structs", []) or []:
				for f in getattr(s, "fields", []) or []:
					_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, f.type_expr)
			for e in getattr(prog, "exceptions", []) or []:
				for a in getattr(e, "args", []) or []:
					_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, a.type_expr)
			for v in getattr(prog, "variants", []) or []:
				for arm in getattr(v, "arms", []) or []:
					for f in getattr(arm, "fields", []) or []:
						_resolve_type_expr_in_file(path, file_aliases, file_type_bindings, f.type_expr)

	# Cycle detection (MVP: reject import cycles).
	def _find_cycle() -> list[str] | None:
		vis: set[str] = set()
		stack: list[str] = []
		onstack: set[str] = set()

		def dfs(n: str) -> list[str] | None:
			vis.add(n)
			stack.append(n)
			onstack.add(n)
			for m in deps.get(n, set()):
				if m not in merged_programs:
					continue
				if m not in vis:
					c = dfs(m)
					if c is not None:
						return c
				elif m in onstack:
					try:
						i = stack.index(m)
					except ValueError:
						i = 0
					return stack[i:] + [m]
			stack.pop()
			onstack.remove(n)
			return None

		for n in merged_programs:
			if n not in vis:
				c = dfs(n)
				if c is not None:
					return c
		return None

	cycle = _find_cycle()
	if cycle is not None:
		# Anchor the diagnostic to one concrete import site in the cycle.
		# (We choose the first edge in the reported cycle.)
		primary_span: Span | None = None
		notes: list[str] = []
		for i in range(len(cycle) - 1):
			a = cycle[i]
			b = cycle[i + 1]
			for to, sp in dep_edges.get(a, []):
				if to == b:
					if i == 0:
						primary_span = sp
					notes.append(f"{a} imports {b}")
					break
		if primary_span is None:
			# Fallback: pick any import edge span from any node in the cycle.
			for node in cycle:
				for _to, sp in dep_edges.get(node, []):
					primary_span = sp
					break
				if primary_span is not None:
					break
		diagnostics.append(
			Diagnostic(
				message=f"import cycle detected: {' -> '.join(cycle)}",
				severity="error",
				span=primary_span or Span(),
				notes=notes,
			)
		)

	if any(d.severity == "error" for d in diagnostics):
		return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	# Lower modules using a shared TypeTable so TypeIds remain comparable across the workspace.
	shared_type_table = TypeTable()
	_prime_builtins(shared_type_table)
	# Pre-declare all nominal type names across the workspace before lowering any
	# individual module.
	#
	# This prevents cross-module type references (e.g. `import lib as x; val p: x.Point`)
	# from accidentally minting placeholder scalar TypeIds via `ensure_named` when
	# the defining module hasn't been lowered yet. `declare_struct`/`declare_variant`
	# are idempotent when the kind already matches, so later per-module lowering
	# can safely re-run its local declaration passes.
	for _mid, _prog in merged_programs.items():
		for _s in getattr(_prog, "structs", []) or []:
			try:
				shared_type_table.declare_struct(_mid, _s.name, [f.name for f in getattr(_s, "fields", []) or []])
			except ValueError as err:
				diagnostics.append(Diagnostic(message=str(err), severity="error", span=Span.from_loc(getattr(_s, "loc", None))))
		for _v in getattr(_prog, "variants", []) or []:
			arms: list[VariantArmSchema] = []
			for _arm in getattr(_v, "arms", []) or []:
				fields = [
					VariantFieldSchema(
						name=_f.name,
						type_expr=_generic_type_expr_from_parser(
							_f.type_expr, type_params=list(getattr(_v, "type_params", []) or [])
						),
					)
					for _f in getattr(_arm, "fields", []) or []
				]
				arms.append(VariantArmSchema(name=_arm.name, fields=fields))
			try:
				shared_type_table.declare_variant(
					_mid,
					_v.name,
					list(getattr(_v, "type_params", []) or []),
					arms,
				)
			except ValueError as err:
				diagnostics.append(Diagnostic(message=str(err), severity="error", span=Span.from_loc(getattr(_v, "loc", None))))

		if any(d.severity == "error" for d in diagnostics):
			return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	def _qualify_fn_name(module_id: str, name: str) -> str:
		# MVP: symbols in the default `main` module remain unqualified so
		# single-module programs keep legacy names.
		if module_id in (None, "main"):
			return name
		return f"{module_id}::{name}"

	def _qualify_symbol(module_id: str, sym: str, *, local_free_fns: set[str]) -> str:
		"""
		Qualify a module-local callable symbol for inclusion in a multi-module build.

		MVP intent: avoid collisions when multiple modules are lowered into a single
		LLVM module by making callable symbols module-scoped:
		- free functions: `foo` → `mod::foo` (except the entry `main`)
		- methods: `Type::method` → `mod::Type::method`

		This does not define a long-term symbol identity model; it's a pragmatic
		naming layer until the resolver carries explicit module/type identities.
		"""
		if sym in local_free_fns:
			return _qualify_fn_name(module_id, sym)
		if "::" in sym and not sym.startswith(f"{module_id}::"):
			return f"{module_id}::{sym}"
		return sym

	all_func_hirs: dict[FunctionId, H.HBlock] = {}
	all_sigs: dict[FunctionId, FnSignature] = {}
	fn_ids_by_name: dict[str, list[FunctionId]] = {}
	exc_catalog: dict[str, int] = {}
	fn_owner_module: dict[FunctionId, str] = {}
	fn_symbol_by_id: dict[FunctionId, str] = {}

	# Lower each module and qualify its callable symbols.
	for mid, prog in merged_programs.items():
		func_hirs, sigs, ids_by_name, _table, excs, diags = _lower_parsed_program_to_hir(
			prog,
			diagnostics=[],
			type_table=shared_type_table,
		)
		diagnostics.extend(diags)
		exc_catalog.update(excs)

		local_free_fns = {fn.name for fn in getattr(prog, "functions", []) or []}
		exported_values = exports_values_by_module.get(mid, {})

		# Qualify and copy function bodies/signatures.
		for fn_id, block in func_hirs.items():
			local_name = fn_id.name
			global_name = _qualify_symbol(mid, local_name, local_free_fns=local_free_fns)
			all_func_hirs[fn_id] = block
			fn_owner_module[fn_id] = mid
			fn_symbol_by_id[fn_id] = global_name
			fn_ids_by_name.setdefault(global_name, []).append(fn_id)

		for fn_id, sig in sigs.items():
			local_name = fn_id.name
			global_name = _qualify_symbol(mid, local_name, local_free_fns=local_free_fns)
			# Mark module-interface entry points early so downstream phases can
			# enforce visibility and (later) ABI-boundary rules consistently.
			is_exported = (local_name in local_free_fns) and (local_name in exported_values) and (local_name != "main")
			all_sigs[fn_id] = replace(sig, name=global_name, is_exported_entrypoint=is_exported)

	# Materialize re-exported functions as trampoline entry points.
	#
	# Even though `export { foo }` can refer to an imported binding (re-export),
	# module interfaces must remain self-contained: importing a symbol from a module
	# binds to `module::symbol`, not to some hidden downstream module.
	#
	# MVP implementation strategy:
	# - if module `a` exports `foo` that maps to an underlying target `(b, foo)`,
	#   synthesize `a::foo` as a trivial trampoline calling `b::foo`.
	# - this ensures exported entrypoints exist in the exporting module and keeps
	#   future package/interface metadata straightforward.
	for mid, exported_values in exports_values_by_module.items():
		for export_name, (target_mod, target_sym) in exported_values.items():
			if export_name == "main":
				continue
			if (target_mod, target_sym) == (mid, export_name):
				continue
			trampoline_name = _qualify_fn_name(mid, export_name)
			if fn_ids_by_name.get(trampoline_name):
				continue
			target_name = _qualify_fn_name(target_mod, target_sym)
			target_ids = fn_ids_by_name.get(target_name) or []
			if not target_ids:
				diagnostics.append(
					Diagnostic(
						message=f"internal: missing signature for re-export target '{target_mod}::{target_sym}'",
						severity="error",
						span=Span(),
					)
				)
				continue
			if len(target_ids) > 1:
				diagnostics.append(
					Diagnostic(
						message=f"ambiguous re-export target '{target_mod}::{target_sym}' (overloaded)",
						severity="error",
						span=Span(),
					)
				)
				continue
			target_id = target_ids[0]
			target_sig = all_sigs.get(target_id)
			if target_sig is None:
				diagnostics.append(
					Diagnostic(
						message=f"internal: missing signature for re-export target '{target_mod}::{target_sym}'",
						severity="error",
						span=Span(),
					)
				)
				continue
			ordinal = len(fn_ids_by_name.get(trampoline_name, []))
			trampoline_id = FunctionId(module=mid, name=export_name, ordinal=ordinal)
			all_sigs[trampoline_id] = replace(target_sig, name=trampoline_name, is_exported_entrypoint=True)
			fn_owner_module[trampoline_id] = mid
			fn_symbol_by_id[trampoline_id] = trampoline_name
			fn_ids_by_name.setdefault(trampoline_name, []).append(trampoline_id)

			# Build a minimal HIR body that forwards to the underlying target.
			arg_exprs: list[H.HExpr] = []
			for p in getattr(target_sig, "param_names", None) or []:
				if p:
					arg_exprs.append(H.HVar(name=p))
			callee = H.HVar(name=target_name)
			call_expr = H.HCall(fn=callee, args=arg_exprs)
			if target_sig.return_type_id is not None and shared_type_table.is_void(target_sig.return_type_id):
				all_func_hirs[trampoline_id] = H.HBlock(
					statements=[
						H.HExprStmt(expr=call_expr),
						H.HReturn(value=None),
					]
				)
			else:
				all_func_hirs[trampoline_id] = H.HBlock(statements=[H.HReturn(value=call_expr)])

		if any(d.severity == "error" for d in diagnostics):
			return {}, {}, {}, TypeTable(), {}, {}, diagnostics

	# Materialize const re-exports into the exporting module’s const table when
	# the origin const value is already available in the shared TypeTable.
	#
	# This covers the source-only workspace case (all modules provided as source).
	# When the origin const is provided by a package, the value is imported later
	# in the driver pipeline (after package TypeId remapping); in that case we
	# leave the const unresolved here and let `driftc` materialize it once the
	# origin const becomes available.
	for exporting_mid, targets in reexported_const_targets_by_module.items():
		for local_name, (origin_mid, origin_name) in targets.items():
			origin_sym = f"{origin_mid}::{origin_name}"
			dst_sym = f"{exporting_mid}::{local_name}"
			origin_entry = shared_type_table.lookup_const(origin_sym)
			if origin_entry is None:
				continue
			origin_tid, origin_val = origin_entry
			prev = shared_type_table.lookup_const(dst_sym)
			if prev is not None:
				if prev != (origin_tid, origin_val):
					diagnostics.append(
						Diagnostic(
							message=f"const '{dst_sym}' defined with a different value than re-export target '{origin_sym}'",
							severity="error",
							span=Span(),
						)
					)
				continue
			shared_type_table.define_const(module_id=exporting_mid, name=local_name, type_id=origin_tid, value=origin_val)

	# Rewrite call sites: HCall(fn=HVar(name="foo")) -> HVar(name="m::foo") for imported/local functions.
	local_maps: dict[str, dict[str, str]] = {
		mid: {fn.name: _qualify_fn_name(mid, fn.name) for fn in getattr(prog, "functions", []) or []}
		for mid, prog in merged_programs.items()
	}

	def _rewrite_calls_in_block(
		block: H.HBlock,
		*,
		module_id: str,
		fn_id: FunctionId,
		fn_symbol: str,
		origin_file: Path | None,
	) -> None:
		local_map = local_maps.get(module_id, {})
		file_bindings = from_value_bindings_by_file.get(origin_file or Path(), {})
		import_map: dict[str, str] = {local_name: _qualify_fn_name(mod, sym) for local_name, (mod, sym) in file_bindings.items()}
		file_const_bindings = from_const_bindings_by_file.get(origin_file or Path(), {})
		import_const_map: dict[str, str] = {local_name: f"{mod}::{sym}" for local_name, (mod, sym) in file_const_bindings.items()}
		file_module_aliases = module_aliases_by_file.get(origin_file or Path(), {})
		# Call-site rewriting must be scope-correct: a local binding shadows only
		# within its lexical block, not across the whole function.
		#
		# This is still a limited MVP resolver (it only rewrites direct calls
		# represented as `HCall(HVar("foo"))`), but it avoids silent miscompiles by:
		# - never rewriting names that are currently bound (params, lets, binders),
		# - applying bindings as statements are traversed (let-binding is visible
		#   only *after* its initializer).
		param_names: list[str] = []
		sig = all_sigs.get(fn_id)
		if sig is not None and getattr(sig, "param_names", None):
			param_names = [p for p in sig.param_names if p]

		def rewrite_name(name: str, *, bound: set[str]) -> str:
			if name in bound:
				return name
			if name in local_map:
				return local_map[name]
			if name in import_map:
				return import_map[name]
			return name

		def rewrite_const_name(name: str, *, bound: set[str]) -> str:
			if name in bound:
				return name
			return import_const_map.get(name, name)

		def exported_value_names(mod: str) -> set[str]:
			if mod in exports_values_by_module:
				return set((exports_values_by_module.get(mod) or {}).keys())
			if external_module_exports is not None and mod in external_module_exports:
				ext = external_module_exports.get(mod) or {}
				return set(ext.get("values") or set())
			return set()

		def exported_type_names(mod: str) -> set[str]:
			if mod in exports_types_by_module:
				return _union_exported_types(exports_types_by_module.get(mod))
			if external_module_exports is not None and mod in external_module_exports:
				ext = external_module_exports.get(mod) or {}
				ext_types = ext.get("types")
				if isinstance(ext_types, dict):
					return (
						set(ext_types.get("structs") or set())
						| set(ext_types.get("variants") or set())
						| set(ext_types.get("exceptions") or set())
					)
				return set()
			return set()

		def exported_const_names(mod: str) -> set[str]:
			if mod in exports_consts_by_module:
				return set(exports_consts_by_module.get(mod) or set())
			if external_module_exports is not None and mod in external_module_exports:
				ext = external_module_exports.get(mod) or {}
				return set(ext.get("consts") or set())
			return set()

		def exported_struct_names(mod: str) -> set[str]:
			if mod in exports_types_by_module:
				return set((exports_types_by_module.get(mod) or {}).get("structs") or set())
			if external_module_exports is not None and mod in external_module_exports:
				ext = external_module_exports.get(mod) or {}
				ext_types = ext.get("types")
				if isinstance(ext_types, dict):
					return set(ext_types.get("structs") or set())
				return set()
			return set()

		def _rewrite_module_qualified_call(
			*,
			receiver: H.HExpr,
			member: str,
			args: list[H.HExpr],
			kwargs: list[H.HKwArg],
			type_args: list[object] | None,
		) -> H.HExpr | None:
			"""
			Rewrite a syntactic member call `x.member(...)` when `x` is a module alias.

			MVP surface rule (pinned):
			  import lib as x
			  x.foo(1, 2)   // call exported function foo from module lib
			  x.Point(...)  // call struct constructor Point from module lib

			We do *not* create a runtime module object. Instead, we resolve the
			member at compile time and rewrite the callee to a fully-qualified
			callable symbol (`lib::foo`) or an unqualified struct constructor (`Point`).

			Note on representation: in stage1 HIR, a `.`-call like `x.foo(...)` is
			represented as `HMethodCall(receiver=x, method_name=\"foo\", ...)` (method
			sugar). We reuse that syntactic form for module-qualified access and
			rewrite it here into a plain `HCall` once we confirm `x` is a module alias.
			"""
			if not isinstance(receiver, H.HVar):
				return None
			if receiver.binding_id is not None:
				# Local/param shadowing wins: `x.foo` refers to the local `x`, not a module.
				return None
			alias = receiver.name
			mod = file_module_aliases.get(alias)
			if mod is None:
				return None
			vals = exported_value_names(mod)
			types = exported_type_names(mod)
			structs = exported_struct_names(mod)
			if member in vals:
				return H.HCall(
					fn=H.HVar(name=_qualify_fn_name(mod, member)),
					args=args,
					kwargs=kwargs,
					type_args=type_args,
				)
			if member in structs:
				# Constructor call through a module alias. MVP supports only struct ctors.
				def_mod, def_name = reexported_type_targets_by_module.get(mod, {}).get("structs", {}).get(member, (mod, member))
				struct_id = shared_type_table.get_nominal(kind=TypeKind.STRUCT, module_id=def_mod, name=def_name)
				if struct_id is None:
					diagnostics.append(
						Diagnostic(
							message=f"module-qualified constructor call '{alias}.{member}(...)' is only supported for structs in MVP",
							severity="error",
							span=getattr(receiver, "loc", Span()),
						)
					)
					return None
				# Rewrite to an internal fully-qualified constructor name so later
				# phases can resolve it deterministically even when multiple modules
				# define the same short type name.
				return H.HCall(
					fn=H.HVar(name=f"{def_mod}::{def_name}"),
					args=args,
					kwargs=kwargs,
					type_args=type_args,
				)
			available = ", ".join(sorted(vals | types))
			notes = (
				[f"available exports: {available}"]
				if available
				else [f"module '{mod}' exports nothing (private by default)"]
			)
			diagnostics.append(
				Diagnostic(
					message=f"module '{mod}' does not export symbol '{member}'",
					severity="error",
					span=getattr(receiver, "loc", Span()),
					notes=notes,
				)
			)
			return None

		def walk_block(b: H.HBlock, *, bound: set[str]) -> None:
			scope_bound = set(bound)
			for st in b.statements:
				walk_stmt(st, bound=scope_bound)
				if isinstance(st, H.HLet):
					scope_bound.add(st.name)

		def walk_expr(expr: H.HExpr, *, bound: set[str]) -> H.HExpr:
			# Module-qualified access: the surface syntax is `x.foo(...)`. Stage1
			# initially represents this as `HMethodCall`, so we rewrite that form
			# when `x` resolves to a module alias in the current file.
			if isinstance(expr, H.HMethodCall):
				expr.receiver = walk_expr(expr.receiver, bound=bound)
				expr.args = [walk_expr(a, bound=bound) for a in expr.args]
				for kw in getattr(expr, "kwargs", []) or []:
					if getattr(kw, "value", None) is not None:
						kw.value = walk_expr(kw.value, bound=bound)
				rewritten = _rewrite_module_qualified_call(
					receiver=expr.receiver,
					member=expr.method_name,
					args=expr.args,
					kwargs=getattr(expr, "kwargs", []) or [],
					type_args=getattr(expr, "type_args", None),
				)
				if rewritten is not None:
					return rewritten
				return expr

			if isinstance(expr, H.HCall):
				expr.fn = walk_expr(expr.fn, bound=bound)
				expr.args = [walk_expr(a, bound=bound) for a in expr.args]
				for kw in getattr(expr, "kwargs", []) or []:
					if getattr(kw, "value", None) is not None:
						kw.value = walk_expr(kw.value, bound=bound)
				# Resolve direct calls that name a local/imported/free function.
				if isinstance(expr.fn, H.HVar):
					expr.fn.name = rewrite_name(expr.fn.name, bound=bound)
				elif isinstance(expr.fn, H.HField) and isinstance(expr.fn.subject, H.HVar):
					# Handle the (rarer) explicit field-call form: `(x.foo)(...)`.
					q = _rewrite_module_qualified_call(
						receiver=expr.fn.subject,
						member=expr.fn.name,
						args=expr.args,
						kwargs=getattr(expr, "kwargs", []) or [],
						type_args=getattr(expr, "type_args", None),
					)
					if isinstance(q, H.HCall):
						# Preserve the rewritten call and ignore the original callee expression.
						return q
				return expr

			if isinstance(expr, H.HVar):
				expr.name = rewrite_const_name(expr.name, bound=bound)
				return expr

			if isinstance(expr, H.HField) and isinstance(expr.subject, H.HVar) and expr.subject.binding_id is None:
				mod = file_module_aliases.get(expr.subject.name)
				if mod is not None:
					if expr.name in exported_value_names(mod):
						return H.HVar(name=_qualify_fn_name(mod, expr.name))
					if expr.name in exported_const_names(mod):
						# Module-qualified const access always targets the module’s own
						# const table. Const re-exports are materialized by copying the
						# literal value into the exporting module, so consumers do not
						# need to reference the origin module.
						return H.HVar(name=f"{mod}::{expr.name}")
					# Note: module-qualified type names are handled in type positions
					# via TypeExpr.module_id. Expression-position `x.Point` without
					# call is not a supported surface construct in MVP.
				return expr

			# Generic recursion for other expression shapes.
			for k, child in list(getattr(expr, "__dict__", {}).items()):
				if isinstance(child, H.HExpr):
					setattr(expr, k, walk_expr(child, bound=bound))
				elif isinstance(child, H.HBlock):
					walk_block(child, bound=bound)
				elif isinstance(child, list):
					new_list = []
					for it in child:
						if isinstance(it, H.HExpr):
							new_list.append(walk_expr(it, bound=bound))
						elif isinstance(it, H.HBlock):
							walk_block(it, bound=bound)
							new_list.append(it)
						# Expression-form arms (match/try) live under expression nodes and
						# must be handled here so binders introduce lexical scopes.
						elif hasattr(H, "HMatchArm") and isinstance(it, getattr(H, "HMatchArm")):
							arm_bound = set(bound)
							for bname in getattr(it, "binders", []) or []:
								arm_bound.add(bname)
							walk_block(it.block, bound=arm_bound)
							if getattr(it, "result", None) is not None:
								it.result = walk_expr(it.result, bound=arm_bound)
							new_list.append(it)
						elif hasattr(H, "HTryExprArm") and isinstance(it, getattr(H, "HTryExprArm")):
							arm_bound = set(bound)
							if getattr(it, "binder", None):
								arm_bound.add(it.binder)
							walk_block(it.block, bound=arm_bound)
							if getattr(it, "result", None) is not None:
								it.result = walk_expr(it.result, bound=arm_bound)
							new_list.append(it)
						else:
							new_list.append(it)
					setattr(expr, k, new_list)
			return expr

		def walk_stmt(stmt: H.HStmt, *, bound: set[str]) -> None:
			if isinstance(stmt, H.HTry):
				walk_block(stmt.body, bound=bound)
				for arm in stmt.catches:
					arm_bound = set(bound)
					if arm.binder:
						arm_bound.add(arm.binder)
					walk_block(arm.block, bound=arm_bound)
				return
			for k, child in list(getattr(stmt, "__dict__", {}).items()):
				if isinstance(child, H.HExpr):
					setattr(stmt, k, walk_expr(child, bound=bound))
				elif isinstance(child, H.HBlock):
					walk_block(child, bound=bound)
				elif isinstance(child, list):
					new_list = []
					for it in child:
						if isinstance(it, H.HStmt):
							walk_stmt(it, bound=bound)
							new_list.append(it)
						elif isinstance(it, H.HExpr):
							new_list.append(walk_expr(it, bound=bound))
						elif isinstance(it, H.HBlock):
							walk_block(it, bound=bound)
							new_list.append(it)
						elif hasattr(H, "HCatchArm") and isinstance(it, getattr(H, "HCatchArm")):
							arm_bound = set(bound)
							if getattr(it, "binder", None):
								arm_bound.add(it.binder)
							walk_block(it.block, bound=arm_bound)
							new_list.append(it)
						elif hasattr(H, "HMatchArm") and isinstance(it, getattr(H, "HMatchArm")):
							arm_bound = set(bound)
							for bname in getattr(it, "binders", []) or []:
								arm_bound.add(bname)
							walk_block(it.block, bound=arm_bound)
							if getattr(it, "result", None) is not None:
								it.result = walk_expr(it.result, bound=arm_bound)
							new_list.append(it)
						elif hasattr(H, "HTryExprArm") and isinstance(it, getattr(H, "HTryExprArm")):
							arm_bound = set(bound)
							if getattr(it, "binder", None):
								arm_bound.add(it.binder)
							walk_block(it.block, bound=arm_bound)
							if getattr(it, "result", None) is not None:
								it.result = walk_expr(it.result, bound=arm_bound)
							new_list.append(it)
						else:
							new_list.append(it)
					setattr(stmt, k, new_list)

		initial_bound = set(param_names)
		walk_block(block, bound=initial_bound)

	# Apply rewrite to each function body using its origin file’s import environment.
	fn_origin_file: dict[str, Path] = {}
	for _mid, origins in origin_by_module.items():
		for fn_id, src_path in origins.items():
			fn_symbol = fn_symbol_by_id.get(fn_id, _qualify_fn_name(fn_id.module, fn_id.name))
			fn_origin_file[fn_symbol] = src_path

	for fn_id, block in all_func_hirs.items():
		fn_symbol = fn_symbol_by_id.get(fn_id, _qualify_fn_name(fn_id.module, fn_id.name))
		_rewrite_calls_in_block(
			block,
			module_id=fn_owner_module.get(fn_id, "main"),
			fn_id=fn_id,
			fn_symbol=fn_symbol,
			origin_file=fn_origin_file.get(fn_symbol),
		)

	# Cross-module exception code collision detection: event codes are derived
	# from the canonical event FQN (`module:Event`). Collisions are extremely
	# unlikely, but if they happen we must diagnose them deterministically.
	payload_seen: dict[int, str] = {}
	for fqn, code in exc_catalog.items():
		payload = code & PAYLOAD_MASK
		other = payload_seen.get(payload)
		if other is not None and other != fqn:
			diagnostics.append(Diagnostic(message=f"exception code collision between '{other}' and '{fqn}' (payload {payload})", severity="error", span=Span()))
		else:
			payload_seen[payload] = fqn

	return all_func_hirs, all_sigs, fn_ids_by_name, shared_type_table, exc_catalog, module_exports, diagnostics


def _lower_parsed_program_to_hir(
	prog: parser_ast.Program,
	*,
	diagnostics: list[Diagnostic] | None = None,
	type_table: TypeTable | None = None,
) -> Tuple[Dict[FunctionId, H.HBlock], Dict[FunctionId, FnSignature], Dict[str, List[FunctionId]], "TypeTable", Dict[str, int], List[Diagnostic]]:
	"""
	Lower an already-parsed `Program` to HIR/signatures/type table.

	This is shared by both single-file and multi-file entry points.
	"""
	diagnostics = list(diagnostics or [])
	module_name = getattr(prog, "module", None)
	module_id = module_name or "main"
	func_hirs: Dict[FunctionId, H.HBlock] = {}
	fn_ids_by_name: Dict[str, List[FunctionId]] = {}
	decls: list[_FrontendDecl] = []
	signatures: Dict[FunctionId, FnSignature] = {}
	lowerer = AstToHIR()
	lowerer._module_name = module_name
	from lang2.driftc.traits.world import build_trait_world
	# Track method keys to prevent duplicate method bodies within the same impl.
	method_keys: set[tuple[tuple | None, tuple, str]] = set()  # (trait_key, impl_target_key, method_name)
	module_function_names: set[str] = {fn.name for fn in getattr(prog, "functions", []) or []}
	exception_schemas: dict[str, tuple[str, list[str]]] = {}
	struct_defs = list(getattr(prog, "structs", []) or [])
	variant_defs = list(getattr(prog, "variants", []) or [])
	exception_catalog: dict[str, int] = _build_exception_catalog(prog.exceptions, module_name, diagnostics)
	for exc in prog.exceptions:
		fqn = f"{module_name}:{exc.name}" if module_name else exc.name
		field_names = [arg.name for arg in getattr(exc, "args", [])]
		exception_schemas[fqn] = (fqn, field_names)
	# Build a TypeTable early so we can register user-defined type names (structs)
	# before resolving function signatures. This prevents `resolve_opaque_type`
	# from minting unrelated placeholder TypeIds for struct names.
	type_table = type_table or TypeTable()
	_prime_builtins(type_table)
	# Build a per-module TraitWorld and stash it on the shared TypeTable so later
	# phases can enforce requirements without re-parsing sources.
	world = build_trait_world(prog, diagnostics=diagnostics)
	trait_worlds = getattr(type_table, "trait_worlds", None)
	if not isinstance(trait_worlds, dict):
		trait_worlds = {}
	trait_worlds[module_id] = world
	type_table.trait_worlds = trait_worlds

	# Register module-local compile-time constants.
	#
	# MVP: const initializers are restricted to literal values (or unary +/- applied
	# to a numeric literal). We evaluate them here so later phases can
	# treat const references as typed literals without requiring whole-program
	# evaluation infrastructure.
	def _eval_const_value(expr: parser_ast.Expr) -> object | None:
		if isinstance(expr, parser_ast.Literal):
			return expr.value
		if isinstance(expr, parser_ast.Unary) and getattr(expr, "op", None) in ("-", "+"):
			inner = getattr(expr, "operand", None)
			if isinstance(inner, parser_ast.Literal) and isinstance(inner.value, (int, float)):
				if getattr(expr, "op", None) == "-":
					return -inner.value
				return inner.value
		return None

	for c in getattr(prog, "consts", []) or []:
		decl_ty = resolve_opaque_type(c.type_expr, type_table, module_id=module_id)
		val = _eval_const_value(c.value)
		if val is None:
			diagnostics.append(
				Diagnostic(
					phase="typecheck",
					message=(
						f"const '{c.name}' initializer must be a compile-time literal in MVP "
						"(Int/Uint/Bool/String/Float, optionally with unary '+' or '-')"
					),
					severity="error",
					span=Span.from_loc(getattr(c, "loc", None)),
				)
			)
			continue
		# Enforce that the declared type matches the literal kind exactly.
		#
		# Consts are intentionally strict: they form part of the module interface,
		# and packages must be able to embed them deterministically without
		# re-running the evaluator.
		ok = False
		if decl_ty == type_table.ensure_int() and isinstance(val, int):
			ok = True
		elif decl_ty == type_table.ensure_uint() and isinstance(val, int) and val >= 0:
			ok = True
		elif decl_ty == type_table.ensure_bool() and isinstance(val, bool):
			ok = True
		elif decl_ty == type_table.ensure_string() and isinstance(val, str):
			ok = True
		elif decl_ty == type_table.ensure_float() and isinstance(val, float):
			ok = True
		if not ok:
			diagnostics.append(
				Diagnostic(
					phase="typecheck",
					message=f"const '{c.name}' declared type does not match initializer value",
					severity="error",
					span=Span.from_loc(getattr(c, "loc", None)),
				)
			)
			continue
		type_table.define_const(module_id=module_id, name=c.name, type_id=decl_ty, value=val)
	# Prelude: `Optional<T>` is required for iterator-style `for` desugaring and
	# other control-flow sugar. Until modules are supported, the compiler injects
	# a canonical `Optional<T>` variant base into every compilation unit unless
	# user code declares its own `variant Optional<...>`.
	#
	# MVP contract:
	#   variant Optional<T> { Some(value: T), None }
	if not any(getattr(v, "name", None) == "Optional" for v in variant_defs) and type_table.get_variant_base(
		module_id="lang.core", name="Optional"
	) is None:
		type_table.declare_variant(
			"lang.core",
			"Optional",
			["T"],
			[
				VariantArmSchema(
					name="Some",
					fields=[VariantFieldSchema(name="value", type_expr=GenericTypeExpr.param(0))],
				),
				VariantArmSchema(name="None", fields=[]),
			],
		)
	# Declare all struct names first (placeholder field types) to support recursion.
	for s in struct_defs:
		field_names = [f.name for f in getattr(s, "fields", [])]
		try:
			type_table.declare_struct(module_id, s.name, field_names)
		except ValueError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=Span.from_loc(getattr(s, "loc", None))))
	# Declare all variant names/schemas next so type resolution can instantiate
	# variants (e.g., Optional<Int>) while resolving later annotations/fields.
	for v in variant_defs:
		arms: list[VariantArmSchema] = []
		for arm in getattr(v, "arms", []) or []:
			fields = [
				VariantFieldSchema(
					name=f.name,
					type_expr=_generic_type_expr_from_parser(f.type_expr, type_params=list(getattr(v, "type_params", []) or [])),
				)
				for f in getattr(arm, "fields", []) or []
			]
			arms.append(VariantArmSchema(name=arm.name, fields=fields))
		try:
			type_table.declare_variant(
				module_id,
				v.name,
				list(getattr(v, "type_params", []) or []),
				arms,
			)
		except ValueError as err:
			diagnostics.append(Diagnostic(message=str(err), severity="error", span=Span.from_loc(getattr(v, "loc", None))))
	# Fill field TypeIds in a second pass now that all names exist.
	for s in struct_defs:
		struct_id = type_table.require_nominal(kind=TypeKind.STRUCT, module_id=module_id, name=s.name)
		field_types = []
		for f in getattr(s, "fields", []):
			ft = resolve_opaque_type(f.type_expr, type_table, module_id=module_id)
			# MVP escape policy: references cannot be stored in long-lived memory.
			# Struct fields are long-lived by construction, so `struct S(r: &T)` is
			# rejected early (before lowering/typecheck) with a source-anchored
			# diagnostic.
			try:
				td = type_table.get(ft)
			except Exception:
				td = None
			if td is not None and td.kind is TypeKind.REF:
				diagnostics.append(
					Diagnostic(
						message=f"struct '{s.name}' field '{f.name}' cannot have a reference type in MVP",
						severity="error",
						span=Span.from_loc(getattr(f.type_expr, "loc", getattr(f, "loc", None))),
					)
				)
			field_types.append(ft)
		type_table.define_struct_fields(struct_id, field_types)
	# After all variant schemas are known and structs are declared, finalize
	# non-generic variants so their concrete arm types are available.
	type_table.finalize_variants()
	seen_sig: dict[tuple, object | None] = {}
	name_ord: dict[str, int] = {}
	for fn in prog.functions:
		sig_key = (
			module_id,
			fn.name,
			len(getattr(fn, "params", []) or []),
			tuple(_type_expr_key(p.type_expr) for p in getattr(fn, "params", []) or []),
		)
		if sig_key in seen_sig:
			diagnostics.append(
				Diagnostic(
					message=f"duplicate function signature for '{fn.name}'",
					severity="error",
					span=Span.from_loc(getattr(fn, "loc", None)),
				)
			)
			continue
		seen_sig[sig_key] = getattr(fn, "loc", None)
		ordinal = name_ord.get(fn.name, 0)
		name_ord[fn.name] = ordinal + 1
		fn_id = FunctionId(module=module_id, name=fn.name, ordinal=ordinal)
		qualified_name = _qualify_fn_name(module_id, fn.name)
		fn_ids_by_name.setdefault(qualified_name, []).append(fn_id)
		decl_decl = _decl_from_parser_fn(fn, fn_id=fn_id)
		decl_decl.module = module_name
		# Reject FnResult in surface type annotations (return or parameter types).
		# FnResult is an internal ABI carrier in lang2, not a user-facing type.
		if _typeexpr_uses_internal_fnresult(decl_decl.return_type):
			_report_internal_fnresult_in_surface_type(
				kind="function",
				symbol=fn.name,
				loc=getattr(fn.return_type, "loc", getattr(fn, "loc", None)),
				diagnostics=diagnostics,
			)
		for p in getattr(fn, "params", []) or []:
			if _typeexpr_uses_internal_fnresult(p.type_expr):
				_report_internal_fnresult_in_surface_type(
					kind="parameter",
					symbol=f"{fn.name}({p.name})",
					loc=getattr(p.type_expr, "loc", getattr(p, "loc", None)),
					diagnostics=diagnostics,
				)
			if getattr(p, "non_escaping", False) and not _typeexpr_is_callable(p.type_expr):
				diagnostics.append(
					_diagnostic(
						f"nonescaping parameter '{fn.name}({p.name})' must have a callable type",
						getattr(p.type_expr, "loc", getattr(p, "loc", None)),
					)
				)
		decls.append(decl_decl)
		stmt_block = _convert_block(fn.body)
		param_names = [p.name for p in getattr(fn, "params", []) or []]
		hir_block = lowerer.lower_function_block(stmt_block, param_names=param_names)
		func_hirs[fn_id] = hir_block
	# Methods inside implement blocks.
	for impl in getattr(prog, "implements", []):
		# Reject reference-qualified impl headers in v1 (must be nominal types).
		if getattr(impl.target, "name", None) in {"&", "&mut"}:
			diagnostics.append(
				Diagnostic(
					message="implement header must use a nominal type, not a reference type",
					severity="error",
					span=Span.from_loc(getattr(impl, "loc", None)),
				)
			)
			continue
		for fn in impl.methods:
			# Note: receiver shape/name/type are semantic rules enforced by the
			# typecheck phase. The parser adapter stays structural-only here so
			# related errors consistently report as typecheck diagnostics.
			receiver_ty = fn.params[0].type_expr if fn.params else None
			self_mode: str | None = None
			if receiver_ty is not None:
				self_mode = "value"
				if receiver_ty.name == "&":
					self_mode = "ref"
				elif receiver_ty.name == "&mut":
					self_mode = "ref_mut"

			trait_key = _type_expr_key(impl.trait) if getattr(impl, "trait", None) is not None else None
			trait_str = _type_expr_key_str(impl.trait) if getattr(impl, "trait", None) is not None else None
			# Compute the canonical symbol for this method early so any diagnostics
			# (including type-annotation validation) can reference it.
			target_key = _type_expr_key(impl.target)
			target_str = _type_expr_key_str(impl.target)
			if trait_str:
				symbol_name = f"{target_str}::{trait_str}::{fn.name}"
			else:
				symbol_name = f"{target_str}::{fn.name}"

			params = [
				_FrontendParam(
					p.name,
					p.type_expr,
					getattr(p, "loc", None),
					non_escaping=getattr(p, "non_escaping", False),
				)
				for p in fn.params
			]
			# Reject FnResult in method surface type annotations too.
			if _typeexpr_uses_internal_fnresult(fn.return_type):
				_report_internal_fnresult_in_surface_type(
					kind="method",
					symbol=symbol_name,
					loc=getattr(fn.return_type, "loc", getattr(fn, "loc", None)),
					diagnostics=diagnostics,
				)
			for p in getattr(fn, "params", []) or []:
				if _typeexpr_uses_internal_fnresult(p.type_expr):
					_report_internal_fnresult_in_surface_type(
						kind="parameter",
						symbol=f"{symbol_name}({p.name})",
						loc=getattr(p.type_expr, "loc", getattr(p, "loc", None)),
						diagnostics=diagnostics,
					)
				if getattr(p, "non_escaping", False) and not _typeexpr_is_callable(p.type_expr):
					diagnostics.append(
						_diagnostic(
							f"nonescaping parameter '{symbol_name}({p.name})' must have a callable type",
							getattr(p.type_expr, "loc", getattr(p, "loc", None)),
						)
					)
			if fn.name in module_function_names:
				diagnostics.append(
					Diagnostic(
						message=f"method '{fn.name}' conflicts with existing free function of the same name",
						severity="error",
						span=Span.from_loc(getattr(fn, "loc", None)),
					)
				)
				continue
			key = (trait_key, target_key, fn.name)
			if key in method_keys:
				impl_label = f"{trait_str} for {target_str}" if trait_str else target_str
				diagnostics.append(
					Diagnostic(
						message=f"duplicate method definition '{fn.name}' for type '{impl_label}'",
						severity="error",
						span=Span.from_loc(getattr(fn, "loc", None)),
					)
				)
				continue
			method_keys.add(key)
			ordinal = name_ord.get(symbol_name, 0)
			name_ord[symbol_name] = ordinal + 1
			fn_id = FunctionId(module=module_id, name=symbol_name, ordinal=ordinal)
			fn_ids_by_name.setdefault(symbol_name, []).append(fn_id)
			decls.append(
				_FrontendDecl(
					fn_id,
					symbol_name,
					fn.orig_name,
					fn.type_params,
					list(getattr(fn, "type_param_locs", []) or []),
					params,
					fn.return_type,
					getattr(fn, "loc", None),
					is_method=True,
					self_mode=self_mode,
					impl_target=impl.target,
					module=module_name,
				)
			)
			stmt_block = _convert_block(fn.body)
			# Enable implicit `self` member lookup for method bodies (spec §3.9).
			# Unknown identifiers may resolve to fields/methods on `self` after
			# locals and module-scope items are considered.
			#
			# We only need names here; semantic validation happens in the typed checker.
			# Collect receiver field names for implicit `self` member lookup.
			#
			# IMPORTANT: structs are module-scoped. We must resolve the impl target
			# in the current module context, not by bare name.
			field_names: set[str] = set()
			try:
				origin_mod = getattr(impl.target, "module_id", None) or module_name or "main"
				struct_id = type_table.get_nominal(kind=TypeKind.STRUCT, module_id=origin_mod, name=impl.target.name)
				if struct_id is not None:
					td = type_table.get(struct_id)
					if td.field_names is not None:
						field_names = set(td.field_names)
			except Exception:
				field_names = set()
			method_names: set[str] = {m.name for m in getattr(impl, "methods", []) or []}
			param_names = [p.name for p in getattr(fn, "params", []) or []]
			if fn.params and self_mode is not None:
				lowerer._push_implicit_self(
					self_name=str(getattr(fn.params[0], "name", "self")),
					self_mode=self_mode,
					field_names=field_names,
					method_names=method_names,
					module_function_names=module_function_names,
				)
				try:
					hir_block = lowerer.lower_function_block(stmt_block, param_names=param_names)
				finally:
					lowerer._pop_implicit_self()
			else:
				hir_block = lowerer.lower_function_block(stmt_block, param_names=param_names)
			func_hirs[fn_id] = hir_block
	# Build signatures with resolved TypeIds from parser decls.
	from lang2.driftc.type_resolver import resolve_program_signatures

	type_table, sigs = resolve_program_signatures(decls, table=type_table)
	signatures.update(sigs)
	# Resolve function require subjects (T -> TypeParamId) now that signatures exist.
	from lang2.driftc.traits.world import resolve_fn_require_subjects

	resolve_fn_require_subjects(world, signatures)
	# Thread exception schemas through the shared type table for downstream validators.
	#
	# In a multi-module build, this function may be called repeatedly with a
	# shared TypeTable; preserve previously registered schemas and extend them.
	prev_schemas = getattr(type_table, "exception_schemas", None)
	if not isinstance(prev_schemas, dict):
		prev_schemas = {}
	prev_schemas.update(exception_schemas)
	type_table.exception_schemas = prev_schemas
	return func_hirs, signatures, fn_ids_by_name, type_table, exception_catalog, diagnostics


def parse_drift_to_hir(path: Path) -> Tuple[Dict[FunctionId, H.HBlock], Dict[FunctionId, FnSignature], Dict[str, List[FunctionId]], "TypeTable", Dict[str, int], List[Diagnostic]]:
	"""
	Parse a Drift source file into lang2 HIR blocks + FnSignatures + TypeTable.

	Collects parser/adapter diagnostics (e.g., duplicate functions) instead of
	throwing, so callers can report them alongside later pipeline checks.
	"""
	source = path.read_text()
	try:
		prog = _parser.parse_program(source)
	except _parser.FStringParseError as err:
		return {}, {}, {}, TypeTable(), {}, [Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc))]
	except _parser.QualifiedMemberParseError as err:
		return {}, {}, {}, TypeTable(), {}, [Diagnostic(message=str(err), severity="error", span=_span_in_file(path, err.loc))]
	except UnexpectedInput as err:
		span = Span(
			file=str(path),
			line=getattr(err, "line", None),
			column=getattr(err, "column", None),
			raw=err,
		)
		return {}, {}, {}, TypeTable(), {}, [Diagnostic(message=str(err), severity="error", span=span)]
	return _lower_parsed_program_to_hir(prog, diagnostics=[])


__all__ = ["parse_drift_to_hir", "parse_drift_files_to_hir", "parse_drift_workspace_to_hir"]

[==== File: staged/lang2/driftc/traits/enforce.py =====]
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Iterable, List, Optional, Set, Tuple

from lang2.driftc.core.diagnostics import Diagnostic
from lang2.driftc.core.span import Span
from lang2.driftc import stage1 as H
from lang2.driftc.parser import ast as parser_ast
from lang2.driftc.method_resolver import MethodResolution
from lang2.driftc.traits.solver import Env, ProofStatus, prove_expr
from lang2.driftc.core.function_id import FunctionId, function_symbol
from lang2.driftc.traits.world import TraitWorld, TypeKey, type_key_from_typeid
from lang2.driftc.core.type_resolve_common import resolve_opaque_type


@dataclass
class TraitEnforceResult:
	diagnostics: List[Diagnostic]


def _collect_exprs(expr: H.HExpr, out: List[H.HExpr]) -> None:
	out.append(expr)
	for field in getattr(expr, "__dataclass_fields__", {}) or {}:
		val = getattr(expr, field, None)
		if isinstance(val, H.HExpr):
			_collect_exprs(val, out)
		elif isinstance(val, list):
			for item in val:
				if isinstance(item, H.HExpr):
					_collect_exprs(item, out)


def _walk_block(block: H.HBlock, out: List[H.HExpr]) -> None:
	for stmt in block.statements:
		if isinstance(stmt, H.HExprStmt):
			_collect_exprs(stmt.expr, out)
		elif isinstance(stmt, H.HLet):
			_collect_exprs(stmt.value, out)
		elif isinstance(stmt, H.HAssign):
			_collect_exprs(stmt.value, out)
		elif isinstance(stmt, H.HAugAssign):
			_collect_exprs(stmt.value, out)
		elif isinstance(stmt, H.HIf):
			if isinstance(stmt.cond, H.HExpr):
				_collect_exprs(stmt.cond, out)
			_walk_block(stmt.then_block, out)
			if stmt.else_block:
				_walk_block(stmt.else_block, out)
		elif isinstance(stmt, H.HLoop):
			_walk_block(stmt.body, out)
		elif isinstance(stmt, H.HTry):
			_walk_block(stmt.body, out)
			for arm in stmt.catches:
				_walk_block(arm.block, out)
		elif isinstance(stmt, H.HReturn) and stmt.value is not None:
			_collect_exprs(stmt.value, out)


def collect_used_type_keys(
	typed_fns: Dict[FunctionId, object],
	type_table: object,
	signatures: Dict[FunctionId, object],
) -> Set[TypeKey]:
	used: Set[TypeKey] = set()
	for sig in signatures.values():
		for tid in getattr(sig, "param_type_ids", []) or []:
			if tid is None:
				continue
			used.add(type_key_from_typeid(type_table, tid))
		ret = getattr(sig, "return_type_id", None)
		if ret is not None:
			used.add(type_key_from_typeid(type_table, ret))
	for typed_fn in typed_fns.values():
		for tid in getattr(typed_fn, "binding_types", {}).values():
			if tid is None:
				continue
			used.add(type_key_from_typeid(type_table, tid))
		for tid in getattr(typed_fn, "expr_types", {}).values():
			if tid is None:
				continue
			used.add(type_key_from_typeid(type_table, tid))
	return used


def _normalize_type_key(key: TypeKey, *, module_name: str) -> TypeKey:
	if key.module is None:
		return TypeKey(module=module_name, name=key.name, args=key.args)
	return key


def _collect_trait_subjects(expr: parser_ast.TraitExpr, out: Set[object]) -> None:
	if isinstance(expr, parser_ast.TraitIs):
		out.add(expr.subject)
	elif isinstance(expr, (parser_ast.TraitAnd, parser_ast.TraitOr)):
		_collect_trait_subjects(expr.left, out)
		_collect_trait_subjects(expr.right, out)
	elif isinstance(expr, parser_ast.TraitNot):
		_collect_trait_subjects(expr.expr, out)


def enforce_struct_requires(
	world: TraitWorld,
	used_types: Iterable[TypeKey],
	*,
	module_name: str,
) -> TraitEnforceResult:
	diags: List[Diagnostic] = []
	env = Env(default_module=module_name)
	for ty in used_types:
		ty_norm = _normalize_type_key(ty, module_name=module_name)
		req = world.requires_by_struct.get(ty_norm)
		if req is None:
			continue
		subst = {"Self": ty_norm}
		res = prove_expr(world, env, subst, req)
		if res.status is not ProofStatus.PROVED:
			diags.append(
				Diagnostic(
					message=f"trait requirements not met for struct '{ty.name}'",
					severity="error",
					span=Span.from_loc(getattr(req, "loc", None)),
				)
			)
	return TraitEnforceResult(diags)


def enforce_fn_requires(
	world: TraitWorld,
	typed_fn: object,
	type_table: object,
	*,
	module_name: str,
	signatures: Dict[FunctionId, object],
) -> TraitEnforceResult:
	diags: List[Diagnostic] = []
	env = Env(default_module=module_name)
	exprs: List[H.HExpr] = []
	_walk_block(getattr(typed_fn, "body"), exprs)
	expr_types = getattr(typed_fn, "expr_types", {})
	call_resolutions = getattr(typed_fn, "call_resolutions", {}) or {}
	seen: Set[Tuple[FunctionId, Tuple[TypeKey, ...]]] = set()
	symbol_to_id = {function_symbol(fid): fid for fid in signatures.keys()}
	for expr in exprs:
		if not isinstance(expr, H.HCall) or not isinstance(expr.fn, H.HVar):
			continue
		decl_name = expr.fn.name
		resolution = call_resolutions.get(id(expr))
		if isinstance(resolution, MethodResolution):
			# Trait requires are currently declared on free functions only.
			continue
		fn_id = getattr(resolution, "fn_id", None)
		if fn_id is None:
			fn_id = symbol_to_id.get(decl_name)
		if fn_id is None:
			continue
		req = world.requires_by_fn.get(fn_id)
		if req is None:
			continue
		sig = signatures.get(fn_id)
		subst: Dict[object, TypeKey] = {}
		subjects: Set[object] = set()
		_collect_trait_subjects(req, subjects)
		arg_keys: List[TypeKey] = []
		for arg in expr.args:
			tid = expr_types.get(id(arg))
			if tid is None:
				continue
			arg_keys.append(_normalize_type_key(type_key_from_typeid(type_table, tid), module_name=module_name))
		if sig and getattr(sig, "type_params", None):
			type_params = list(getattr(sig, "type_params", []) or [])
			type_args = getattr(expr, "type_args", None) or []
			if type_args and len(type_args) == len(type_params):
				for idx, tp in enumerate(type_params):
					if tp.id in subjects:
						ty_id = resolve_opaque_type(type_args[idx], type_table, module_id=module_name)
						subst[tp.id] = _normalize_type_key(type_key_from_typeid(type_table, ty_id), module_name=module_name)
		subst_key = tuple(arg_keys)
		seen_key = (fn_id, subst_key)
		if seen_key in seen:
			continue
		seen.add(seen_key)
		res = prove_expr(world, env, subst, req)
		if res.status is not ProofStatus.PROVED:
			diags.append(
				Diagnostic(
					message=f"trait requirements not met for call to '{expr.fn.name}'",
					severity="error",
					span=getattr(expr, "loc", Span()),
				)
			)
	return TraitEnforceResult(diags)

[==== File: staged/lang2/driftc/traits/solver.py =====]
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Dict, List, Optional, Set, Tuple

from lang2.driftc.parser import ast as parser_ast
from .world import TraitWorld, TraitKey, TypeKey, ImplDef, trait_key_from_expr


class ProofStatus(Enum):
	PROVED = auto()
	REFUTED = auto()
	UNKNOWN = auto()
	AMBIGUOUS = auto()


@dataclass
class ProofResult:
	status: ProofStatus
	reasons: List[str] = field(default_factory=list)
	used_impls: List[int] = field(default_factory=list)


@dataclass
class Env:
	assumed_true: Set[Tuple[object, TraitKey]] = field(default_factory=set)
	assumed_false: Set[Tuple[object, TraitKey]] = field(default_factory=set)
	default_module: Optional[str] = None


CacheKey = Tuple[object, str, Optional[TypeKey]]


def _type_key_str(key: TypeKey) -> str:
	module = key.module
	base = f"{module}.{key.name}" if module else key.name
	if not key.args:
		return base
	args = ", ".join(_type_key_str(a) for a in key.args)
	return f"{base}<{args}>"


def _trait_key_str(key: TraitKey) -> str:
	return f"{key.module}.{key.name}" if key.module else key.name


def _impl_sort_key(impl: ImplDef) -> Tuple[str, str, int, int]:
	trait_str = _trait_key_str(impl.trait)
	target_str = _type_key_str(impl.target)
	loc = getattr(impl.loc, "loc", None) if hasattr(impl.loc, "loc") else impl.loc
	line = getattr(loc, "line", 0) or 0
	col = getattr(loc, "column", 0) or 0
	return (trait_str, target_str, line, col)


def prove_expr(
	world: TraitWorld,
	env: Env,
	subst: Dict[object, TypeKey],
	expr: parser_ast.TraitExpr,
	*,
	_cache: Optional[Dict[CacheKey, ProofResult]] = None,
	_in_progress: Optional[Set[Tuple[str, TraitKey, Optional[TypeKey]]]] = None,
) -> ProofResult:
	if isinstance(expr, parser_ast.TraitIs):
		trait_key = trait_key_from_expr(expr.trait, default_module=env.default_module)
		return prove_is(world, env, subst, expr.subject, trait_key, _cache=_cache, _in_progress=_in_progress)
	if isinstance(expr, parser_ast.TraitAnd):
		left = prove_expr(world, env, subst, expr.left, _cache=_cache, _in_progress=_in_progress)
		if left.status is ProofStatus.REFUTED:
			return left
		right = prove_expr(world, env, subst, expr.right, _cache=_cache, _in_progress=_in_progress)
		if right.status is ProofStatus.REFUTED:
			return right
		if left.status is ProofStatus.UNKNOWN or right.status is ProofStatus.UNKNOWN:
			return ProofResult(status=ProofStatus.UNKNOWN, reasons=left.reasons + right.reasons)
		if left.status is ProofStatus.AMBIGUOUS or right.status is ProofStatus.AMBIGUOUS:
			return ProofResult(status=ProofStatus.AMBIGUOUS, reasons=left.reasons + right.reasons)
		return ProofResult(status=ProofStatus.PROVED, reasons=left.reasons + right.reasons, used_impls=left.used_impls + right.used_impls)
	if isinstance(expr, parser_ast.TraitOr):
		left = prove_expr(world, env, subst, expr.left, _cache=_cache, _in_progress=_in_progress)
		right = prove_expr(world, env, subst, expr.right, _cache=_cache, _in_progress=_in_progress)
		if left.status is ProofStatus.PROVED and right.status is ProofStatus.PROVED:
			return ProofResult(status=ProofStatus.PROVED, reasons=left.reasons + right.reasons, used_impls=left.used_impls + right.used_impls)
		if left.status is ProofStatus.PROVED:
			return left
		if right.status is ProofStatus.PROVED:
			return right
		if left.status is ProofStatus.REFUTED and right.status is ProofStatus.REFUTED:
			return ProofResult(status=ProofStatus.REFUTED, reasons=left.reasons + right.reasons)
		if left.status is ProofStatus.AMBIGUOUS or right.status is ProofStatus.AMBIGUOUS:
			return ProofResult(status=ProofStatus.AMBIGUOUS, reasons=left.reasons + right.reasons)
		return ProofResult(status=ProofStatus.UNKNOWN, reasons=left.reasons + right.reasons)
	if isinstance(expr, parser_ast.TraitNot):
		return deny_expr(world, env, subst, expr.expr, _cache=_cache, _in_progress=_in_progress)
	return ProofResult(status=ProofStatus.UNKNOWN, reasons=["unsupported trait expression"])


def deny_expr(
	world: TraitWorld,
	env: Env,
	subst: Dict[object, TypeKey],
	expr: parser_ast.TraitExpr,
	*,
	_cache: Optional[Dict[CacheKey, ProofResult]] = None,
	_in_progress: Optional[Set[Tuple[str, TraitKey, Optional[TypeKey]]]] = None,
) -> ProofResult:
	if isinstance(expr, parser_ast.TraitIs):
		trait_key = trait_key_from_expr(expr.trait, default_module=env.default_module)
		res = prove_is(world, env, subst, expr.subject, trait_key, _cache=_cache, _in_progress=_in_progress)
		if res.status is ProofStatus.PROVED:
			return ProofResult(status=ProofStatus.REFUTED, reasons=res.reasons)
		if res.status is ProofStatus.REFUTED:
			return ProofResult(status=ProofStatus.PROVED, reasons=res.reasons)
		return ProofResult(status=ProofStatus.UNKNOWN, reasons=res.reasons)
	if isinstance(expr, parser_ast.TraitAnd):
		left = deny_expr(world, env, subst, expr.left, _cache=_cache, _in_progress=_in_progress)
		right = deny_expr(world, env, subst, expr.right, _cache=_cache, _in_progress=_in_progress)
		if left.status is ProofStatus.PROVED or right.status is ProofStatus.PROVED:
			return ProofResult(status=ProofStatus.PROVED, reasons=left.reasons + right.reasons)
		if left.status is ProofStatus.REFUTED and right.status is ProofStatus.REFUTED:
			return ProofResult(status=ProofStatus.REFUTED, reasons=left.reasons + right.reasons)
		return ProofResult(status=ProofStatus.UNKNOWN, reasons=left.reasons + right.reasons)
	if isinstance(expr, parser_ast.TraitOr):
		left = deny_expr(world, env, subst, expr.left, _cache=_cache, _in_progress=_in_progress)
		if left.status is ProofStatus.REFUTED:
			return left
		right = deny_expr(world, env, subst, expr.right, _cache=_cache, _in_progress=_in_progress)
		if right.status is ProofStatus.REFUTED:
			return right
		if left.status is ProofStatus.UNKNOWN or right.status is ProofStatus.UNKNOWN:
			return ProofResult(status=ProofStatus.UNKNOWN, reasons=left.reasons + right.reasons)
		return ProofResult(status=ProofStatus.PROVED, reasons=left.reasons + right.reasons)
	if isinstance(expr, parser_ast.TraitNot):
		return prove_expr(world, env, subst, expr.expr, _cache=_cache, _in_progress=_in_progress)
	return ProofResult(status=ProofStatus.UNKNOWN, reasons=["unsupported trait expression"])


def prove_is(
	world: TraitWorld,
	env: Env,
	subst: Dict[object, TypeKey],
	subject: object,
	trait_key: TraitKey,
	*,
	_cache: Optional[Dict[CacheKey, ProofResult]] = None,
	_in_progress: Optional[Set[Tuple[str, TraitKey, Optional[TypeKey]]]] = None,
) -> ProofResult:
	cache = _cache if _cache is not None else {}
	in_progress = _in_progress if _in_progress is not None else set()
	subject_ty = subst.get(subject)
	cache_key: CacheKey = (subject, _trait_key_str(trait_key), subject_ty)
	if cache_key in cache:
		return cache[cache_key]
	if (subject, trait_key) in env.assumed_true:
		res = ProofResult(status=ProofStatus.PROVED, reasons=["assumed true"])
		cache[cache_key] = res
		return res
	if (subject, trait_key) in env.assumed_false:
		res = ProofResult(status=ProofStatus.REFUTED, reasons=["assumed false"])
		cache[cache_key] = res
		return res
	if subject_ty is None:
		res = ProofResult(status=ProofStatus.UNKNOWN, reasons=["unknown subject type"])
		cache[cache_key] = res
		return res
	if trait_key not in world.traits:
		res = ProofResult(status=ProofStatus.REFUTED, reasons=["unknown trait"])
		cache[cache_key] = res
		return res

	cycle_key = (subject, trait_key, subject_ty)
	if cycle_key in in_progress:
		res = ProofResult(status=ProofStatus.UNKNOWN, reasons=["cycle in trait requirements"])
		cache[cache_key] = res
		return res
	in_progress.add(cycle_key)
	try:
		head = subject_ty.head()
		candidates = world.impls_by_trait_target.get((trait_key, head), [])
		ordered = [(impl_id, world.impls[impl_id]) for impl_id in candidates]
		ordered.sort(key=lambda item: (_impl_sort_key(item[1]), item[0]))

		applicable: List[int] = []
		reasons: List[str] = []
		for impl_id, impl in ordered:
			if impl.target != subject_ty:
				continue
			if impl.require is not None:
				req = prove_expr(world, env, subst, impl.require, _cache=cache, _in_progress=in_progress)
				if req.status is ProofStatus.PROVED:
					applicable.append(impl_id)
					continue
				if req.status is ProofStatus.AMBIGUOUS:
					reasons.append("ambiguous impl requirement")
					continue
				if req.status is ProofStatus.UNKNOWN:
					reasons.append("impl requirement unknown")
					continue
				reasons.append("impl requirement refuted")
				continue
			applicable.append(impl_id)

		if len(applicable) == 0:
			res = ProofResult(status=ProofStatus.REFUTED, reasons=reasons or ["no applicable impls"])
		elif len(applicable) == 1:
			res = ProofResult(status=ProofStatus.PROVED, used_impls=applicable)
		else:
			res = ProofResult(status=ProofStatus.AMBIGUOUS, reasons=["multiple applicable impls"], used_impls=applicable)
		cache[cache_key] = res
		return res
	finally:
		in_progress.remove(cycle_key)


__all__ = ["Env", "ProofResult", "ProofStatus", "prove_expr", "prove_is", "deny_expr", "CacheKey"]

[==== File: staged/lang2/driftc/traits/world.py =====]
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

from lang2.driftc.core.diagnostics import Diagnostic
from lang2.driftc.core.function_id import FunctionId
from lang2.driftc.core.span import Span
from lang2.driftc.core.types_core import TypeParamId
from lang2.driftc.parser import ast as parser_ast


@dataclass(frozen=True)
class TraitKey:
	module: Optional[str]
	name: str


@dataclass(frozen=True)
class TypeKey:
	module: Optional[str]
	name: str
	args: Tuple["TypeKey", ...] = ()

	def head(self) -> "TypeHeadKey":
		return TypeHeadKey(module=self.module, name=self.name)


@dataclass(frozen=True)
class TypeHeadKey:
	module: Optional[str]
	name: str


@dataclass(frozen=True)
class FnKey:
	module: Optional[str]
	name: str


@dataclass
class TraitDef:
	key: TraitKey
	name: str
	methods: List[parser_ast.TraitMethodSig]
	require: Optional[parser_ast.TraitExpr]
	loc: Optional[object] = None


@dataclass
class ImplDef:
	trait: TraitKey
	target: TypeKey
	target_head: TypeHeadKey
	methods: List[parser_ast.FunctionDef]
	require: Optional[parser_ast.TraitExpr]
	loc: Optional[object] = None


@dataclass
class TraitWorld:
	traits: Dict[TraitKey, TraitDef] = field(default_factory=dict)
	impls: List[ImplDef] = field(default_factory=list)
	impls_by_trait: Dict[TraitKey, List[int]] = field(default_factory=dict)
	impls_by_target_head: Dict[TypeHeadKey, List[int]] = field(default_factory=dict)
	impls_by_trait_target: Dict[Tuple[TraitKey, TypeHeadKey], List[int]] = field(default_factory=dict)
	requires_by_struct: Dict[TypeKey, parser_ast.TraitExpr] = field(default_factory=dict)
	requires_by_fn: Dict[FunctionId, parser_ast.TraitExpr] = field(default_factory=dict)
	diagnostics: List[Diagnostic] = field(default_factory=list)


def _qual_from_type_expr(typ: parser_ast.TypeExpr) -> Optional[str]:
	return getattr(typ, "module_id", None) or getattr(typ, "module_alias", None)


def type_key_from_expr(typ: parser_ast.TypeExpr, *, default_module: Optional[str] = None) -> TypeKey:
	return TypeKey(
		module=_qual_from_type_expr(typ) or default_module,
		name=typ.name,
		args=tuple(type_key_from_expr(a, default_module=default_module) for a in getattr(typ, "args", []) or []),
	)


def type_key_from_typeid(type_table: object, tid: int) -> TypeKey:
	td = type_table.get(tid)
	args = tuple(type_key_from_typeid(type_table, t) for t in getattr(td, "param_types", []) or [])
	return TypeKey(module=getattr(td, "module_id", None), name=getattr(td, "name", ""), args=args)


def trait_key_from_expr(typ: parser_ast.TypeExpr, *, default_module: Optional[str] = None) -> TraitKey:
	return TraitKey(module=_qual_from_type_expr(typ) or default_module, name=typ.name)


def _type_key_str(key: TypeKey | TypeHeadKey) -> str:
	module = getattr(key, "module", None)
	name = getattr(key, "name", "")
	base = f"{module}.{name}" if module else name
	if isinstance(key, TypeKey) and key.args:
		args = ", ".join(_type_key_str(a) for a in key.args)
		return f"{base}<{args}>"
	return base


def _trait_key_str(key: TraitKey) -> str:
	return f"{key.module}.{key.name}" if key.module else key.name


def _diag(message: str, loc: object | None) -> Diagnostic:
	return Diagnostic(message=message, severity="error", span=Span.from_loc(loc))


def _collect_trait_is(expr: parser_ast.TraitExpr) -> List[parser_ast.TraitIs]:
	out: List[parser_ast.TraitIs] = []
	if isinstance(expr, parser_ast.TraitIs):
		out.append(expr)
	elif isinstance(expr, (parser_ast.TraitAnd, parser_ast.TraitOr)):
		out.extend(_collect_trait_is(expr.left))
		out.extend(_collect_trait_is(expr.right))
	elif isinstance(expr, parser_ast.TraitNot):
		out.extend(_collect_trait_is(expr.expr))
	return out


def build_trait_world(prog: parser_ast.Program, *, diagnostics: Optional[List[Diagnostic]] = None) -> TraitWorld:
	diags: List[Diagnostic] = list(diagnostics or [])
	world = TraitWorld(diagnostics=diags)
	module_id = getattr(prog, "module", None) or "main"

	# Collect trait declarations.
	method_seen: Dict[Tuple[TraitKey, str], object | None] = {}
	for tr in getattr(prog, "traits", []) or []:
		key = TraitKey(module=module_id, name=tr.name)
		if key in world.traits:
			world.diagnostics.append(_diag(f"duplicate trait definition '{_trait_key_str(key)}'", tr.loc))
			continue
		require_expr = getattr(tr, "require", None).expr if getattr(tr, "require", None) is not None else None
		world.traits[key] = TraitDef(
			key=key,
			name=tr.name,
			methods=list(getattr(tr, "methods", []) or []),
			require=require_expr,
			loc=getattr(tr, "loc", None),
		)
		if require_expr is not None:
			for atom in _collect_trait_is(require_expr):
				if atom.subject != "Self":
					world.diagnostics.append(
						_diag("trait require clause must use 'Self is Trait'", getattr(atom, "loc", None))
					)
					continue
				trait_key = trait_key_from_expr(atom.trait, default_module=module_id)
				if trait_key not in world.traits:
					world.diagnostics.append(
						_diag(
							f"unknown trait '{_trait_key_str(trait_key)}' in require clause",
							getattr(atom, "loc", None),
						)
					)
		for m in getattr(tr, "methods", []) or []:
			mkey = (key, m.name)
			if mkey in method_seen:
				world.diagnostics.append(
					_diag(
						f"duplicate method '{m.name}' in trait '{_trait_key_str(key)}'",
						getattr(m, "loc", None),
					)
				)
			else:
				method_seen[mkey] = getattr(m, "loc", None)

	# Collect require clauses for structs and functions.
	for s in getattr(prog, "structs", []) or []:
		if getattr(s, "require", None) is None:
			continue
		type_key = TypeKey(module=module_id, name=s.name, args=())
		req_expr = s.require.expr
		world.requires_by_struct[type_key] = req_expr
		for atom in _collect_trait_is(req_expr):
			if atom.subject == "Self":
				trait_key = trait_key_from_expr(atom.trait, default_module=module_id)
				if trait_key not in world.traits:
					world.diagnostics.append(
						_diag(
							f"unknown trait '{_trait_key_str(trait_key)}' in require clause",
							getattr(atom, "loc", None),
						)
					)
			else:
				world.diagnostics.append(
					_diag("require clause on struct must use 'Self is Trait'", getattr(atom, "loc", None))
				)

	name_ord: Dict[str, int] = {}
	for fn in getattr(prog, "functions", []) or []:
		ordinal = name_ord.get(fn.name, 0)
		name_ord[fn.name] = ordinal + 1
		if getattr(fn, "require", None) is None:
			continue
		req_expr = fn.require.expr
		fn_id = FunctionId(module=module_id, name=fn.name, ordinal=ordinal)
		world.requires_by_fn[fn_id] = req_expr
		for atom in _collect_trait_is(req_expr):
			if atom.subject == "Self":
				world.diagnostics.append(
					_diag("function require clause cannot use 'Self'", getattr(atom, "loc", None))
				)
				continue
			trait_key = trait_key_from_expr(atom.trait, default_module=module_id)
			if trait_key not in world.traits:
				world.diagnostics.append(
					_diag(
						f"unknown trait '{_trait_key_str(trait_key)}' in require clause",
						getattr(atom, "loc", None),
					)
				)

	# Collect impls (trait impls only).
	for impl in getattr(prog, "implements", []) or []:
		if getattr(impl, "trait", None) is None:
			continue
		trait_key = trait_key_from_expr(impl.trait, default_module=module_id)
		if trait_key not in world.traits:
			world.diagnostics.append(
				_diag(f"unknown trait '{_trait_key_str(trait_key)}' in implement block", getattr(impl, "loc", None))
			)
			continue
		target_key = type_key_from_expr(impl.target, default_module=module_id)
		head_key = target_key.head()
		req_expr = impl.require.expr if getattr(impl, "require", None) is not None else None
		impl_id = len(world.impls)
		world.impls.append(
			ImplDef(
				trait=trait_key,
				target=target_key,
				target_head=head_key,
				methods=list(getattr(impl, "methods", []) or []),
				require=req_expr,
				loc=getattr(impl, "loc", None),
			)
		)
		world.impls_by_trait.setdefault(trait_key, []).append(impl_id)
		world.impls_by_target_head.setdefault(head_key, []).append(impl_id)
		world.impls_by_trait_target.setdefault((trait_key, head_key), []).append(impl_id)
		if req_expr is not None:
			for atom in _collect_trait_is(req_expr):
				trait_dep = trait_key_from_expr(atom.trait, default_module=module_id)
				if trait_dep not in world.traits:
					world.diagnostics.append(
						_diag(
							f"unknown trait '{_trait_key_str(trait_dep)}' in require clause",
							getattr(atom, "loc", None),
						)
					)

	# Coherence/overlap checks.
	for (trait_key, head_key), impl_ids in world.impls_by_trait_target.items():
		if len(impl_ids) <= 1:
			continue
		first = world.impls[impl_ids[0]]
		for other_id in impl_ids[1:]:
			other = world.impls[other_id]
			if other.target == first.target:
				msg = f"duplicate impl for trait '{_trait_key_str(trait_key)}' on '{_type_key_str(head_key)}'"
			else:
				msg = f"overlapping impls for trait '{_trait_key_str(trait_key)}' on '{_type_key_str(head_key)}'"
			world.diagnostics.append(_diag(msg, other.loc))

	return world


def _resolve_trait_subjects(
	expr: parser_ast.TraitExpr,
	type_param_map: Dict[str, TypeParamId],
) -> parser_ast.TraitExpr:
	if isinstance(expr, parser_ast.TraitIs):
		subj = expr.subject
		if isinstance(subj, str) and subj in type_param_map:
			return parser_ast.TraitIs(loc=expr.loc, subject=type_param_map[subj], trait=expr.trait)
		return expr
	if isinstance(expr, parser_ast.TraitAnd):
		return parser_ast.TraitAnd(
			loc=expr.loc,
			left=_resolve_trait_subjects(expr.left, type_param_map),
			right=_resolve_trait_subjects(expr.right, type_param_map),
		)
	if isinstance(expr, parser_ast.TraitOr):
		return parser_ast.TraitOr(
			loc=expr.loc,
			left=_resolve_trait_subjects(expr.left, type_param_map),
			right=_resolve_trait_subjects(expr.right, type_param_map),
		)
	if isinstance(expr, parser_ast.TraitNot):
		return parser_ast.TraitNot(
			loc=expr.loc,
			expr=_resolve_trait_subjects(expr.expr, type_param_map),
		)
	return expr


def resolve_fn_require_subjects(
	world: TraitWorld,
	signatures: Dict[FunctionId, object],
) -> None:
	"""Lower function-require subjects from names to TypeParamIds."""
	for fn_id, req in list(world.requires_by_fn.items()):
		sig = signatures.get(fn_id)
		if sig is None:
			continue
		type_params = getattr(sig, "type_params", []) or []
		if not type_params:
			continue
		type_param_map = {p.name: p.id for p in type_params if hasattr(p, "name") and hasattr(p, "id")}
		if not type_param_map:
			continue
		world.requires_by_fn[fn_id] = _resolve_trait_subjects(req, type_param_map)


__all__ = [
	"TraitWorld",
	"TraitKey",
	"TypeKey",
	"TypeHeadKey",
	"ImplDef",
	"TraitDef",
	"FnKey",
	"build_trait_world",
	"type_key_from_typeid",
]

[==== File: staged/lang2/driftc/type_checker.py =====]
#!/usr/bin/env python3
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
# author: Sławomir Liszniański; created: 2025-12-09
"""
Minimal typed checker skeleton for lang2.

This is a real checker scaffold that:
- Allocates ParamId/LocalId/BindingId for bindings.
- Infers types for basic expressions (literals, vars, lets, borrows, calls).
- Produces a TypedFn record with expression TypeIds and binding identity.

It is intentionally small; it will grow to cover full Drift semantics. Borrow
checker integration will consume TypedFn once this matures.
"""

from __future__ import annotations

from dataclasses import dataclass, field, replace
from typing import Dict, List, Optional, Mapping, Tuple

from lang2.driftc import stage1 as H
from lang2.driftc.checker import FnSignature
from lang2.driftc.core.diagnostics import Diagnostic
from lang2.driftc.core.span import Span
from lang2.driftc.core.types_core import TypeId, TypeTable, TypeKind, VariantInstance, VariantSchema
from lang2.driftc.core.function_id import FunctionId, function_symbol
from lang2.driftc.core.type_resolve_common import resolve_opaque_type
from lang2.driftc.core.type_subst import Subst, apply_subst
from lang2.driftc.core.generic_type_expr import GenericTypeExpr
from lang2.driftc.borrow_checker import (
	DerefProj,
	FieldProj,
	IndexProj,
	Place,
	PlaceBase,
	PlaceKind,
	place_from_expr,
	places_overlap,
)
from lang2.driftc.method_registry import CallableDecl, CallableRegistry, CallableSignature, ModuleId
from lang2.driftc.method_resolver import MethodResolution, ResolutionError, resolve_method_call
from lang2.driftc.core.iter_intrinsics import ensure_array_iter_struct, is_array_iter_struct
from lang2.driftc.parser import ast as parser_ast
from lang2.driftc.traits.solver import Env as TraitEnv, ProofStatus, prove_expr
from lang2.driftc.traits.world import type_key_from_typeid

# Identifier aliases for clarity.
ParamId = int
LocalId = int


@dataclass
class TypedFn:
	"""Typed view of a single function's HIR."""

	fn_id: FunctionId
	name: str
	params: List[ParamId]
	param_bindings: List[int]
	locals: List[LocalId]
	body: H.HBlock
	expr_types: Dict[int, TypeId]  # keyed by id(expr)
	binding_for_var: Dict[int, int]  # keyed by id(HVar)
	binding_types: Dict[int, TypeId]  # binding_id -> TypeId
	binding_names: Dict[int, str]  # binding_id -> name
	binding_mutable: Dict[int, bool]  # binding_id -> declared var?
	call_resolutions: Dict[int, CallableDecl | MethodResolution] = field(default_factory=dict)


@dataclass
class TypeCheckResult:
	"""Result of type checking a function."""

	typed_fn: TypedFn
	diagnostics: List[Diagnostic] = field(default_factory=list)


class TypeChecker:
	"""
	Minimal HIR type checker that assigns binding IDs and basic types.

	This is a skeleton: it understands literals, vars, lets, borrows, calls, and
	a small set of builtin constructs (f-strings, exceptions, DiagnosticValue
	helpers).
	"""

	def __init__(self, type_table: Optional[TypeTable] = None):
		self.type_table = type_table or TypeTable()
		self._uint = self.type_table.ensure_uint()
		self._int = self.type_table.ensure_int()
		self._float = self.type_table.ensure_float()
		self._bool = self.type_table.ensure_bool()
		self._string = self.type_table.ensure_string()
		self._void = self.type_table.ensure_void()
		self._dv = self.type_table.ensure_diagnostic_value()
		self._opt_int = self.type_table.new_optional(self._int)
		self._opt_bool = self.type_table.new_optional(self._bool)
		self._opt_string = self.type_table.new_optional(self._string)
		self._unknown = self.type_table.ensure_unknown()
		# Binding ids (params and locals) share a single id-space.
		#
		# This is critical for correctness: many downstream passes (including the
		# borrow checker) treat `binding_id` as a stable identity. If ParamId and
		# LocalId were allocated from separate counters, their numeric ids could
		# collide (e.g. param 1 and local 1), silently corrupting identity-based
		# maps like `binding_types`.
		self._next_binding_id: int = 1

	def _pretty_type_name(self, ty: TypeId, *, current_module: str | None) -> str:
		"""
		Render a user-facing type name for diagnostics.

		This is intentionally small: enough for MVP error messages without
		committing to a full surface type renderer.
		"""
		td = self.type_table.get(ty)
		name = td.name
		if td.module_id and current_module and td.module_id not in {current_module, "lang.core"}:
			name = f"{td.module_id}.{name}"
		if td.param_types:
			args = ", ".join(self._pretty_type_name(t, current_module=current_module) for t in td.param_types)
			return f"{name}<{args}>"
		return name

	def _format_ctor_signature_list(
		self,
		*,
		schema: VariantSchema,
		instance: VariantInstance | None,
		current_module: str | None,
	) -> list[str]:
		"""
		Return a stable, user-facing list of constructor “signatures”.

		Pinned formatting rules (MVP):
		- Sort by constructor name, then arity.
		- Render as: `CtorName(arg1, arg2)` with no extra spaces.
		- If a payload type is unknown/unrenderable, show `_`.

		When `instance` is available we prefer concrete field types; otherwise we
		fall back to schema generic expressions (`T`, `Array<T>`, etc.).
		"""

		def _render_generic(g: GenericTypeExpr) -> str:
			if g.param_index is not None:
				idx = int(g.param_index)
				if 0 <= idx < len(schema.type_params):
					return schema.type_params[idx]
				return "_"
			name = g.name
			args = list(g.args or [])
			if not args:
				return name
			return f"{name}<{', '.join(_render_generic(a) for a in args)}>"

		arms = sorted(schema.arms, key=lambda a: (a.name, len(a.fields)))
		out: list[str] = []
		for arm in arms:
			field_parts: list[str] = []
			if instance is not None:
				inst_arm = instance.arms_by_name.get(arm.name)
				if inst_arm is not None:
					for ft in inst_arm.field_types:
						field_parts.append(self._pretty_type_name(ft, current_module=current_module))
			if not field_parts:
				for f in arm.fields:
					field_parts.append(_render_generic(f.type_expr))
			out.append(f"`{arm.name}({', '.join(field_parts)})`")
		return out

	def check_function(
		self,
		fn_id: FunctionId,
		body: H.HBlock,
		param_types: Mapping[str, TypeId] | None = None,
		return_type: TypeId | None = None,
		call_signatures: Mapping[str, list[FnSignature]] | None = None,
		signatures_by_id: Mapping[FunctionId, FnSignature] | None = None,
		callable_registry: CallableRegistry | None = None,
		visible_modules: Optional[Tuple[ModuleId, ...]] = None,
		current_module: ModuleId = 0,
	) -> TypeCheckResult:
		# Best-effort current module id in canonical string form.
		#
		# This is required for correct module-scoped nominal type resolution
		# (e.g., `Point(...)` inside module `a.geom` must refer to `a.geom:Point`
		# even if another module also defines `Point`).
		current_module_name: str | None = None
		current_module_name = fn_id.module or "main"

		scope_env: List[Dict[str, TypeId]] = [dict()]
		scope_bindings: List[Dict[str, int]] = [dict()]
		expr_types: Dict[int, TypeId] = {}
		binding_for_var: Dict[int, int] = {}
		binding_types: Dict[int, TypeId] = {}
		binding_names: Dict[int, str] = {}
		# Binding mutability (val/var) keyed by binding id.
		#
		# MVP borrow rules depend on this:
		#   - `&mut x` requires `x` to be declared mutable (`var`).
		binding_mutable: Dict[int, bool] = {}
		# Binding identity kind (param vs local). This avoids accidental collisions:
		# ParamId and LocalId are allocated from separate counters, so a param and
		# local can share the same numeric id.
		binding_place_kind: Dict[int, PlaceKind] = {}
		# Borrow exclusivity (MVP): tracked within a single statement/expression.
		#
		# Key by Place (not binding id) so this mechanism naturally extends to
		# projections once we support borrowing from `x.field`, `arr[i]`, `*p`.
		#
		# Value is "shared" or "mut". This is intentionally shallow (no lifetimes)
		# but prevents the worst footguns:
		#   - multiple `&x` in a statement is OK
		#   - `&mut x` conflicts with any other borrow of `x` in the same statement
		#   - `&x` conflicts with a prior `&mut x` in the same statement
		borrows_in_stmt: Dict[Place, str] = {}
		# Ref origin tracking (MVP escape policy):
		#
		# When a binding has a reference type, record whether it is ultimately
		# derived from a single reference *parameter* binding. This lets us enforce
		# "return refs only derived from a ref param" without a full lifetime model.
		#
		# Value is the binding_id of the originating ref param, or None when the
		# reference points at local/temporary storage.
		ref_origin_param: Dict[int, Optional[int]] = {}
		diagnostics: List[Diagnostic] = []
		call_resolutions: Dict[int, CallableDecl | MethodResolution] = {}
		trait_worlds = getattr(self.type_table, "trait_worlds", {}) or {}

		def _single_sig(name: str) -> FnSignature | None:
			if not call_signatures:
				return None
			sigs = call_signatures.get(name)
			if sigs is None:
				return None
			if isinstance(sigs, FnSignature):
				return sigs
			if len(sigs) == 1:
				return sigs[0]
			return None

		def _loc_from_span(span: Span) -> parser_ast.Located:
			return parser_ast.Located(line=span.line or 0, column=span.column or 0)

		def _trait_expr_to_parser(expr: H.HTraitExpr) -> parser_ast.TraitExpr:
			if isinstance(expr, H.HTraitIs):
				loc = _loc_from_span(expr.loc)
				return parser_ast.TraitIs(loc=loc, subject=expr.subject, trait=expr.trait)
			if isinstance(expr, H.HTraitAnd):
				loc = _loc_from_span(expr.loc)
				return parser_ast.TraitAnd(loc=loc, left=_trait_expr_to_parser(expr.left), right=_trait_expr_to_parser(expr.right))
			if isinstance(expr, H.HTraitOr):
				loc = _loc_from_span(expr.loc)
				return parser_ast.TraitOr(loc=loc, left=_trait_expr_to_parser(expr.left), right=_trait_expr_to_parser(expr.right))
			if isinstance(expr, H.HTraitNot):
				loc = _loc_from_span(expr.loc)
				return parser_ast.TraitNot(loc=loc, expr=_trait_expr_to_parser(expr.expr))
			raise TypeError(f"unsupported trait expr node: {type(expr).__name__}")

		def _collect_trait_subjects(expr: parser_ast.TraitExpr, out: set[object]) -> None:
			if isinstance(expr, parser_ast.TraitIs):
				out.add(expr.subject)
			elif isinstance(expr, (parser_ast.TraitAnd, parser_ast.TraitOr)):
				_collect_trait_subjects(expr.left, out)
				_collect_trait_subjects(expr.right, out)
			elif isinstance(expr, parser_ast.TraitNot):
				_collect_trait_subjects(expr.expr, out)

		def _normalize_type_key(key: object) -> object:
			if getattr(key, "module", None) is None:
				return type(key)(module=current_module_name, name=key.name, args=key.args)
			return key

		def _require_rank(expr: parser_ast.TraitExpr | None) -> tuple[bool, int]:
			if expr is None:
				return True, 0
			if isinstance(expr, parser_ast.TraitIs):
				return True, 1
			if isinstance(expr, parser_ast.TraitAnd):
				left_ok, left_cnt = _require_rank(expr.left)
				right_ok, right_cnt = _require_rank(expr.right)
				return (left_ok and right_ok), left_cnt + right_cnt
			if isinstance(expr, (parser_ast.TraitOr, parser_ast.TraitNot)):
				return False, 0
			return False, 0

		def _fn_id_for_decl(decl: CallableDecl) -> FunctionId | None:
			return decl.fn_id

		def _resolve_free_call_with_require(
			*,
			name: str,
			arg_types: List[TypeId],
			call_type_args: List[TypeId] | None = None,
			call_type_args_span: Span | None = None,
		) -> tuple[CallableDecl, CallableSignature]:
			candidates = callable_registry.get_free_candidates(
				name=name,
				visible_modules=visible_modules or (current_module,),
				include_private_in=current_module,
			)
			viable: List[tuple[CallableDecl, CallableSignature]] = []
			for decl in candidates:
				sig = None
				if decl.fn_id is not None and signatures_by_id is not None:
					sig = signatures_by_id.get(decl.fn_id)
				if sig is None:
					sig = _single_sig(decl.name)

				if sig is None:
					if call_type_args:
						raise ResolutionError(
							f"type arguments require a typed signature for function '{name}'",
							span=call_type_args_span,
						)
					params = list(decl.signature.param_types)
					result_type = decl.signature.result_type
					if len(params) != len(arg_types):
						continue
					if all(p == a for p, a in zip(params, arg_types)):
						viable.append(
							(
								decl,
								CallableSignature(param_types=tuple(params), result_type=result_type),
							)
						)
					continue

				if sig.param_type_ids is None and sig.param_types is not None:
					local_type_params = {p.name: p.id for p in sig.type_params}
					param_type_ids = [
						resolve_opaque_type(p, self.type_table, module_id=sig.module, type_params=local_type_params)
						for p in sig.param_types
					]
					sig = replace(sig, param_type_ids=param_type_ids)

				if sig.return_type_id is None and sig.return_type is not None:
					local_type_params = {p.name: p.id for p in sig.type_params}
					ret_id = resolve_opaque_type(sig.return_type, self.type_table, module_id=sig.module, type_params=local_type_params)
					sig = replace(sig, return_type_id=ret_id)

				if sig.param_type_ids is None or sig.return_type_id is None:
					continue

				if call_type_args:
					if not sig.type_params:
						continue
					if len(call_type_args) != len(sig.type_params):
						raise ResolutionError(
							f"type argument count mismatch for '{name}': expected {len(sig.type_params)}, got {len(call_type_args)}",
							span=call_type_args_span,
						)
					subst = Subst(owner=sig.type_params[0].id.owner, args=list(call_type_args))
					inst_params = [apply_subst(p, subst, self.type_table) for p in sig.param_type_ids]
					inst_return = apply_subst(sig.return_type_id, subst, self.type_table)
					params = inst_params
					result_type = inst_return
				else:
					if sig.type_params:
						continue
					params = list(sig.param_type_ids)
					result_type = sig.return_type_id

				if len(params) != len(arg_types):
					continue
				if all(p == a for p, a in zip(params, arg_types)):
					viable.append(
						(
							decl,
							CallableSignature(param_types=tuple(params), result_type=result_type),
						)
					)
			if not viable:
				if call_type_args:
					raise ResolutionError(f"no matching overload for function '{name}' with provided type arguments")
				raise ResolutionError(f"no matching overload for function '{name}' with args {arg_types}")
			world = None
			applicable: List[tuple[CallableDecl, CallableSignature]] = []
			ranks: Dict[int, tuple[bool, int]] = {}
			for decl, sig_inst in viable:
				fn_id = _fn_id_for_decl(decl)
				if fn_id is None:
					applicable.append((decl, sig_inst))
					ranks[decl.callable_id] = (True, 0)
					continue
				world = trait_worlds.get(fn_id.module) if isinstance(trait_worlds, dict) else None
				req = world.requires_by_fn.get(fn_id) if world is not None else None
				if req is None:
					applicable.append((decl, sig_inst))
					ranks[decl.callable_id] = (True, 0)
					continue
				subjects: set[object] = set()
				_collect_trait_subjects(req, subjects)
				subst: dict[object, object] = {}
				sig = None
				if decl.fn_id is not None and signatures_by_id is not None:
					sig = signatures_by_id.get(decl.fn_id)
				if sig is None:
					sig = _single_sig(decl.name)
				if sig and getattr(sig, "type_params", None) and call_type_args:
					type_params = list(getattr(sig, "type_params", []) or [])
					if len(call_type_args) == len(type_params):
						for idx, tp in enumerate(type_params):
							if tp.id in subjects:
								subst[tp.id] = _normalize_type_key(
									type_key_from_typeid(self.type_table, call_type_args[idx])
								)
				if world is None:
					continue
				env = TraitEnv(default_module=fn_id.module or current_module_name)
				res = prove_expr(world, env, subst, req)
				if res.status is ProofStatus.PROVED:
					applicable.append((decl, sig_inst))
					ranks[decl.callable_id] = _require_rank(req)
			if not applicable:
				raise ResolutionError(f"no matching overload for function '{name}' with args {arg_types}")
			if len(applicable) == 1:
				return applicable[0]
			if any(not ranks[decl.callable_id][0] for decl, _sig in applicable):
				raise ResolutionError(f"ambiguous call to function '{name}' with args {arg_types}")
			best = max(ranks[decl.callable_id][1] for decl, _sig in applicable)
			winners = [(d, s) for d, s in applicable if ranks[d.callable_id][1] == best]
			if len(winners) != 1:
				raise ResolutionError(f"ambiguous call to function '{name}' with args {arg_types}")
			return winners[0]

		params: List[ParamId] = []
		param_bindings: List[int] = []
		locals: List[LocalId] = []

		# Seed parameters if provided.
		for pname, pty in (param_types or {}).items():
			pid = self._alloc_param_id()
			params.append(pid)
			param_bindings.append(pid)
			scope_env[-1][pname] = pty
			scope_bindings[-1][pname] = pid
			binding_types[pid] = pty
			binding_names[pid] = pname
			binding_mutable[pid] = False
			binding_place_kind[pid] = PlaceKind.PARAM

		def record_expr(expr: H.HExpr, ty: TypeId) -> TypeId:
			expr_id = id(expr)
			expr_types[expr_id] = ty
			return ty

		# Precompute constructor-name visibility for diagnostics.
		#
		# MVP constructor resolution rule (work/variant/work-progress.md):
		# - Constructors are unqualified identifiers.
		# - Constructor calls in expression position require an *expected variant type*.
		# - Without an expected type, the compiler diagnoses instead of guessing.
		ctor_to_variant_bases: dict[str, list[TypeId]] = {}
		for base_id, schema in getattr(self.type_table, "variant_schemas", {}).items():
			for arm in schema.arms:
				ctor_to_variant_bases.setdefault(arm.name, []).append(base_id)

		def type_expr(
			expr: H.HExpr,
			*,
			allow_exception_init: bool = False,
			used_as_value: bool = True,
			expected_type: TypeId | None = None,
		) -> TypeId:
			# Literals.
			if isinstance(expr, H.HLiteralInt):
				return record_expr(expr, self._int)
			if hasattr(H, "HLiteralFloat") and isinstance(expr, getattr(H, "HLiteralFloat")):
				return record_expr(expr, self._float)
			if isinstance(expr, H.HLiteralBool):
				return record_expr(expr, self._bool)
			if isinstance(expr, H.HTraitExpr):
				# Trait guard expressions are compile-time only; treat them as Bool.
				return record_expr(expr, self._bool)
			if isinstance(expr, H.HLiteralString):
				return record_expr(expr, self._string)
			if isinstance(expr, H.HFString):
				# f-strings are sugar that ultimately produce a String.
				#
				# MVP rules (from spec-change request):
				# - Each hole expression must be one of {Bool, Int, Uint, Float, String}.
				# - `:spec` is supported syntactically, but only the empty spec is
				#   accepted for now (future work will validate a richer subset).
				for hole in expr.holes:
					hole_ty = type_expr(hole.expr)
					if hole.spec:
						diagnostics.append(
							Diagnostic(
								message="E-FSTR-BAD-SPEC: non-empty :spec is not supported yet (MVP: empty only)",
								severity="error",
								span=getattr(hole, "loc", Span()),
							)
						)
					if hole_ty not in (self._bool, self._int, self._uint, self._float, self._string):
						pretty = self.type_table.get(hole_ty).name if hole_ty is not None else "Unknown"
						diagnostics.append(
							Diagnostic(
								message=f"E-FSTR-UNSUPPORTED-TYPE: f-string hole value is not formattable in MVP (have {pretty})",
								severity="error",
								span=getattr(hole, "loc", Span()),
							)
						)
				return record_expr(expr, self._string)

			# Names and bindings.
			if isinstance(expr, H.HVar):
				# Module-scoped compile-time constants.
				#
				# Consts live outside local scope bindings. We resolve them here so
				# later stages can:
				# - type-check `CONST` like a literal of its declared type,
				# - lower it to an immediate MIR/LLVM constant at each use site.
				#
				# Resolution order:
				#   1) local/param bindings (lexical scopes),
				#   2) fully-qualified const symbols (`mod::NAME`) present in the TypeTable,
				#   3) unqualified const names resolved within the current module id.
				if expr.binding_id is None:
					# Check for already-qualified const symbol (from imports/module-qualified access).
					if "::" in expr.name:
						cv = self.type_table.lookup_const(expr.name)
						if cv is not None:
							ty_id, _val = cv
							return record_expr(expr, ty_id)
					# Check for a module-local const by current module id.
					cv = self.type_table.lookup_const(f"{current_module_name}::{expr.name}")
					if cv is not None:
						ty_id, _val = cv
						expr.name = f"{current_module_name}::{expr.name}"
						return record_expr(expr, ty_id)
				if expr.binding_id is None:
					for scope in reversed(scope_bindings):
						if expr.name in scope:
							expr.binding_id = scope[expr.name]
							break
				for scope in reversed(scope_env):
					if expr.name in scope:
						if expr.binding_id is not None:
							binding_for_var[id(expr)] = expr.binding_id
						return record_expr(expr, scope[expr.name])
				diagnostics.append(
					Diagnostic(
						message=f"unknown variable '{expr.name}'",
						severity="error",
						span=getattr(expr, "loc", Span()),
					)
				)
				return record_expr(expr, self._unknown)

			if hasattr(H, "HQualifiedMember") and isinstance(expr, getattr(H, "HQualifiedMember")):
				diagnostics.append(
					Diagnostic(
						message=(
							"E-QMEM-NOT-CALLABLE: qualified member reference is not a first-class value in MVP; "
							"call it directly (e.g. `Type::Ctor(...)`)"
						),
						severity="error",
						span=getattr(expr, "loc", Span()),
					)
				)
				return record_expr(expr, self._unknown)

			# `match` expression (expression-only in MVP, but may appear in statement
			# position as an ExprStmt where the result is ignored).
			if hasattr(H, "HMatchExpr") and isinstance(expr, getattr(H, "HMatchExpr")):
				scrut_ty = type_expr(expr.scrutinee)
				inst = None
				if scrut_ty is not None:
					try:
						td_scrut = self.type_table.get(scrut_ty)
					except Exception:
						td_scrut = None
					if td_scrut is not None and td_scrut.kind is not TypeKind.VARIANT:
						diagnostics.append(
							Diagnostic(
								message="match scrutinee must be a variant type",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
					if td_scrut is not None and td_scrut.kind is TypeKind.VARIANT:
						inst = self.type_table.get_variant_instance(scrut_ty)

				seen_default = False
				seen_default_span: Span | None = None
				seen_ctors: set[str] = set()
				result_ty: TypeId | None = None

				for idx, arm in enumerate(expr.arms):
					if arm.ctor is None:
						# default arm
						if seen_default:
							diagnostics.append(
								Diagnostic(
									message="match default arm may appear at most once",
									severity="error",
									span=getattr(arm, "loc", Span()),
								)
							)
						seen_default = True
						seen_default_span = getattr(arm, "loc", Span())
					else:
						if seen_default:
							diagnostics.append(
								Diagnostic(
									message="match arms after default are unreachable",
									severity="error",
									span=getattr(arm, "loc", Span()),
								)
							)
						if arm.ctor in seen_ctors:
							diagnostics.append(
								Diagnostic(
									message=f"duplicate match arm for constructor '{arm.ctor}'",
									severity="error",
									span=getattr(arm, "loc", Span()),
								)
							)
						seen_ctors.add(arm.ctor)

					# Type-check arm body under a scope that includes constructor binders.
					scope_env.append(dict())
					scope_bindings.append(dict())
					try:
						if arm.ctor is not None and inst is not None:
							arm_def = inst.arms_by_name.get(arm.ctor)
							if arm_def is None:
								diagnostics.append(
									Diagnostic(
										message=f"unknown constructor '{arm.ctor}' for this variant",
										severity="error",
										span=getattr(arm, "loc", Span()),
									)
								)
							else:
								form = getattr(arm, "pattern_arg_form", "positional")
								field_names = list(getattr(arm_def, "field_names", []) or [])
								field_types = list(arm_def.field_types)
								field_indices: list[int] = []

								if form == "bare":
									# Bare ctor patterns (`Ctor`) are allowed only for zero-field ctors.
									if field_types:
										diagnostics.append(
											Diagnostic(
												message=(
													f"E-MATCH-PAT-BARE: constructor pattern '{arm.ctor}' requires parentheses; "
													"use `Ctor()` to ignore payload fields"
												),
												severity="error",
												span=getattr(arm, "loc", Span()),
											)
										)
									if arm.binders:
										diagnostics.append(
											Diagnostic(
												message=f"E-MATCH-PAT-BARE: bare constructor pattern '{arm.ctor}' cannot bind fields",
												severity="error",
												span=getattr(arm, "loc", Span()),
											)
										)
								elif form == "paren":
									# `Ctor()` matches the tag only and ignores payload; it binds nothing.
									if arm.binders:
										diagnostics.append(
											Diagnostic(
												message=f"E-MATCH-PAT-PAREN: '{arm.ctor}()' pattern must not bind fields",
												severity="error",
												span=getattr(arm, "loc", Span()),
											)
										)
								elif form == "named":
									binder_fields = getattr(arm, "binder_fields", None)
									if binder_fields is None or len(binder_fields) != len(arm.binders):
										diagnostics.append(
											Diagnostic(
												message=f"internal: named constructor pattern missing binder field list (compiler bug)",
												severity="error",
												span=getattr(arm, "loc", Span()),
											)
										)
									else:
										seen_fields: set[str] = set()
										for fname, bname in zip(binder_fields, arm.binders):
											if fname in seen_fields:
												diagnostics.append(
													Diagnostic(
														message=f"duplicate field '{fname}' in constructor pattern '{arm.ctor}'",
														severity="error",
														span=getattr(arm, "loc", Span()),
													)
												)
												continue
											seen_fields.add(fname)
											if fname not in field_names:
												diagnostics.append(
													Diagnostic(
														message=(
															f"unknown field '{fname}' in constructor pattern '{arm.ctor}'; "
															f"available fields: {', '.join(field_names)}"
														),
														severity="error",
														span=getattr(arm, "loc", Span()),
													)
												)
												continue
											field_indices.append(field_names.index(fname))
								else:
									# Positional binders (exact arity in MVP).
									if len(arm.binders) != len(field_types):
										diagnostics.append(
											Diagnostic(
												message=(
													f"constructor pattern '{arm.ctor}' expects {len(field_types)} binders, got {len(arm.binders)}"
												),
												severity="error",
												span=getattr(arm, "loc", Span()),
											)
										)
									field_indices = list(range(min(len(arm.binders), len(field_types))))

								# Store normalized binder→field-index mapping for stage2 lowering.
								if hasattr(arm, "binder_field_indices"):
									arm.binder_field_indices = list(field_indices)

								# Bind only the fields requested by the pattern form.
								for bname, fidx in zip(arm.binders, field_indices):
									if fidx < 0 or fidx >= len(field_types):
										continue
									bty = field_types[fidx]
									bid = self._alloc_local_id()
									locals.append(bid)
									scope_env[-1][bname] = bty
									scope_bindings[-1][bname] = bid
									binding_types[bid] = bty
									binding_names[bid] = bname
									binding_mutable[bid] = False
									binding_place_kind[bid] = PlaceKind.LOCAL

						type_block(arm.block)

						arm_value_ty: TypeId | None = None
						if arm.result is not None:
							arm_value_ty = type_expr(arm.result)
						elif used_as_value:
							# Allow diverging arms to omit a value in MVP. We treat a block as
							# diverging when it ends with a terminator statement.
							last = arm.block.statements[-1] if arm.block.statements else None
							diverges = isinstance(last, (H.HReturn, H.HBreak, H.HContinue, H.HThrow, H.HRethrow))
							if not diverges:
								diagnostics.append(
									Diagnostic(
										message="E-MATCH-ARM-NO-VALUE: match arm must end with an expression when match result is used",
										severity="error",
										span=getattr(arm, "loc", Span()),
									)
								)
						if used_as_value and arm_value_ty is not None:
							if result_ty is None:
								result_ty = arm_value_ty
							elif result_ty != arm_value_ty:
								diagnostics.append(
									Diagnostic(
										message=(
											"E-MATCH-ARM-TYPE: match arms must produce the same type when match result is used "
											f"(have {self.type_table.get(arm_value_ty).name}, expected {self.type_table.get(result_ty).name})"
										),
										severity="error",
										span=getattr(arm, "loc", Span()),
									)
								)
					finally:
						scope_env.pop()
						scope_bindings.pop()

				# Non-exhaustive matches require a default arm (MVP rule).
				if inst is not None and not seen_default:
					all_ctors = set(inst.arms_by_name.keys())
					if seen_ctors != all_ctors:
						missing = ", ".join(sorted(all_ctors - seen_ctors))
						diagnostics.append(
							Diagnostic(
								message=f"E-MATCH-NONEXHAUSTIVE: non-exhaustive match must include default arm (missing: {missing})",
								severity="error",
								span=getattr(expr, "loc", Span()) if seen_default_span is None else seen_default_span,
							)
						)

				if not used_as_value:
					return record_expr(expr, self._void)
				if result_ty is None:
					diagnostics.append(
						Diagnostic(
							message="E-MATCH-NO-VALUE: match result is used but no arm produces a value",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				return record_expr(expr, result_ty)

			# Borrow.
			if isinstance(expr, H.HBorrow):
				# Guardrail: do not materialize `&mut (move x)` into a temp. This would
				# turn an explicit ownership transfer into an implicit "store then
				# borrow" pattern, which is a semantic expansion we want to avoid.
				#
				# Instead, reject at type-check time with a targeted diagnostic.
				def _contains_move(node: H.HExpr) -> bool:
					if hasattr(H, "HMove") and isinstance(node, getattr(H, "HMove")):
						return True
					if isinstance(node, H.HUnary):
						return _contains_move(node.expr)
					if isinstance(node, H.HBinary):
						return _contains_move(node.left) or _contains_move(node.right)
					if isinstance(node, H.HTernary):
						return _contains_move(node.cond) or _contains_move(node.then_expr) or _contains_move(node.else_expr)
					if isinstance(node, H.HCall):
						return (
							_contains_move(node.fn)
							or any(_contains_move(a) for a in node.args)
							or any(_contains_move(k.value) for k in getattr(node, "kwargs", []) or [])
						)
					if isinstance(node, H.HMethodCall):
						return (
							_contains_move(node.receiver)
							or any(_contains_move(a) for a in node.args)
							or any(_contains_move(k.value) for k in getattr(node, "kwargs", []) or [])
						)
					if isinstance(node, H.HField):
						return _contains_move(node.subject)
					if isinstance(node, H.HIndex):
						return _contains_move(node.subject) or _contains_move(node.index)
					if isinstance(node, getattr(H, "HPlaceExpr", ())):
						# Canonical places cannot contain moves in their base/projections.
						return False
					if isinstance(node, H.HArrayLiteral):
						return any(_contains_move(e) for e in node.elements)
					if isinstance(node, H.HDVInit):
						return any(_contains_move(a) for a in node.args)
					if isinstance(node, H.HExceptionInit):
						return any(_contains_move(a) for a in node.pos_args) or any(_contains_move(k.value) for k in node.kw_args)
					if isinstance(node, getattr(H, "HTryExpr", ())):
						if _contains_move(node.attempt):
							return True
						for arm in node.arms:
							if any(_contains_move(s.expr) for s in arm.block.statements if isinstance(s, H.HExprStmt)):
								return True
							if arm.result is not None and _contains_move(arm.result):
								return True
						return False
					return False

				if expr.is_mut and _contains_move(expr.subject):
					diagnostics.append(
						Diagnostic(
							message="cannot take &mut of an expression containing move; assign to a var first",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)

				inner_ty = type_expr(expr.subject)
				# MVP: borrowing is only supported from addressable places.
				#
				# Current support:
				# - locals/params: `&x`, `&mut x`
				# - reborrow through a reference: `&*p`, `&mut *p`
				#
				# Future work: field/index borrows and temporary materialization of rvalues.
				def _base_lookup(hv: object) -> Optional[PlaceBase]:
					bid = getattr(hv, "binding_id", None)
					if bid is None:
						return None
					kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
					name = hv.name if hasattr(hv, "name") else str(hv)
					return PlaceBase(kind=kind, local_id=bid, name=name)

				place = place_from_expr(expr.subject, base_lookup=_base_lookup)
				if place is None:
					diagnostics.append(
						Diagnostic(
							message="borrow operand must be an addressable place in MVP (local/param or deref place)",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)

				# MVP: we accept borrowing from nested projections (`x.field`, `arr[i]`,
				# `(*p).field`, etc.) as long as the operand is a real place.
				#
				# Note: rvalues are rejected above by `place_from_expr` returning None.
				# We intentionally do not allow autoref: callers must write `&x`.

				if expr.is_mut:
					# `&mut x` requires `x` to be `var`.
					#
					# We enforce two invariants:
					#  - If the borrow is from owned storage (no deref projections), the base
					#    binding must be `var`. (Example: `&mut p.x` where `p` is a local.)
					#  - If the borrow goes through a deref projection (reborrow), mutability
					#    comes from the reference being dereferenced (Example: `&mut (*p).x`
					#    where `p: &mut Point`). In that case, the base binding does not need
					#    to be `var` (params are effectively `val`), but the dereferenced
					#    reference must be `&mut`.
					#  - If the place includes a deref projection, the reference being dereferenced
					#    must itself be mutable (`&mut`), i.e. a mutable reborrow.
					has_deref = any(isinstance(p, DerefProj) for p in place.projections)
					if (not has_deref) and place.base.local_id is not None and not binding_mutable.get(
						place.base.local_id, False
					):
						diagnostics.append(
							Diagnostic(
								message="cannot take &mut of an immutable binding; declare it with `var`",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
					# Detect a deref projection anywhere in the place and validate the corresponding
					# reference expression is `&mut`.
					#
					# We do a conservative check:
					#  - For canonical `HPlaceExpr` operands, walk projections and ensure each deref
					#    happens through `&mut`.
					#  - For legacy tree-shaped operands (`HUnary(DEREF, ...)`), walk the tree.
					def _validate_mutable_derefs(node: H.HExpr) -> None:
						if hasattr(H, "HPlaceExpr") and isinstance(node, getattr(H, "HPlaceExpr")):
							cur = type_expr(node.base)
							for pr in node.projections:
								if isinstance(pr, H.HPlaceDeref):
									ptr_def = self.type_table.get(cur)
									if ptr_def.kind is not TypeKind.REF or not ptr_def.ref_mut:
										diagnostics.append(
											Diagnostic(
												message="cannot take &mut through *p unless p is a mutable reference (&mut T)",
												severity="error",
												span=getattr(expr, "loc", Span()),
											)
										)
										return
									if ptr_def.param_types:
										cur = ptr_def.param_types[0]
								elif isinstance(pr, H.HPlaceField):
									td = self.type_table.get(cur)
									if td.kind is TypeKind.STRUCT:
										info = self.type_table.struct_field(cur, pr.name)
										if info is not None:
											_, cur = info
								elif isinstance(pr, H.HPlaceIndex):
									td = self.type_table.get(cur)
									if td.kind is TypeKind.ARRAY and td.param_types:
										cur = td.param_types[0]
							return
						if isinstance(node, H.HUnary) and node.op is H.UnaryOp.DEREF:
							ptr_ty = type_expr(node.expr)
							ptr_def = self.type_table.get(ptr_ty)
							if ptr_def.kind is not TypeKind.REF or not ptr_def.ref_mut:
								diagnostics.append(
									Diagnostic(
										message="cannot take &mut through *p unless p is a mutable reference (&mut T)",
										severity="error",
										span=getattr(expr, "loc", Span()),
									)
								)
							_validate_mutable_derefs(node.expr)
						elif isinstance(node, H.HField):
							_validate_mutable_derefs(node.subject)
						elif isinstance(node, H.HIndex):
							_validate_mutable_derefs(node.subject)
							_validate_mutable_derefs(node.index)

					_validate_mutable_derefs(expr.subject)
					if place in borrows_in_stmt:
						diagnostics.append(
							Diagnostic(
								message="conflicting borrows in the same statement: cannot take &mut while borrowed",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
					borrows_in_stmt[place] = "mut"
				else:
					if borrows_in_stmt.get(place) == "mut":
						diagnostics.append(
							Diagnostic(
								message="conflicting borrows in the same statement: cannot take & while mutably borrowed",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
					borrows_in_stmt.setdefault(place, "shared")

				ref_ty = self.type_table.ensure_ref_mut(inner_ty) if expr.is_mut else self.type_table.ensure_ref(inner_ty)
				return record_expr(expr, ref_ty)

			# Explicit move.
			#
			# `move <place>` is a surface marker for ownership transfer. For MVP we
			# keep it deliberately strict:
			# - the operand must be an addressable place (same as borrow),
			# - the operand must be a *plain* binding (no projections) to avoid
			#   partial-move semantics before we have a real lifetime/ownership model.
			#
			# The borrow checker enforces:
			# - no moving while borrowed, and
			# - use-after-move until reinitialization.
			if hasattr(H, "HMove") and isinstance(expr, getattr(H, "HMove")):
				def _base_lookup(hv: object) -> Optional[PlaceBase]:
					bid = getattr(hv, "binding_id", None)
					if bid is None:
						return None
					kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
					name = hv.name if hasattr(hv, "name") else str(hv)
					return PlaceBase(kind=kind, local_id=bid, name=name)

				place = place_from_expr(expr.subject, base_lookup=_base_lookup)
				if place is None:
					diagnostics.append(
						Diagnostic(
							message="move operand must be an addressable place in MVP (local/param)",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				if place.projections:
					diagnostics.append(
						Diagnostic(
							message="move of a projected place is not supported in MVP; move a local/param or use swap/replace",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				if place.base.local_id is not None and not binding_mutable.get(place.base.local_id, False):
					diagnostics.append(
						Diagnostic(
							message="move requires an owned mutable binding declared with var",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				inner_ty = type_expr(expr.subject)
				if inner_ty is not None:
					td = self.type_table.get(inner_ty)
					if td.kind is TypeKind.REF:
						diagnostics.append(
							Diagnostic(
								message="cannot move from a reference type; move requires owned storage",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
				return record_expr(expr, inner_ty)

			# Calls.
			if isinstance(expr, H.HCall):
				# Qualified type member call: `TypeRef::member(args...)`.
				#
				# MVP: only variant constructors are supported, and the qualified
				# member must be called (bare `TypeRef::member` is rejected above).
				if hasattr(H, "HQualifiedMember") and isinstance(expr.fn, getattr(H, "HQualifiedMember")):
					qm = expr.fn
					kw_pairs = getattr(expr, "kwargs", []) or []

					base_te = getattr(qm, "base_type_expr", None)
					call_type_args = getattr(expr, "type_args", None) or []
					if base_te is not None and call_type_args:
						if getattr(base_te, "args", []) or []:
							diagnostics.append(
								Diagnostic(
									message="E-QMEM-DUP-TYPEARGS: qualified member may specify type arguments only once",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						base_te = replace(base_te, args=list(call_type_args))
					base_tid = resolve_opaque_type(base_te, self.type_table, module_id=current_module_name)
					# TypeRef without explicit module context may refer to lang.core
					# variants (e.g., `Optional`). Prefer that base when present.
					try:
						base_def = self.type_table.get(base_tid)
					except Exception:
						base_def = None
					if base_def is None or base_def.kind is not TypeKind.VARIANT:
						name = getattr(base_te, "name", None)
						if isinstance(name, str):
							vb = self.type_table.get_variant_base(module_id=current_module_name, name=name) or self.type_table.get_variant_base(
								module_id="lang.core", name=name
							)
							if vb is not None:
								base_tid = vb
								base_def = self.type_table.get(base_tid)

					if base_def is None or base_def.kind is not TypeKind.VARIANT:
						diagnostics.append(
							Diagnostic(
								message="E-QMEM-NONVARIANT: qualified member base is not a variant type",
								severity="error",
								span=getattr(qm, "loc", getattr(expr, "loc", Span())),
							)
						)
						return record_expr(expr, self._unknown)

					schema = self.type_table.get_variant_schema(base_tid)
					if schema is None:
						diagnostics.append(
							Diagnostic(
								message="internal: missing variant schema for qualified member base (compiler bug)",
								severity="error",
								span=getattr(qm, "loc", getattr(expr, "loc", Span())),
							)
						)
						return record_expr(expr, self._unknown)

					# Validate and map ctor arguments. For MVP:
					# - positional args require exact arity
					# - named args require all fields, no mixing, no unknown/dup/missing
					arm_schema = next((a for a in schema.arms if a.name == qm.member), None)
					if arm_schema is None:
						ctors = self._format_ctor_signature_list(schema=schema, instance=None, current_module=current_module_name)
						diagnostics.append(
							Diagnostic(
								message=(
									f"E-QMEM-NO-CTOR: constructor '{qm.member}' not found in variant "
									f"'{self._pretty_type_name(base_tid, current_module=current_module_name)}'. "
									f"Available constructors: {', '.join(ctors)}"
								),
								severity="error",
								span=getattr(qm, "loc", getattr(expr, "loc", Span())),
							)
						)
						return record_expr(expr, self._unknown)

					field_names = [f.name for f in arm_schema.fields]
					mapped_types: list[TypeId | None] = [None] * len(field_names)
					mapped_spans: list[Span] = [getattr(expr, "loc", Span())] * len(field_names)

					if kw_pairs and expr.args:
						diagnostics.append(
							Diagnostic(
								message=(
									f"E-QMEM-MIXED-ARGS: constructor '{qm.member}' does not allow mixing positional "
									"and named arguments"
								),
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)

					if kw_pairs:
						# Typecheck keyword values (in written order) and place them in field order.
						for kw in kw_pairs:
							try:
								field_idx = field_names.index(kw.name)
							except ValueError:
								diagnostics.append(
									Diagnostic(
										message=f"unknown field '{kw.name}' for constructor '{qm.member}'",
										severity="error",
										span=getattr(kw, "loc", getattr(expr, "loc", Span())),
									)
								)
								continue
							if mapped_types[field_idx] is not None:
								diagnostics.append(
									Diagnostic(
										message=f"duplicate field '{kw.name}' for constructor '{qm.member}'",
										severity="error",
										span=getattr(kw, "loc", getattr(expr, "loc", Span())),
									)
								)
								continue
							mapped_types[field_idx] = type_expr(kw.value)
							mapped_spans[field_idx] = getattr(kw.value, "loc", getattr(expr, "loc", Span()))
					else:
						# Positional arguments in declaration order.
						if len(expr.args) != len(field_names):
							diagnostics.append(
								Diagnostic(
									message=f"E-QMEM-ARITY: constructor '{qm.member}' expects {len(field_names)} arguments, got {len(expr.args)}",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						for idx, a in enumerate(expr.args):
							mapped_types[idx] = type_expr(a)
							mapped_spans[idx] = getattr(a, "loc", getattr(expr, "loc", Span()))

					for idx, ty in enumerate(mapped_types):
						if ty is None:
							diagnostics.append(
								Diagnostic(
									message=f"missing field '{field_names[idx]}' for constructor '{qm.member}'",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)

					arg_types = [t if t is not None else self._unknown for t in mapped_types]

					# Determine the concrete variant type for this constructor call.
					inst_tid: TypeId = base_tid
					has_explicit_type_args = bool(getattr(base_te, "args", []) or [])
					if schema.type_params and not has_explicit_type_args:
						inferred: list[TypeId | None] = [None for _ in schema.type_params]

						def unify(gexpr: GenericTypeExpr, actual: TypeId) -> None:
							# Only infer from occurrences of type parameters. Shape mismatches
							# are reported later as normal argument type mismatches once the
							# variant instantiation is determined.
							if gexpr.param_index is not None:
								idx = int(gexpr.param_index)
								prev = inferred[idx]
								if prev is None:
									inferred[idx] = actual
									return
								if prev != actual:
									diagnostics.append(
										Diagnostic(
											message=(
												f"E-QMEM-INFER-CONFLICT: inferred type argument '{schema.type_params[idx]}' "
												f"conflicts ({self.type_table.get(prev).name} vs {self.type_table.get(actual).name})"
											),
											severity="error",
											span=getattr(expr, "loc", Span()),
										)
									)
								return

							name = gexpr.name
							args = list(gexpr.args or [])
							td = self.type_table.get(actual)
							if name in {"&", "&mut"} and args:
								if td.kind is TypeKind.REF and td.param_types:
									if name == "&mut" and not td.ref_mut:
										return
									unify(args[0], td.param_types[0])
								return
							if name == "Array" and args:
								if td.kind is TypeKind.ARRAY and td.param_types:
									unify(args[0], td.param_types[0])
								return
							if not args:
								return
							# Recurse into variant instantiations to discover nested params.
							if td.kind is TypeKind.VARIANT and len(td.param_types) == len(args):
								for sub_g, sub_t in zip(args, td.param_types):
									unify(sub_g, sub_t)

						for f, at in zip(arm_schema.fields, arg_types):
							unify(f.type_expr, at)

						if any(t is None for t in inferred):
							diagnostics.append(
								Diagnostic(
									message=(
										"E-QMEM-CANNOT-INFER: cannot infer type arguments for generic variant "
										"(underconstrained; arguments do not determine all type parameters). "
										"Fix: add an expected type (e.g., `val x: Optional<Int> = Optional::None()`) "
										"or add explicit type arguments (e.g., `Optional<Int>::None()` or `Optional::None<type Int>()`)."
									),
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						inst_tid = self.type_table.ensure_instantiated(base_tid, [t for t in inferred if t is not None])

					inst = self.type_table.get_variant_instance(inst_tid)
					if inst is None:
						diagnostics.append(
							Diagnostic(
								message="internal: variant instance missing for qualified member base (compiler bug)",
								severity="error",
								span=getattr(qm, "loc", getattr(expr, "loc", Span())),
							)
						)
						return record_expr(expr, self._unknown)
					arm_def = inst.arms_by_name.get(qm.member)
					if arm_def is None:
						ctors = self._format_ctor_signature_list(
							schema=schema, instance=inst, current_module=current_module_name
						)
						diagnostics.append(
							Diagnostic(
								message=(
									f"E-QMEM-NO-CTOR: constructor '{qm.member}' not found in variant "
									f"'{self._pretty_type_name(inst_tid, current_module=current_module_name)}'. "
									f"Available constructors: {', '.join(ctors)}"
								),
								severity="error",
								span=getattr(qm, "loc", getattr(expr, "loc", Span())),
							)
						)
						return record_expr(expr, self._unknown)
					if len(arm_def.field_types) != len(field_names):
						diagnostics.append(
							Diagnostic(
								message="internal: variant ctor schema/type mismatch (compiler bug)",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, inst_tid)
					for idx, want in enumerate(arm_def.field_types):
						arg_expr: H.HExpr | None = None
						# Re-typecheck with expected field types for better diagnostics.
						if kw_pairs:
							# Find the kw expression for this field (if any) for span.
							for kw in kw_pairs:
								if kw.name == field_names[idx]:
									arg_expr = kw.value
									break
						else:
							arg_expr = expr.args[idx] if idx < len(expr.args) else None
						have = mapped_types[idx]
						if arg_expr is not None:
							have = type_expr(arg_expr, expected_type=want)
						if have is not None and have != want:
							diagnostics.append(
								Diagnostic(
									message=(
										f"constructor '{qm.member}' field '{field_names[idx]}' type mismatch "
										f"(have {self.type_table.get(have).name}, expected {self.type_table.get(want).name})"
									),
									severity="error",
									span=mapped_spans[idx],
								)
							)
					return record_expr(expr, inst_tid)

				# Variant constructor call in expression position.
				#
				# MVP rule: constructor calls require an *expected* variant type from
				# context (annotation, parameter type, return type, etc.). Without an
				# expected type we do not guess which variant the constructor belongs to.
				if isinstance(expr.fn, H.HVar) and expected_type is not None:
					try:
						exp_def = self.type_table.get(expected_type)
					except Exception:
						exp_def = None
					if exp_def is not None and exp_def.kind is TypeKind.VARIANT:
						inst = self.type_table.get_variant_instance(expected_type)
						if inst is not None and expr.fn.name in inst.arms_by_name:
							arm_def = inst.arms_by_name[expr.fn.name]
							kw_pairs = getattr(expr, "kwargs", []) or []
							if kw_pairs and expr.args:
								diagnostics.append(
									Diagnostic(
										message=(
											f"constructor '{arm_def.name}' does not allow mixing positional and named arguments"
										),
										severity="error",
										span=getattr(expr, "loc", Span()),
									)
								)
								return record_expr(expr, self._unknown)

							field_names = list(getattr(arm_def, "field_names", []) or [])
							field_types = list(arm_def.field_types)
							if len(field_names) != len(field_types):
								diagnostics.append(
									Diagnostic(
										message="internal: variant ctor schema/type mismatch (compiler bug)",
										severity="error",
										span=getattr(expr, "loc", Span()),
									)
								)
								return record_expr(expr, expected_type)

							mapped_types: list[TypeId | None] = [None] * len(field_names)
							mapped_spans: list[Span] = [getattr(expr, "loc", Span())] * len(field_names)

							if kw_pairs:
								for kw in kw_pairs:
									try:
										field_idx = field_names.index(kw.name)
									except ValueError:
										diagnostics.append(
											Diagnostic(
												message=f"unknown field '{kw.name}' for constructor '{arm_def.name}'",
												severity="error",
												span=getattr(kw, "loc", getattr(expr, "loc", Span())),
											)
										)
										continue
									if mapped_types[field_idx] is not None:
										diagnostics.append(
											Diagnostic(
												message=f"duplicate field '{kw.name}' for constructor '{arm_def.name}'",
												severity="error",
												span=getattr(kw, "loc", getattr(expr, "loc", Span())),
											)
										)
										continue
									mapped_types[field_idx] = type_expr(kw.value, expected_type=field_types[field_idx])
									mapped_spans[field_idx] = getattr(kw.value, "loc", getattr(expr, "loc", Span()))
							else:
								if len(expr.args) != len(field_types):
									diagnostics.append(
										Diagnostic(
											message=(
												f"constructor '{arm_def.name}' expects {len(field_types)} arguments, got {len(expr.args)}"
											),
											severity="error",
											span=getattr(expr, "loc", Span()),
										)
									)
									return record_expr(expr, self._unknown)
								for idx, (arg, want) in enumerate(zip(expr.args, field_types)):
									mapped_types[idx] = type_expr(arg, expected_type=want)
									mapped_spans[idx] = getattr(arg, "loc", getattr(expr, "loc", Span()))

							for idx, want in enumerate(field_types):
								if mapped_types[idx] is None:
									diagnostics.append(
										Diagnostic(
											message=f"missing field '{field_names[idx]}' for constructor '{arm_def.name}'",
											severity="error",
											span=getattr(expr, "loc", Span()),
										)
									)
									continue
								have = mapped_types[idx]
								if have is not None and have != want:
									diagnostics.append(
										Diagnostic(
											message=(
												f"constructor '{arm_def.name}' field '{field_names[idx]}' type mismatch "
												f"(have {self.type_table.get(have).name}, expected {self.type_table.get(want).name})"
											),
											severity="error",
											span=mapped_spans[idx],
										)
									)
							return record_expr(expr, expected_type)

				# Always type fn and args first for side-effects/subexpressions.
				#
				# Special-case struct constructors: `Point(1, 2)` uses a call-like
				# surface form but is not a function call. In that case we must *not*
				# type-check `expr.fn` as a normal expression (`Point` is a type name,
				# not a value), otherwise we'd emit a misleading "unknown variable"
				# diagnostic before the constructor path has a chance to fire.
				should_type_fn = True
				if isinstance(expr.fn, H.HVar):
					# Builtins that look like calls but are not normal function values.
					# We must not type-check `expr.fn` as a variable, otherwise we'd emit
					# misleading "unknown variable" diagnostics before the builtin path
					# fires.
					if expr.fn.name in ("swap", "replace"):
						should_type_fn = False
					struct_ctor_tid: TypeId | None = None
					if "::" in expr.fn.name:
						parts = expr.fn.name.split("::")
						if len(parts) == 2:
							struct_ctor_tid = self.type_table.get_nominal(
								kind=TypeKind.STRUCT, module_id=parts[0], name=parts[1]
							)
					else:
						struct_ctor_tid = self.type_table.get_nominal(
							kind=TypeKind.STRUCT, module_id=current_module_name, name=expr.fn.name
						) or self.type_table.find_unique_nominal_by_name(kind=TypeKind.STRUCT, name=expr.fn.name)
					sig = _single_sig(expr.fn.name)
					is_struct_ctor = struct_ctor_tid is not None and sig is None
					if is_struct_ctor:
						should_type_fn = False
					if callable_registry is not None:
						should_type_fn = False
					elif _single_sig(expr.fn.name):
						should_type_fn = False
				if should_type_fn:
					type_expr(expr.fn)
				kw_pairs = getattr(expr, "kwargs", []) or []
				# When a call signature is known by name, use its parameter types as
				# expected types for arguments. This enables constructor calls inside
				# arguments, e.g. `takes_opt(Some(1))` where `takes_opt` expects
				# `Optional<Int>`.
				arg_types: list[TypeId] = []
				if isinstance(expr.fn, H.HVar):
					sig = _single_sig(expr.fn.name)
				else:
					sig = None
				if sig and sig.param_type_ids is not None:
					expected_params = sig.param_type_ids or []
					for i, a in enumerate(expr.args):
						want = expected_params[i] if i < len(expected_params) else None
						arg_types.append(type_expr(a, expected_type=want))
				else:
					arg_types = [type_expr(a) for a in expr.args]
				kw_types = [type_expr(k.value) for k in kw_pairs]

				# Builtins: swap/replace operate on *places*.
				#
				# These are part of the borrow/move MVP story: they let users extract or
				# exchange values in-place without creating "moved-from holes" in
				# containers/structs. They are validated here (with spans) and lowered as
				# dedicated MIR patterns later; they are not normal function calls.
				if isinstance(expr.fn, H.HVar) and expr.fn.name in ("swap", "replace"):
					if kw_pairs:
						diagnostics.append(
							Diagnostic(
								message=f"{expr.fn.name} does not support keyword arguments",
								severity="error",
								span=kw_pairs[0].loc if hasattr(kw_pairs[0], "loc") else getattr(expr, "loc", Span()),
							)
						)
					def _base_lookup(hv: object) -> Optional[PlaceBase]:
						bid = getattr(hv, "binding_id", None)
						if bid is None:
							return None
						kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
						name = hv.name if hasattr(hv, "name") else str(hv)
						return PlaceBase(kind=kind, local_id=bid, name=name)

					def _require_writable_place(place_expr: H.HExpr, span: Span) -> None:
						place = place_from_expr(place_expr, base_lookup=_base_lookup)
						if place is None:
							return
						# If the place includes a deref projection, mutability is provided by
						# the reference type (`&mut`) rather than the base binding being `var`.
						has_deref = any(isinstance(p, DerefProj) for p in place.projections)
						if not has_deref and place.base.local_id is not None and not binding_mutable.get(
							place.base.local_id, False
						):
							diagnostics.append(
								Diagnostic(
									message="write requires an owned mutable binding declared with var",
									severity="error",
									span=span,
								)
							)
						# Validate deref projections are through `&mut` refs.
						if has_deref and hasattr(H, "HPlaceExpr") and isinstance(place_expr, getattr(H, "HPlaceExpr")):
							cur = type_expr(place_expr.base)
							for pr in place_expr.projections:
								if isinstance(pr, H.HPlaceDeref):
									if cur is None:
										break
									ptr_def = self.type_table.get(cur)
									if ptr_def.kind is not TypeKind.REF or not ptr_def.ref_mut:
										diagnostics.append(
											Diagnostic(
												message=(
													"cannot write through *p unless p is a mutable reference (&mut T)"
												),
												severity="error",
												span=span,
											)
										)
										return
									if ptr_def.param_types:
										cur = ptr_def.param_types[0]
									continue
								if isinstance(pr, H.HPlaceField):
									if cur is None:
										break
									td = self.type_table.get(cur)
									if td.kind is TypeKind.STRUCT:
										info = self.type_table.struct_field(cur, pr.name)
										if info is not None:
											_, cur = info
									continue
								if isinstance(pr, H.HPlaceIndex):
									if cur is None:
										break
									td = self.type_table.get(cur)
									if td.kind is TypeKind.ARRAY and td.param_types:
										cur = td.param_types[0]
									continue

					name = expr.fn.name
					if name == "swap":
						if len(expr.args) != 2:
							diagnostics.append(
								Diagnostic(
									message="swap expects exactly 2 arguments",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._void)
						a, b = expr.args
						pa = place_from_expr(a, base_lookup=_base_lookup)
						pb = place_from_expr(b, base_lookup=_base_lookup)
						if pa is None:
							diagnostics.append(
								Diagnostic(
									message="swap argument 0 must be an addressable place",
									severity="error",
									span=getattr(a, "loc", getattr(expr, "loc", Span())),
								)
							)
						if pb is None:
							diagnostics.append(
								Diagnostic(
									message="swap argument 1 must be an addressable place",
									severity="error",
									span=getattr(b, "loc", getattr(expr, "loc", Span())),
								)
							)
						if pa is not None:
							_require_writable_place(a, getattr(a, "loc", getattr(expr, "loc", Span())))
						if pb is not None:
							_require_writable_place(b, getattr(b, "loc", getattr(expr, "loc", Span())))
						if arg_types[0] is not None and arg_types[1] is not None and arg_types[0] != arg_types[1]:
							diagnostics.append(
								Diagnostic(
									message="swap requires both places to have the same type",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
						if pa is not None and pb is not None and places_overlap(pa, pb):
							diagnostics.append(
								Diagnostic(
									message="swap operands must be distinct non-overlapping places",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
						return record_expr(expr, self._void)
					# replace(place, new_value) -> old_value
					if name == "replace":
						if len(expr.args) != 2:
							diagnostics.append(
								Diagnostic(
									message="replace expects exactly 2 arguments",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						place_expr, new_val_expr = expr.args
						place = place_from_expr(place_expr, base_lookup=_base_lookup)
						if place is None:
							diagnostics.append(
								Diagnostic(
									message="replace argument 0 must be an addressable place",
									severity="error",
									span=getattr(place_expr, "loc", getattr(expr, "loc", Span())),
								)
							)
							return record_expr(expr, self._unknown)
						_require_writable_place(place_expr, getattr(place_expr, "loc", getattr(expr, "loc", Span())))
						place_ty = arg_types[0]
						new_ty = arg_types[1]
						if place_ty is not None and new_ty is not None and place_ty != new_ty:
							diagnostics.append(
								Diagnostic(
									message="replace requires the new value to have the same type as the place",
									severity="error",
									span=getattr(new_val_expr, "loc", getattr(expr, "loc", Span())),
								)
							)
						return record_expr(expr, place_ty if place_ty is not None else self._unknown)

				# Struct constructor: `Point(1, 2)` constructs a `struct Point`.
				#
				# In v1, struct initialization uses a call-like surface form. This is a
				# language-level construct (not a function call) and must work even when
				# a callable registry is present.
				#
				# We only treat the call as a constructor when there is no known callable
				# signature for the same name (to avoid ambiguity if user code later
				# allows a free function named `Point`).
				def _resolve_struct_ctor_type_id(name: str) -> TypeId | None:
					# Module-qualified constructor calls are rewritten to `mod::Type`.
					if "::" in name:
						parts = name.split("::")
						if len(parts) != 2:
							return None
						mod, tname = parts[0], parts[1]
						return self.type_table.get_nominal(kind=TypeKind.STRUCT, module_id=mod, name=tname)
					# Unqualified constructor: resolve in the current module first.
					local = self.type_table.get_nominal(kind=TypeKind.STRUCT, module_id=current_module_name, name=name)
					if local is not None:
						return local
					# Fallback: accept only when the name is unique across all modules.
					return self.type_table.find_unique_nominal_by_name(kind=TypeKind.STRUCT, name=name)

				struct_id: TypeId | None = None
				struct_name: str | None = None
				if isinstance(expr.fn, H.HVar):
					struct_id = _resolve_struct_ctor_type_id(expr.fn.name)
					struct_name = expr.fn.name

				sig = _single_sig(expr.fn.name) if isinstance(expr.fn, H.HVar) else None
				if sig is None and isinstance(expr.fn, H.HVar) and struct_id is not None:
					struct_def = self.type_table.get(struct_id)
					if struct_def.kind is not TypeKind.STRUCT:
						diagnostics.append(
							Diagnostic(
								message=f"internal: struct schema '{struct_name}' is not a STRUCT TypeId",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
					field_names = list(struct_def.field_names or [])
					field_types = list(struct_def.param_types)
					if len(field_names) != len(field_types):
						diagnostics.append(
							Diagnostic(
								message=f"internal: struct '{struct_name}' schema/type mismatch",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, struct_id)
					if len(arg_types) > len(field_types):
						diagnostics.append(
							Diagnostic(
								message=f"struct '{struct_name}' constructor expects {len(field_types)} args, got {len(arg_types)}",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, struct_id)

					# Map positional + keyword args to fields in declaration order.
					mapped_types: list[Optional[TypeId]] = [None] * len(field_types)
					mapped_spans: list[Span] = [getattr(expr, "loc", Span())] * len(field_types)

					for idx, (ty, arg_expr) in enumerate(zip(arg_types, expr.args)):
						mapped_types[idx] = ty
						mapped_spans[idx] = getattr(arg_expr, "loc", getattr(expr, "loc", Span()))

					for kw, kw_ty in zip(kw_pairs, kw_types):
						try:
							field_idx = field_names.index(kw.name)
						except ValueError:
							diagnostics.append(
								Diagnostic(
									message=f"unknown field '{kw.name}' for struct '{struct_name}'",
									severity="error",
									span=getattr(kw, "loc", getattr(expr, "loc", Span())),
								)
							)
							continue
						if field_idx < len(arg_types):
							diagnostics.append(
								Diagnostic(
									message=f"duplicate field '{kw.name}' for struct '{struct_name}' (already provided positionally)",
									severity="error",
									span=getattr(kw, "loc", getattr(expr, "loc", Span())),
								)
							)
							continue
						if mapped_types[field_idx] is not None:
							diagnostics.append(
								Diagnostic(
									message=f"duplicate field '{kw.name}' for struct '{struct_name}'",
									severity="error",
									span=getattr(kw, "loc", getattr(expr, "loc", Span())),
								)
							)
							continue
						mapped_types[field_idx] = kw_ty
						mapped_spans[field_idx] = getattr(kw.value, "loc", getattr(expr, "loc", Span()))

					for idx, (have, want) in enumerate(zip(mapped_types, field_types)):
						if have is None:
							diagnostics.append(
								Diagnostic(
									message=f"missing field '{field_names[idx]}' for struct '{struct_name}' constructor",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							continue
						if have != want:
							diagnostics.append(
								Diagnostic(
									message=(
										f"struct '{struct_name}' field '{field_names[idx]}' type mismatch "
										f"(have {self.type_table.get(have).name}, expected {self.type_table.get(want).name})"
									),
									severity="error",
									span=mapped_spans[idx],
								)
							)
					return record_expr(expr, struct_id)

				if kw_pairs:
					diagnostics.append(
						Diagnostic(
							message="keyword arguments are only supported for struct constructors in MVP",
							severity="error",
							span=getattr(kw_pairs[0], "loc", getattr(expr, "loc", Span())),
						)
					)
					return record_expr(expr, self._unknown)

				# Try registry-based resolution when available.
				if callable_registry and isinstance(expr.fn, H.HVar):
					try:
						type_arg_ids: List[TypeId] | None = None
						call_type_args_span = None
						if getattr(expr, "type_args", None):
							type_arg_ids = [
								resolve_opaque_type(t, self.type_table, module_id=current_module_name)
								for t in (expr.type_args or [])
							]
							first_loc = getattr((expr.type_args or [None])[0], "loc", None)
							call_type_args_span = Span.from_loc(first_loc)
						decl, inst_sig = _resolve_free_call_with_require(
							name=expr.fn.name,
							arg_types=arg_types,
							call_type_args=type_arg_ids,
							call_type_args_span=call_type_args_span or getattr(expr, "loc", Span()),
						)
						if decl.fn_id is not None:
							expr.fn.name = function_symbol(decl.fn_id)
						call_resolutions[id(expr)] = decl
						return record_expr(expr, inst_sig.result_type)
					except ResolutionError as err:
						# If this call looks like a variant constructor invocation (unqualified
						# constructor name) but we have no expected variant type, prefer a
						# targeted diagnostic over a generic "no overload" message.
						#
						# We only do this when there are *no* visible free-function candidates
						# with the same name. If user code declares a real function named
						# `Some`, we should report overload errors for that function instead.
						if expected_type is None and expr.fn.name in ctor_to_variant_bases:
							candidates = callable_registry.get_free_candidates(
								name=expr.fn.name,
								visible_modules=visible_modules or (current_module,),
								include_private_in=current_module,
							)
							if not candidates:
								diagnostics.append(
											Diagnostic(
												message=(
													"E-CTOR-EXPECTED-TYPE: constructor call requires an expected variant type; "
													"add a type annotation or call a function that expects this variant. "
													"Hint: qualify the constructor (e.g., `Optional::None()` or `Optional<Int>::None()` or `Optional::None<type Int>()`)."
												),
												severity="error",
												span=getattr(expr, "loc", Span()),
											)
								)
								return record_expr(expr, self._unknown)
						diag_span = getattr(err, "span", None) or getattr(expr, "loc", Span())
						diagnostics.append(Diagnostic(message=str(err), severity="error", span=diag_span))
						return record_expr(expr, self._unknown)

				# Fallback: signature map by name.
				if isinstance(expr.fn, H.HVar):
					sig = _single_sig(expr.fn.name)
				else:
					sig = None
				if sig and sig.return_type_id is not None:
					return record_expr(expr, sig.return_type_id)
				# Constructor calls without an expected variant type are rejected in MVP.
				if isinstance(expr.fn, H.HVar) and expected_type is None:
					if expr.fn.name in ctor_to_variant_bases:
						diagnostics.append(
							Diagnostic(
								message=(
									"E-CTOR-EXPECTED-TYPE: constructor call requires an expected variant type; "
									"add a type annotation or call a function that expects this variant. "
									"Hint: qualify the constructor (e.g., `Optional::None()` or `Optional<Int>::None()` or `Optional::None<type Int>()`)."
								),
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
				return record_expr(expr, self._unknown)

			if isinstance(expr, H.HMethodCall):
				# Built-in DiagnosticValue helpers are reserved method names and take precedence.
				if expr.method_name in ("as_int", "as_bool", "as_string"):
					recv_ty = type_expr(expr.receiver)
					recv_def = self.type_table.get(recv_ty)
					if recv_def.kind is not TypeKind.DIAGNOSTICVALUE:
						diagnostics.append(
							Diagnostic(
								message=f"{expr.method_name} is only valid on DiagnosticValue",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
					if expr.method_name == "as_int":
						return record_expr(expr, self._opt_int)
					if expr.method_name == "as_bool":
						return record_expr(expr, self._opt_bool)
					if expr.method_name == "as_string":
						return record_expr(expr, self._opt_string)
					return record_expr(expr, self._unknown)

				if getattr(expr, "kwargs", None):
					first = (getattr(expr, "kwargs", []) or [None])[0]
					diagnostics.append(
						Diagnostic(
							message="keyword arguments are not supported for method calls in MVP",
							severity="error",
							span=getattr(first, "loc", getattr(expr, "loc", Span())),
						)
					)
					return record_expr(expr, self._unknown)

				recv_ty = type_expr(expr.receiver)
				arg_types = [type_expr(a) for a in expr.args]

				# Iterator protocol intrinsics for `for` desugaring (MVP).
				#
				# The stage1 lowering desugars:
				#   for x in expr { body }
				# into:
				#   let it = expr.iter()
				#   loop { match it.next() { Some(x) => { body } default => { break } } }
				#
				# Modules/traits are not implemented yet, so `.iter()` / `.next()` are
				# compiler intrinsics on arrays.
				if expr.method_name == "iter" and not expr.args:
					recv_def = self.type_table.get(recv_ty)
					if recv_def.kind is TypeKind.ARRAY:
						iter_ty = ensure_array_iter_struct(recv_ty, self.type_table)
						return record_expr(expr, iter_ty)
				if expr.method_name == "next" and not expr.args:
					if is_array_iter_struct(recv_ty, self.type_table):
						iter_def = self.type_table.get(recv_ty)
						if not iter_def.param_types or len(iter_def.param_types) != 2:
							diagnostics.append(
								Diagnostic(
									message="internal array iterator type is malformed (compiler bug)",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						arr_ty = iter_def.param_types[0]
						arr_def = self.type_table.get(arr_ty)
						if arr_def.kind is not TypeKind.ARRAY or not arr_def.param_types:
							diagnostics.append(
								Diagnostic(
									message="internal array iterator type does not contain Array<T> (compiler bug)",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						elem_ty = arr_def.param_types[0]
						opt_base = self.type_table.get_variant_base(module_id="lang.core", name="Optional")
						if opt_base is None:
							diagnostics.append(
								Diagnostic(
									message="Optional<T> variant base is missing (compiler bug)",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						return record_expr(expr, self.type_table.ensure_instantiated(opt_base, [elem_ty]))

				if callable_registry:
					try:
						resolution = resolve_method_call(
							callable_registry,
							self.type_table,
							receiver_type=recv_ty,
							method_name=expr.method_name,
							arg_types=arg_types,
							visible_modules=visible_modules or (current_module,),
							current_module=current_module,
						)
						call_resolutions[id(expr)] = resolution
						return record_expr(expr, resolution.decl.signature.result_type)
					except ResolutionError as err:
						diagnostics.append(
							Diagnostic(message=str(err), severity="error", span=getattr(expr, "loc", Span()))
						)
						return record_expr(expr, self._unknown)

				if call_signatures:
					sig = _single_sig(expr.method_name)
					if sig and sig.return_type_id is not None:
						return record_expr(expr, sig.return_type_id)
				return record_expr(expr, self._unknown)

			# Field access and indexing.
			#
			# Canonical place expressions (`HPlaceExpr`) denote addressable storage
			# locations. In expression position they behave like lvalues: their type is
			# the type of the referenced storage location.
			if hasattr(H, "HPlaceExpr") and isinstance(expr, getattr(H, "HPlaceExpr")):
				current_ty = type_expr(expr.base)
				for proj in expr.projections:
					if isinstance(proj, H.HPlaceDeref):
						td = self.type_table.get(current_ty)
						if td.kind is not TypeKind.REF or not td.param_types:
							diagnostics.append(
								Diagnostic(
									message="deref requires a reference value",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						current_ty = td.param_types[0]
						continue
					if isinstance(proj, H.HPlaceField):
						td = self.type_table.get(current_ty)
						if td.kind is not TypeKind.STRUCT:
							diagnostics.append(
								Diagnostic(
									message="field access requires a struct value",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						info = self.type_table.struct_field(current_ty, proj.name)
						if info is None:
							diagnostics.append(
								Diagnostic(
									message=f"unknown field '{proj.name}' on struct '{td.name}'",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						_, field_ty = info
						current_ty = field_ty
						continue
					if isinstance(proj, H.HPlaceIndex):
						idx_ty = type_expr(proj.index)
						if idx_ty is not None and idx_ty not in (self._int, self._uint):
							diagnostics.append(
								Diagnostic(
									message="array index must be an integer type",
									severity="error",
									span=getattr(proj.index, "loc", getattr(expr, "loc", Span())),
								)
							)
							return record_expr(expr, self._unknown)
						td = self.type_table.get(current_ty)
						if td.kind is not TypeKind.ARRAY or not td.param_types:
							diagnostics.append(
								Diagnostic(
									message="indexing requires an Array value",
									severity="error",
									span=getattr(expr, "loc", Span()),
								)
							)
							return record_expr(expr, self._unknown)
						current_ty = td.param_types[0]
						continue
					diagnostics.append(
						Diagnostic(
							message="unsupported place projection",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				return record_expr(expr, current_ty)

			if isinstance(expr, H.HField):
				sub_ty = type_expr(expr.subject)
				if expr.name == "attrs":
					diagnostics.append(
						Diagnostic(
							message='attrs must be indexed: use error.attrs["key"]',
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				# Struct fields: `x.field`
				sub_def = self.type_table.get(sub_ty)
				if sub_def.kind is TypeKind.STRUCT:
					info = self.type_table.struct_field(sub_ty, expr.name)
					if info is None:
						diagnostics.append(
							Diagnostic(
								message=f"unknown field '{expr.name}' on struct '{sub_def.name}'",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
					_, field_ty = info
					return record_expr(expr, field_ty)
				return record_expr(expr, self._unknown)

			if isinstance(expr, H.HIndex):
				# Special-case Error.attrs["key"] → DiagnosticValue.
				if isinstance(expr.subject, H.HField) and expr.subject.name == "attrs":
					sub_ty = type_expr(expr.subject.subject)
					key_ty = type_expr(expr.index)
					if self.type_table.get(sub_ty).kind is not TypeKind.ERROR:
						diagnostics.append(
							Diagnostic(
								message="attrs access is only supported on Error values",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
					if self.type_table.get(key_ty).name != "String":
						diagnostics.append(
							Diagnostic(
								message="Error.attrs expects a String key",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
					return record_expr(expr, self._dv)

				sub_ty = type_expr(expr.subject)
				idx_ty = type_expr(expr.index)
				td = self.type_table.get(sub_ty)
				if idx_ty is not None and idx_ty not in (self._int, self._uint):
					diagnostics.append(
						Diagnostic(
							message="array index must be an integer type",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				if td.kind is TypeKind.ARRAY and td.param_types:
					return record_expr(expr, td.param_types[0])
				diagnostics.append(
					Diagnostic(
						message="indexing requires an Array value",
						severity="error",
						span=getattr(expr, "loc", Span()),
					)
				)
				return record_expr(expr, self._unknown)

			# Disallow implicit setters; attrs require explicit runtime helpers in MIR.
			if isinstance(expr, H.HCall) and isinstance(expr.fn, H.HField) and expr.fn.name == "attrs":
				diagnostics.append(
					Diagnostic(
						message="attrs values must be DiagnosticValue; implicit setters are not supported",
						severity="error",
						span=getattr(expr, "loc", Span()),
					)
				)
				return record_expr(expr, self._unknown)

			# Unary/binary ops (MVP).
			if isinstance(expr, H.HUnary):
				sub_ty = type_expr(expr.expr)
				if expr.op is H.UnaryOp.NEG:
					return record_expr(expr, sub_ty if sub_ty in (self._int, self._float) else self._unknown)
				if expr.op in (H.UnaryOp.NOT,):
					return record_expr(expr, self._bool)
				if expr.op is H.UnaryOp.BIT_NOT:
					return record_expr(expr, sub_ty if sub_ty in (self._uint,) else self._unknown)
				return record_expr(expr, self._unknown)

			if isinstance(expr, H.HBinary):
				left_ty = type_expr(expr.left)
				right_ty = type_expr(expr.right)
				if expr.op in (
					H.BinaryOp.ADD,
					H.BinaryOp.SUB,
					H.BinaryOp.MUL,
					H.BinaryOp.MOD,
				):
					# Arithmetic on Int/Float; MOD also on Uint.
					if left_ty == self._int and right_ty == self._int:
						return record_expr(expr, self._int)
					if left_ty == self._float and right_ty == self._float:
						return record_expr(expr, self._float)
					if expr.op is H.BinaryOp.MOD and left_ty == self._uint and right_ty == self._uint:
						return record_expr(expr, self._uint)
					return record_expr(expr, self._unknown)
				if expr.op in (H.BinaryOp.DIV,):
					if left_ty == self._int and right_ty == self._int:
						return record_expr(expr, self._int)
					if left_ty == self._float and right_ty == self._float:
						return record_expr(expr, self._float)
					return record_expr(expr, self._unknown)
				if expr.op in (
					H.BinaryOp.BIT_AND,
					H.BinaryOp.BIT_OR,
					H.BinaryOp.BIT_XOR,
					H.BinaryOp.SHL,
					H.BinaryOp.SHR,
				):
					if left_ty == self._uint and right_ty == self._uint:
						return record_expr(expr, self._uint)
					diagnostics.append(
						Diagnostic(
							message="bitwise operators require Uint operands",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				if expr.op in (
					H.BinaryOp.EQ,
					H.BinaryOp.NE,
					H.BinaryOp.LT,
					H.BinaryOp.LE,
					H.BinaryOp.GT,
					H.BinaryOp.GE,
				):
					return record_expr(expr, self._bool)
				if expr.op in (H.BinaryOp.AND, H.BinaryOp.OR):
					return record_expr(expr, self._bool)
				return record_expr(expr, self._unknown)

			# Arrays/ternary.
			if isinstance(expr, H.HArrayLiteral):
				elem_types = [type_expr(e) for e in expr.elements]
				if elem_types and all(t == elem_types[0] for t in elem_types):
					return record_expr(expr, self.type_table.new_array(elem_types[0]))
				return record_expr(expr, self._unknown)

			if isinstance(expr, H.HTernary):
				type_expr(expr.cond)
				then_ty = type_expr(expr.then_expr)
				else_ty = type_expr(expr.else_expr)
				return record_expr(expr, then_ty if then_ty == else_ty else self._unknown)

			# Exception constructors are only legal as throw payloads.
			if isinstance(expr, H.HExceptionInit):
				if not allow_exception_init:
					diagnostics.append(
						Diagnostic(
							message="exception constructors are only valid as throw payloads",
							severity="error",
							span=getattr(expr, "loc", Span()),
						)
					)
					return record_expr(expr, self._unknown)
				from lang2.driftc.core.exception_ctor_args import KwArg as _KwArg, resolve_exception_ctor_args

				schemas: dict[str, tuple[str, list[str]]] = getattr(self.type_table, "exception_schemas", {}) or {}
				schema = schemas.get(expr.event_fqn)
				decl_fields: list[str] | None
				if schema is None:
					decl_fields = None
				else:
					_decl_fqn, decl_fields = schema

				resolved, diags = resolve_exception_ctor_args(
					event_fqn=expr.event_fqn,
					declared_fields=decl_fields,
					pos_args=[(a, getattr(a, "loc", Span())) for a in expr.pos_args],
					kw_args=[
						_KwArg(name=kw.name, value=kw.value, name_span=getattr(kw, "loc", Span()))
						for kw in expr.kw_args
					],
					span=getattr(expr, "loc", Span()),
				)
				diagnostics.extend(diags)

				values_to_validate = [v for _name, v in resolved]
				if decl_fields is None:
					# Unknown schema: we cannot map positional args to names, but we
					# still validate that provided values are DV or supported literals.
					values_to_validate = list(expr.pos_args) + [kw.value for kw in expr.kw_args]

				for val_expr in values_to_validate:
					val_ty = type_expr(val_expr)
					is_primitive_literal = isinstance(val_expr, (H.HLiteralInt, H.HLiteralBool, H.HLiteralString))
					if val_ty != self._dv and not is_primitive_literal:
						diagnostics.append(
							Diagnostic(
								message=(
									"exception field value must be a DiagnosticValue or a primitive literal "
									"(Int/Bool/String)"
								),
								severity="error",
								span=getattr(val_expr, "loc", Span()),
							)
						)
				return record_expr(expr, self._dv)

			# DiagnosticValue constructors.
			if isinstance(expr, H.HDVInit):
				arg_types = [type_expr(a) for a in expr.args]
				if expr.args:
					# Only zero-arg (missing) or single-arg primitive DV ctors are supported in v1.
					if len(expr.args) > 1:
						diagnostics.append(
							Diagnostic(
								message="DiagnosticValue constructors support at most one argument in v1",
								severity="error",
								span=getattr(expr, "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
					inner_ty = arg_types[0]
					if inner_ty not in (self._int, self._bool, self._string):
						diagnostics.append(
							Diagnostic(
								message="unsupported DiagnosticValue constructor argument type",
								severity="error",
								span=getattr(expr.args[0], "loc", Span()),
							)
						)
						return record_expr(expr, self._unknown)
				return record_expr(expr, self._dv)

			# Result/try sugar.
			if isinstance(expr, H.HResultOk):
				ok_ty = type_expr(expr.value)
				err_ty = self._unknown
				return record_expr(expr, self.type_table.new_fnresult(ok_ty, err_ty))

			# Fallback: unknown type.
			return record_expr(expr, self._unknown)

		catch_depth = 0

		def type_stmt(stmt: H.HStmt) -> None:
			nonlocal catch_depth
			# Borrow conflicts are diagnosed within a single statement.
			borrows_in_stmt.clear()
			if isinstance(stmt, H.HLet):
				if stmt.binding_id is None:
					stmt.binding_id = self._alloc_local_id()
				locals.append(stmt.binding_id)
				declared_ty: TypeId | None = None
				if getattr(stmt, "declared_type_expr", None) is not None:
					try:
						declared_ty = resolve_opaque_type(stmt.declared_type_expr, self.type_table, module_id=current_module_name)
					except Exception:
						declared_ty = None
				# If the user provides a type annotation, treat it as the expected type
				# for the initializer. This enables constructor calls like:
				#   val x: Optional<Int> = Some(1)
				inferred_ty = type_expr(stmt.value, expected_type=declared_ty)
				val_ty = inferred_ty
				if declared_ty is not None:
					# MVP: treat the declared type as authoritative for the binding.
					# If the initializer is obviously incompatible, emit a diagnostic.
					# Numeric literals are allowed to flow into Int/Uint without requiring
					# an explicit cast.
					if inferred_ty is not None and inferred_ty != declared_ty:
						is_int_lit = isinstance(stmt.value, H.HLiteralInt)
						decl_name = self.type_table.get(declared_ty).name
						inf_name = self.type_table.get(inferred_ty).name
						if not (is_int_lit and decl_name in ("Int", "Uint") and inf_name == "Int"):
							diagnostics.append(
								Diagnostic(
									message=f"initializer type '{inf_name}' does not match declared type '{decl_name}'",
									severity="error",
									span=getattr(stmt, "loc", Span()),
								)
							)
					val_ty = declared_ty
				scope_env[-1][stmt.name] = val_ty
				scope_bindings[-1][stmt.name] = stmt.binding_id
				binding_types[stmt.binding_id] = val_ty
				binding_names[stmt.binding_id] = stmt.name
				binding_mutable[stmt.binding_id] = bool(getattr(stmt, "is_mutable", False))
				binding_place_kind[stmt.binding_id] = PlaceKind.LOCAL
				# Track origin for ref-typed locals: allow propagation from an existing
				# ref binding, otherwise treat as local/temporary.
				if val_ty is not None and self.type_table.get(val_ty).kind is TypeKind.REF:
					origin: Optional[int] = None
					# val r = p;  (p is a ref param or a local ref derived from param)
					if isinstance(stmt.value, H.HVar) and getattr(stmt.value, "binding_id", None) is not None:
						origin = ref_origin_param.get(stmt.value.binding_id)
					# val r = &(*p).x;  (reborrow through a ref that derives from param)
					if isinstance(stmt.value, H.HBorrow):
						def _base_lookup(hv: object) -> Optional[PlaceBase]:
							bid = getattr(hv, "binding_id", None)
							if bid is None:
								return None
							kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
							name = hv.name if hasattr(hv, "name") else str(hv)
							return PlaceBase(kind=kind, local_id=bid, name=name)

						sub_place = place_from_expr(stmt.value.subject, base_lookup=_base_lookup)
						if sub_place is not None and any(isinstance(p, DerefProj) for p in sub_place.projections):
							origin = ref_origin_param.get(sub_place.base.local_id)
					ref_origin_param[stmt.binding_id] = origin
			elif isinstance(stmt, H.HBlock):
				# Block statements introduce a nested lexical scope.
				#
				# This is used by desugarings like `for` which need to introduce hidden
				# temporaries without leaking them to the surrounding scope.
				scope_env.append(dict())
				scope_bindings.append(dict())
				try:
					for s in stmt.statements:
						type_stmt(s)
				finally:
					scope_env.pop()
					scope_bindings.pop()
			elif isinstance(stmt, H.HAssign):
				type_expr(stmt.value)
				type_expr(stmt.target)
				# Assignment target must be an addressable place.
				def _base_lookup(hv: object) -> Optional[PlaceBase]:
					bid = getattr(hv, "binding_id", None)
					if bid is None:
						return None
					kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
					name = hv.name if hasattr(hv, "name") else str(hv)
					return PlaceBase(kind=kind, local_id=bid, name=name)

				if place_from_expr(stmt.target, base_lookup=_base_lookup) is None:
					diagnostics.append(
						Diagnostic(
							message="assignment target must be an addressable place",
							severity="error",
							span=getattr(stmt, "loc", Span()),
							)
						)
				# If assigning to a ref-typed binding, track origin (simple propagation).
				if isinstance(stmt.target, H.HVar) and getattr(stmt.target, "binding_id", None) is not None:
					tgt_bid = stmt.target.binding_id
					tgt_ty = binding_types.get(tgt_bid)
					if tgt_ty is not None and self.type_table.get(tgt_ty).kind is TypeKind.REF:
						origin: Optional[int] = None
						if isinstance(stmt.value, H.HVar) and getattr(stmt.value, "binding_id", None) is not None:
							origin = ref_origin_param.get(stmt.value.binding_id)
						ref_origin_param[tgt_bid] = origin
			elif hasattr(H, "HAugAssign") and isinstance(stmt, getattr(H, "HAugAssign")):
				"""
				Augmented assignment (`+=`) type rules (MVP).

				- Target must be an addressable place (same as `=`).
				- Operand types must match.
				- Currently supported for numeric scalars only (Int/Float).

				We enforce *writability* here as well:
				- Writes to owned storage require a `var` base binding.
				- Writes through deref require a mutable reference (`&mut`) at each deref.
				"""
				tgt_ty = type_expr(stmt.target)
				val_ty = type_expr(stmt.value)

				def _base_lookup(hv: object) -> Optional[PlaceBase]:
					bid = getattr(hv, "binding_id", None)
					if bid is None:
						return None
					kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
					name = hv.name if hasattr(hv, "name") else str(hv)
					return PlaceBase(kind=kind, local_id=bid, name=name)

				tgt_place = place_from_expr(stmt.target, base_lookup=_base_lookup)
				if tgt_place is None:
					diagnostics.append(
						Diagnostic(
							message="assignment target must be an addressable place",
							severity="error",
							span=getattr(stmt, "loc", Span()),
						)
					)
					return

				# Writability: owned storage requires `var`; reborrow writes require `&mut`.
				has_deref = any(isinstance(p, DerefProj) for p in tgt_place.projections)
				if not has_deref and tgt_place.base.local_id is not None and not binding_mutable.get(tgt_place.base.local_id, False):
					diagnostics.append(
						Diagnostic(
							message="cannot assign through an immutable binding; declare it with `var`",
							severity="error",
							span=getattr(stmt, "loc", Span()),
						)
					)
				if has_deref and hasattr(H, "HPlaceExpr") and isinstance(stmt.target, getattr(H, "HPlaceExpr")):
					cur = type_expr(stmt.target.base)
					for pr in stmt.target.projections:
						if isinstance(pr, H.HPlaceDeref):
							ptr_def = self.type_table.get(cur)
							if ptr_def.kind is not TypeKind.REF or not ptr_def.ref_mut:
								diagnostics.append(
									Diagnostic(
										message="cannot assign through *p unless p is a mutable reference (&mut T)",
										severity="error",
										span=getattr(stmt, "loc", Span()),
									)
								)
								break
							if ptr_def.param_types:
								cur = ptr_def.param_types[0]
						elif isinstance(pr, H.HPlaceField):
							td = self.type_table.get(cur)
							if td.kind is TypeKind.STRUCT:
								info = self.type_table.struct_field(cur, pr.name)
								if info is not None:
									_, cur = info
						elif isinstance(pr, H.HPlaceIndex):
							td = self.type_table.get(cur)
							if td.kind is TypeKind.ARRAY and td.param_types:
								cur = td.param_types[0]

				arith_ops = {"+=", "-=", "*=", "/="}
				bit_ops = {"&=", "|=", "^=", "<<=", ">>="}
				mod_ops = {"%="}
				# Type check: supported augmented assignment operators.
				if stmt.op not in (arith_ops | bit_ops | mod_ops):
					diagnostics.append(
						Diagnostic(
							message=f"unsupported augmented assignment operator '{stmt.op}'",
							severity="error",
							span=getattr(stmt, "loc", Span()),
						)
					)
				if tgt_ty != val_ty:
					diagnostics.append(
						Diagnostic(
							message="augmented assignment requires matching operand types",
							severity="error",
							span=getattr(stmt, "loc", Span()),
						)
					)
				if stmt.op in arith_ops:
					if tgt_ty not in (self._int, self._float):
						pretty = self.type_table.get(tgt_ty).name if tgt_ty is not None else "Unknown"
						diagnostics.append(
							Diagnostic(
								message=f"augmented assignment '{stmt.op}' is not supported for type '{pretty}' in MVP",
								severity="error",
								span=getattr(stmt, "loc", Span()),
							)
						)
				elif stmt.op in mod_ops:
					if tgt_ty not in (self._int, self._uint):
						pretty = self.type_table.get(tgt_ty).name if tgt_ty is not None else "Unknown"
						diagnostics.append(
							Diagnostic(
								message=f"augmented assignment '{stmt.op}' is not supported for type '{pretty}' in MVP",
								severity="error",
								span=getattr(stmt, "loc", Span()),
							)
						)
				elif stmt.op in bit_ops:
					if tgt_ty != self._uint:
						pretty = self.type_table.get(tgt_ty).name if tgt_ty is not None else "Unknown"
						diagnostics.append(
							Diagnostic(
								message=f"bitwise augmented assignment requires Uint operands (have '{pretty}')",
								severity="error",
								span=getattr(stmt, "loc", Span()),
							)
						)
			elif isinstance(stmt, H.HExprStmt):
				type_expr(stmt.expr, used_as_value=False)
			elif isinstance(stmt, H.HReturn):
				if stmt.value is not None:
					type_expr(stmt.value, expected_type=return_type)
			elif isinstance(stmt, H.HIf):
				if isinstance(stmt.cond, H.HTraitExpr):
					parser_expr = _trait_expr_to_parser(stmt.cond)
					subst: dict[str, object] = {}
					subjects: set[str] = set()
					_collect_trait_subjects(parser_expr, subjects)
					for subj in subjects:
						if subj == "Self":
							continue
						for scope in reversed(scope_env):
							if subj in scope:
								subst[subj] = _normalize_type_key(type_key_from_typeid(self.type_table, scope[subj]))
								break
					world = None
					if isinstance(trait_worlds, dict):
						world = trait_worlds.get(current_module_name)
					if world is None:
						diagnostics.append(
							Diagnostic(
								message="trait guard cannot be evaluated without a trait world",
								severity="error",
								span=getattr(stmt.cond, "loc", Span()),
							)
						)
						type_block(stmt.then_block)
						if stmt.else_block:
							type_block(stmt.else_block)
					else:
						env = TraitEnv(default_module=current_module_name)
						res = prove_expr(world, env, subst, parser_expr)
						if res.status is ProofStatus.PROVED:
							type_block(stmt.then_block)
						elif res.status is ProofStatus.REFUTED:
							if stmt.else_block:
								type_block(stmt.else_block)
						else:
							diagnostics.append(
								Diagnostic(
									message="trait guard is not decidable at compile time",
									severity="error",
									span=getattr(stmt.cond, "loc", Span()),
								)
							)
							type_block(stmt.then_block)
							if stmt.else_block:
								type_block(stmt.else_block)
				else:
					type_expr(stmt.cond)
					type_block(stmt.then_block)
					if stmt.else_block:
						type_block(stmt.else_block)
			elif isinstance(stmt, H.HLoop):
				type_block(stmt.body)
			elif isinstance(stmt, H.HTry):
				type_block(stmt.body)
				for arm in stmt.catches:
					catch_depth += 1
					type_block(arm.block)
					catch_depth -= 1
			elif isinstance(stmt, H.HThrow):
				if isinstance(stmt.value, H.HMethodCall) and stmt.value.method_name == "unwrap_err":
					type_expr(stmt.value)
				elif not isinstance(stmt.value, H.HExceptionInit):
					diagnostics.append(
						Diagnostic(
							message="throw payload must be an exception constructor",
							severity="error",
							span=getattr(stmt, "loc", Span()),
						)
					)
					type_expr(stmt.value)
				else:
					type_expr(stmt.value, allow_exception_init=True)
			elif isinstance(stmt, H.HRethrow):
				# Valid only inside a catch; outside catches it is reported here.
				if catch_depth == 0:
					diagnostics.append(
						Diagnostic(
							message="rethrow is only valid inside a catch block",
							severity="error",
							span=getattr(stmt, "loc", Span()),
						)
					)
			# HBreak/HContinue are typeless here.

		def type_block(block: H.HBlock) -> None:
			scope_env.append(dict())
			scope_bindings.append(dict())
			try:
				for s in block.statements:
					type_stmt(s)
			finally:
				scope_env.pop()
				scope_bindings.pop()

		type_block(body)

		typed = TypedFn(
			fn_id=fn_id,
			name=fn_id.name,
			params=params,
			param_bindings=param_bindings,
			locals=locals,
			body=body,
			expr_types={ref: ty for ref, ty in expr_types.items()},
			binding_for_var=binding_for_var,
			binding_types=binding_types,
			binding_names=binding_names,
			binding_mutable=binding_mutable,
			call_resolutions=call_resolutions,
		)

		# MVP escape policy: reference returns must be derived from a single
		# reference parameter.
		if return_type is not None and self.type_table.get(return_type).kind is TypeKind.REF:
			# Seed origin for reference parameters.
			for bid in param_bindings:
				pty = binding_types.get(bid)
				if pty is not None and self.type_table.get(pty).kind is TypeKind.REF:
					ref_origin_param[bid] = bid

			def _return_origin(expr: H.HExpr) -> Optional[int]:
				# Returning an existing reference value (param or local ref).
				if isinstance(expr, H.HVar) and getattr(expr, "binding_id", None) is not None:
					return ref_origin_param.get(expr.binding_id)
				if hasattr(H, "HPlaceExpr") and isinstance(expr, getattr(H, "HPlaceExpr")):
					if isinstance(expr.base, H.HVar) and getattr(expr.base, "binding_id", None) is not None:
						return ref_origin_param.get(expr.base.binding_id)
				# Returning a borrow is only allowed when it reborrows through a ref
				# that originates from a reference parameter (e.g. &(*p).x).
				if isinstance(expr, H.HBorrow):
					def _base_lookup(hv: object) -> Optional[PlaceBase]:
						bid = getattr(hv, "binding_id", None)
						if bid is None:
							return None
						kind = binding_place_kind.get(bid, PlaceKind.LOCAL)
						name = hv.name if hasattr(hv, "name") else str(hv)
						return PlaceBase(kind=kind, local_id=bid, name=name)

					sub_place = place_from_expr(expr.subject, base_lookup=_base_lookup)
					if sub_place is None:
						return None
					if not any(isinstance(p, DerefProj) for p in sub_place.projections):
						return None
					return ref_origin_param.get(sub_place.base.local_id)
				return None

			def _walk_returns(block: H.HBlock, out: List[tuple[Optional[int], Span]]) -> None:
				for s in block.statements:
					if isinstance(s, H.HReturn) and s.value is not None:
						out.append((_return_origin(s.value), getattr(s, "loc", getattr(s.value, "loc", Span()))))
					elif isinstance(s, H.HIf):
						_walk_returns(s.then_block, out)
						if s.else_block:
							_walk_returns(s.else_block, out)
					elif isinstance(s, H.HLoop):
						_walk_returns(s.body, out)
					elif isinstance(s, H.HTry):
						_walk_returns(s.body, out)
						for arm in s.catches:
							_walk_returns(arm.block, out)

			returns: List[tuple[Optional[int], Span]] = []
			_walk_returns(body, returns)

			# Determine the single allowed origin param (if any).
			origin_param: Optional[int] = None
			for origin, span in returns:
				if origin is None:
					diagnostics.append(
						Diagnostic(
							message="reference return must be derived from a reference parameter (MVP escape rule)",
							severity="error",
							span=span,
						)
					)
					continue
				if origin_param is None:
					origin_param = origin
				elif origin != origin_param:
					diagnostics.append(
						Diagnostic(
							message="reference return must derive from a single reference parameter (cannot return from different params)",
							severity="error",
							span=span,
						)
					)

		return TypeCheckResult(typed_fn=typed, diagnostics=diagnostics)

	def _alloc_param_id(self) -> ParamId:
		pid = self._next_binding_id
		self._next_binding_id += 1
		return pid

	def _alloc_local_id(self) -> LocalId:
		lid = self._next_binding_id
		self._next_binding_id += 1
		return lid

[==== File: staged/lang2/tests/core/test_type_subst.py =====]
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
from __future__ import annotations

from lang2.driftc.core.function_id import FunctionId
from lang2.driftc.core.type_subst import Subst, apply_subst
from lang2.driftc.core.types_core import TypeParamId, TypeTable, TypeKind


def test_subst_owner_isolated() -> None:
	table = TypeTable()
	fid_a = FunctionId(module="main", name="f", ordinal=0)
	fid_b = FunctionId(module="main", name="g", ordinal=0)
	tp_a = TypeParamId(owner=fid_a, index=0)
	tp_b = TypeParamId(owner=fid_b, index=0)
	tv_a = table.ensure_typevar(tp_a, name="T")
	tv_b = table.ensure_typevar(tp_b, name="T")
	subst = Subst(owner=fid_a, args=[table.ensure_int()])
	assert apply_subst(tv_a, subst, table) == table.ensure_int()
	assert apply_subst(tv_b, subst, table) == tv_b


def test_subst_nested_types() -> None:
	table = TypeTable()
	fid = FunctionId(module="main", name="wrap", ordinal=0)
	tp = TypeParamId(owner=fid, index=0)
	tv = table.ensure_typevar(tp, name="T")
	arr = table.new_array(tv)
	opt = table.new_optional(arr)
	subst = Subst(owner=fid, args=[table.ensure_int()])
	res = apply_subst(opt, subst, table)
	td = table.get(res)
	assert td.kind is TypeKind.OPTIONAL
	inner = table.get(td.param_types[0])
	assert inner.kind is TypeKind.ARRAY
	assert inner.param_types[0] == table.ensure_int()

[==== File: staged/lang2/tests/traits/tests/test_trait_world.py =====]
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
from __future__ import annotations

from lang2.driftc.parser import parser as p
from lang2.driftc.parser import parse_drift_to_hir
from lang2.driftc.core.types_core import TypeParamId
from lang2.driftc.traits.world import build_trait_world


def test_trait_world_collects_traits_and_impls_with_qualified_heads() -> None:
	prog = p.parse_program(
		"""
trait Debuggable { fn fmt(self: Int) returns String }

implement Debuggable for a.Point { fn fmt(self: a.Point) returns String { return ""; } }
implement Debuggable for b.Point { fn fmt(self: b.Point) returns String { return ""; } }
"""
	)
	world = build_trait_world(prog)
	assert world.diagnostics == []
	assert len(world.traits) == 1
	assert len(world.impls) == 2
	assert len(world.impls_by_trait_target) == 2


def test_trait_world_reports_unknown_trait_in_require() -> None:
	prog = p.parse_program(
		"""
struct File require Self is Missing { }
"""
	)
	world = build_trait_world(prog)
	assert any("unknown trait" in d.message for d in world.diagnostics)


def test_trait_world_allows_unqualified_trait_in_struct_require() -> None:
	prog = p.parse_program(
		"""
trait Debuggable { fn fmt(self: Int) returns String }
struct File require Self is Debuggable { }
"""
	)
	world = build_trait_world(prog)
	assert world.diagnostics == []


def test_trait_world_rejects_overlapping_impls_for_same_head() -> None:
	prog = p.parse_program(
		"""
trait Debuggable { fn fmt(self: Int) returns String }

implement Debuggable for Box<T> { fn fmt(self: Box<T>) returns String { return ""; } }
implement Debuggable for Box<U> { fn fmt(self: Box<U>) returns String { return ""; } }
"""
	)
	world = build_trait_world(prog)
	assert any("overlapping impls" in d.message for d in world.diagnostics)


def test_trait_world_rejects_self_in_function_require() -> None:
	prog = p.parse_program(
		"""
trait Debuggable { fn fmt(self: Int) returns String }

fn use_file() returns Int require Self is Debuggable { return 0; }
"""
	)
	world = build_trait_world(prog)
	assert any("function require clause cannot use 'Self'" in d.message for d in world.diagnostics)


def test_trait_world_lowers_fn_require_subjects_to_typeparam_ids(tmp_path) -> None:
	src = tmp_path / "main.drift"
	src.write_text(
		"""
trait Debuggable { fn fmt(self: Int) returns String }

fn use<T>(x: T) returns Int require T is Debuggable { return 0; }
"""
	)
	_func_hirs, sigs, _ids, table, _excs, diagnostics = parse_drift_to_hir(src)
	assert diagnostics == []
	world = table.trait_worlds.get("main")
	assert world is not None
	fn_id = next(fid for fid in sigs.keys() if fid.name == "use")
	req = world.requires_by_fn.get(fn_id)
	assert req is not None
	if hasattr(req, "subject"):
		assert isinstance(req.subject, TypeParamId)
	elif hasattr(req, "left"):
		assert isinstance(req.left.subject, TypeParamId)

[==== File: staged/lang2/tests/type_checker/tests/test_type_checker_expressions.py =====]
#!/usr/bin/env python3
# vim: set noexpandtab: -*- indent-tabs-mode: t -*-
# author: Sławomir Liszniański; created: 2025-12-09
"""Expression typing coverage: unary/binary/index/array/ternary."""

from lang2.driftc import stage1 as H
from lang2.driftc.type_checker import TypeChecker
from lang2.driftc.core.function_id import FunctionId
from lang2.driftc.core.types_core import TypeKind, TypeParamId, TypeTable
from lang2.driftc.checker import FnSignature, TypeParam
from lang2.driftc.method_registry import CallableRegistry, CallableSignature, Visibility, SelfMode
from lang2.driftc.method_resolver import MethodResolution
from lang2.driftc.parser import ast as parser_ast
from lang2.driftc.core.span import Span


def _tc() -> TypeChecker:
	return TypeChecker(TypeTable())


def _fn_id(name: str) -> FunctionId:
	return FunctionId(module="main", name=name, ordinal=0)


def test_binary_int_ops_infer_int():
	tc = _tc()
	block = H.HBlock(
		statements=[
			H.HExprStmt(
				expr=H.HBinary(left=H.HLiteralInt(1), op=H.BinaryOp.ADD, right=H.HLiteralInt(2)),
			)
		]
	)
	res = tc.check_function(_fn_id("f"), block)
	assert res.diagnostics == []
	assert tc.type_table.ensure_int() in res.typed_fn.expr_types.values()


def test_logical_ops_infer_bool():
	tc = _tc()
	block = H.HBlock(
		statements=[
			H.HExprStmt(
				expr=H.HBinary(left=H.HLiteralBool(True), op=H.BinaryOp.AND, right=H.HLiteralBool(False)),
			)
		]
	)
	res = tc.check_function(_fn_id("g"), block)
	assert res.diagnostics == []
	assert tc.type_table.ensure_bool() in res.typed_fn.expr_types.values()


def test_unary_ops():
	tc = _tc()
	block = H.HBlock(
		statements=[
			H.HExprStmt(expr=H.HUnary(op=H.UnaryOp.NEG, expr=H.HLiteralInt(1))),
			H.HExprStmt(expr=H.HUnary(op=H.UnaryOp.NOT, expr=H.HLiteralBool(True))),
		]
	)
	res = tc.check_function(_fn_id("u"), block)
	assert res.diagnostics == []
	assert tc.type_table.ensure_int() in res.typed_fn.expr_types.values()
	assert tc.type_table.ensure_bool() in res.typed_fn.expr_types.values()


def test_array_literal_and_index():
	tc = _tc()
	block = H.HBlock(
		statements=[
			H.HLet(
				name="xs",
				value=H.HArrayLiteral(elements=[H.HLiteralInt(1), H.HLiteralInt(2)]),
				declared_type_expr=None,
			),
			H.HExprStmt(expr=H.HIndex(subject=H.HVar("xs"), index=H.HLiteralInt(0))),
		]
	)
	res = tc.check_function(_fn_id("arr"), block)
	assert res.diagnostics == []
	int_ty = tc.type_table.ensure_int()
	arr_ty = tc.type_table.new_array(int_ty)
	assert arr_ty in res.typed_fn.expr_types.values()
	assert int_ty in res.typed_fn.expr_types.values()


def test_ternary_prefers_common_type():
	tc = _tc()
	block = H.HBlock(
		statements=[
			H.HExprStmt(
				expr=H.HTernary(
					cond=H.HLiteralBool(True),
					then_expr=H.HLiteralInt(1),
					else_expr=H.HLiteralInt(2),
				)
			)
		]
	)
	res = tc.check_function(_fn_id("tern"), block)
	assert res.diagnostics == []
	assert tc.type_table.ensure_int() in res.typed_fn.expr_types.values()


def test_call_return_type_uses_signature():
	table = TypeTable()
	tc = TypeChecker(table)
	ret_ty = table.ensure_string()
	sig = FnSignature(name="foo", return_type_id=ret_ty, param_type_ids=[table.ensure_int()])
	block = H.HBlock(
		statements=[
			H.HLet(name="x", value=H.HLiteralInt(1), declared_type_expr=None, binding_id=1),
			H.HExprStmt(expr=H.HCall(fn=H.HVar("foo"), args=[H.HVar("x", binding_id=1)])),
		]
	)
	res = tc.check_function(_fn_id("c"), block, param_types=None, call_signatures={"foo": sig})
	assert res.diagnostics == []
	assert ret_ty in res.typed_fn.expr_types.values()


def test_call_resolution_uses_registry_and_types():
	table = TypeTable()
	tc = TypeChecker(table)
	int_ty = table.ensure_int()
	ret_ty = table.ensure_string()
	registry = CallableRegistry()
	registry.register_free_function(
		callable_id=1,
		name="foo",
		module_id=0,
		visibility=Visibility.public(),
		signature=CallableSignature(param_types=(int_ty,), result_type=ret_ty),
	)
	block = H.HBlock(
		statements=[
			H.HLet(name="x", value=H.HLiteralInt(1), declared_type_expr=None, binding_id=1),
			H.HExprStmt(expr=H.HCall(fn=H.HVar("foo"), args=[H.HVar("x", binding_id=1)])),
		]
	)
	res = tc.check_function(
		_fn_id("c"),
		block,
		param_types={"x": int_ty},
		callable_registry=registry,
		visible_modules=(0,),
		current_module=0,
	)
	assert res.diagnostics == []
	assert ret_ty in res.typed_fn.expr_types.values()


def test_call_with_explicit_type_args_instantiates_signature():
	table = TypeTable()
	tc = TypeChecker(table)
	fn_id = _fn_id("id")
	type_param_id = TypeParamId(owner=fn_id, index=0)
	type_param = TypeParam(id=type_param_id, name="T", span=Span())
	type_var = table.ensure_typevar(type_param_id, name="T")
	sig = FnSignature(
		name="id",
		return_type_id=type_var,
		param_type_ids=[type_var],
		type_params=[type_param],
		module="main",
	)
	registry = CallableRegistry()
	registry.register_free_function(
		callable_id=1,
		name="id",
		module_id=0,
		visibility=Visibility.public(),
		signature=CallableSignature(param_types=(type_var,), result_type=type_var),
		fn_id=fn_id,
		is_generic=True,
	)
	call = H.HCall(
		fn=H.HVar("id"),
		args=[H.HLiteralInt(1)],
		type_args=[
			parser_ast.TypeExpr(
				name="Int",
				args=[],
				module_alias=None,
				module_id=None,
				loc=parser_ast.Located(line=1, column=1),
			)
		],
	)
	block = H.HBlock(statements=[H.HExprStmt(expr=call)])
	res = tc.check_function(
		_fn_id("caller"),
		block,
		callable_registry=registry,
		signatures_by_id={fn_id: sig},
		visible_modules=(0,),
		current_module=0,
	)
	assert res.diagnostics == []
	assert table.ensure_int() in res.typed_fn.expr_types.values()


def test_method_resolution_uses_registry_and_types():
	table = TypeTable()
	tc = TypeChecker(table)
	int_ty = table.ensure_int()
	str_ty = table.ensure_string()
	registry = CallableRegistry()
	recv_ty = table.ensure_ref(int_ty)
	registry.register_inherent_method(
		callable_id=1,
		name="m",
		module_id=0,
		visibility=Visibility.public(),
		signature=CallableSignature(param_types=(recv_ty,), result_type=str_ty),
		impl_id=1,
		impl_target_type_id=int_ty,
		self_mode=SelfMode.SELF_BY_REF,
	)
	block = H.HBlock(
		statements=[
			H.HLet(name="x", value=H.HLiteralInt(1), declared_type_expr=None, binding_id=1),
			H.HExprStmt(expr=H.HMethodCall(receiver=H.HVar("x", binding_id=1), method_name="m", args=[])),
		]
	)
	res = tc.check_function(
		_fn_id("mcall"),
		block,
		param_types={"x": int_ty},
		callable_registry=registry,
		visible_modules=(0,),
		current_module=0,
	)
	assert res.diagnostics == []
	assert str_ty in res.typed_fn.expr_types.values()
	# Verify resolved callee metadata is recorded on the call.
	call_expr = block.statements[1].expr
	resolution = res.typed_fn.call_resolutions.get(id(call_expr))
	assert isinstance(resolution, MethodResolution)
	assert resolution.decl.callable_id == 1
	assert resolution.decl.signature.result_type == str_ty
	assert resolution.receiver_autoborrow == SelfMode.SELF_BY_REF


def test_result_ok_uses_fnresult_type():
	tc = _tc()
	block = H.HBlock(statements=[H.HExprStmt(expr=H.HResultOk(value=H.HLiteralInt(1)))])
	res = tc.check_function(_fn_id("res"), block)
	assert res.diagnostics == []
	assert any(tc.type_table.get(ty).kind is TypeKind.FNRESULT for ty in res.typed_fn.expr_types.values())

[==== File: staged/work/generics-support/work-progress.md =====]
# Generics support — work progress

Goal: add function generics with explicit instantiation and a stable, ID-based substitution spine (TypeParamId/TypeVar) that later phases can build on.

## G2 invariants (locked)
- Type params are identified by ID after parsing; names exist only for diagnostics and pretty-printing.
- Every TypeVar carries its owner (function/signature) to prevent accidental capture across functions/modules.
- Substitution is explicit and total per instantiation in G2 (no partial substitution or inference in this phase).
- Type param names live in the *type namespace* (do not collide with value identifiers).

## Phase G2 — TypeParamId + TypeVar + substitution spine

### G2.1 Data model
- Add `TypeParamId` (owner + index) and `TypeVar(TypeParamId)` as a `TypeId`/`TypeKind` variant.
  - Recommended shape: `TypeParamId { owner: FnId (or SigId), index: u16 }`.
- Change `FnSignature.type_params` from `List[str]` into:
  - `TypeParam { id: TypeParamId, name: InternedStr, span: Span }`.
  - Preserve `name`/`span` strictly for diagnostics.

### G2.2 Lowering: parser → HIR → TypeIds
- When building a function signature, allocate TypeParamIds in order and build a signature-local `name -> TypeParamId` map.
- When resolving types inside the signature (param types / return type / requirement subjects), lower matching names to:
  - `TypeVar(TypeParamId)` (not a nominal type lookup).
- Scope rule: signature type params are in scope across the whole signature, including requirements/guards.

### G2.3 Substitution spine
- Define `Subst { owner: FnId, args: Vec<TypeId> }` and enforce owner equality on apply/instantiate.
  - (Fast path is vector indexed by `TypeParamId.index`; no HashMap needed in G2.)
- Implement `apply(type_id, subst) -> TypeId`:
  - `TypeVar(id)` → `subst.args[id.index]`
  - recurse through all composite types you already represent (arrays, tuples, optionals, refs/ptrs, fn types, etc.).
  - Keep pure (no mutation); optional memoization later if you intern types and want speed.
- Add `instantiate_fn_sig(sig, subst)` to substitute param + return types (and later requirements if needed).

### G2.4 Explicit instantiation
- In call checking, build `Subst` from `call.type_args`:
  - if arg count != `sig.type_params.len()` → diagnostic (new code; span should highlight the call type-arg list).
  - otherwise instantiate callee parameter/return types *before* checking arguments.
- Ensure qualified members follow the same instantiation rule:
  - `Type::Ctor<type T>(...)` uses the same substitution mechanism (no special casing beyond callee selection).

### G2.5 Trait requirement subjects (data correctness)
- Store `T is Trait` with subject lowered to `TypeParamId` (never stringly).
- Checking “satisfies trait” can be deferred, but the representation must be correct now.

## Tests (G2)
- Same name, different owners: `f<T>` vs `g<T>` remain isolated (no cross-capture).
- Substitution through nesting: `Array<T>` → `Array<Int>` and deeper nests.
- Requirements are ID-based: `where T is Hashable` stores `TypeParamId` subject.
- Length mismatch diagnostic for explicit `<type ...>` call args.
- Explicit `<type ...>` instantiation substitutes param/return types in the checker.

## Exit criteria
- Signatures carry `TypeParamId` and types can contain `TypeVar`.
- Explicit `<type ...>` instantiation substitutes parameter/return types via `Subst`.
- Trait requirements store `TypeParamId` subjects (not strings).
